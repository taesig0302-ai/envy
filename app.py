# -*- coding: utf-8 -*-
import base64, time, re, math, json, io, datetime as dt
from pathlib import Path
from urllib.parse import quote
import pandas as pd
import streamlit as st

# ì„ íƒ ëª¨ë“ˆ
try:
    import requests
except Exception:
    requests = None

try:
    from deep_translator import GoogleTranslator
except Exception:
    GoogleTranslator = None

st.set_page_config(page_title="ENVY â€” Season 1 (Dual Proxy Edition)", layout="wide")
SHOW_ADMIN_BOX = False

# Cloudflare Workers (í”„ë¡ì‹œ)
NAVER_PROXY   = "https://envy-proxy.taesig0302.workers.dev"
ELEVENST_PROXY= "https://worker-11stjs.taesig0302.workers.dev"
ITEMSCOUT_PROXY = "https://worker-itemscoutjs.taesig0302.workers.dev"
SELLERLIFE_PROXY = "https://worker-sellerlifejs.taesig0302.workers.dev"

# ê¸°ë³¸ í‚¤ (secretsê°€ ìˆìœ¼ë©´ secrets ìš°ì„ )
DEFAULT_KEYS = {
    "RAKUTEN_APP_ID": "1043271015809337425",
    "RAKUTEN_AFFILIATE_ID": "4c723498.cbfeca46.4c723499.1deb6f77",

    "NAVER_API_KEY": "0100000000785cf1d8f039b13a5d3c3d1262b84e9ad4a046637e8887bbd003051b0d2a5cdf",
    "NAVER_SECRET_KEY": "AQAAAAB4XPHY8DmxOl08PRJiuE6ao1LN3lh0kF9rOJ4m5b8O5g==",
    "NAVER_CUSTOMER_ID": "2274338",

    "NAVER_CLIENT_ID": "T27iw3tyujrM1nG_shFT",
    "NAVER_CLIENT_SECRET": "s59xKPYLz1",
    "NAVER_WEB_REFERER": ""
}

def _get_key(name: str) -> str:
    return (st.secrets.get(name, "") or DEFAULT_KEYS.get(name, "")).strip()

# í™˜ìœ¨(ê°„ë‹¨)
CURRENCIES = {
    "USD":{"kr":"ë¯¸êµ­ ë‹¬ëŸ¬","symbol":"$","unit":"USD"},
    "EUR":{"kr":"ìœ ë¡œ","symbol":"â‚¬","unit":"EUR"},
    "JPY":{"kr":"ì¼ë³¸ ì—”","symbol":"Â¥","unit":"JPY"},
    "CNY":{"kr":"ì¤‘êµ­ ìœ„ì•ˆ","symbol":"å…ƒ","unit":"CNY"},
}
FX_DEFAULT = {"USD":1400.0,"EUR":1500.0,"JPY":10.0,"CNY":200.0}

# ê¸ˆì¹™ì–´ í”„ë¦¬ì…‹
STOPWORDS_GLOBAL = [
    "ë¬´ë£Œë°°ì†¡","ë¬´ë°°","ì´ˆíŠ¹ê°€","íŠ¹ê°€","í•«ë”œ","ìµœì €ê°€","ì„¸ì¼","sale","ì´ë²¤íŠ¸","ì‚¬ì€í’ˆ","ì¦ì •",
    "ì¿ í°","ì—­ëŒ€ê¸‰","ì—­ëŒ€ê°€","í­íƒ„ì„¸ì¼","ì›ê°€","ì •ê°€","íŒŒê²©","ì´ˆëŒ€ë°•","í• ì¸í­","í˜œíƒê°€",
    "íŒŒì†","í™˜ë¶ˆ","êµí™˜","ì¬ê³ ","í’ˆì ˆ","í•œì •ìˆ˜ëŸ‰","ê¸´ê¸‰","ê¸‰ì²˜","íŠ¹íŒ",
    "mustbuy","ê°•ì¶”","ì¶”ì²œ","ì¶”ì²œí…œ","ğŸ”¥","ğŸ’¥","â­","best","ë² ìŠ¤íŠ¸"
]
STOPWORDS_BY_CAT = {
    "íŒ¨ì…˜ì˜ë¥˜": ["ë£¨ì¦ˆí•","ë¹…ì‚¬ì´ì¦ˆ","ì´ˆìŠ¬ë¦¼","ê·¹ì„¸ì‚¬","ì´ˆê²½ëŸ‰","ì™•ì˜¤ë²„","ëª¸ë§¤ë³´ì •"],
    "íŒ¨ì…˜ì¡í™”": ["ë¬´ë£Œê°ì¸","ì‚¬ì€í’ˆì§€ê¸‰","ì„¸íŠ¸ì¦ì •"],
    "ë·°í‹°/ë¯¸ìš©": ["ì •í’ˆë³´ì¥","ë³‘í–‰ìˆ˜ì…","ë²Œí¬","ë¦¬í•„ë§Œ","ìƒ˜í”Œ","í…ŒìŠ¤í„°"],
    "ìƒí™œ/ê±´ê°•": ["ê³µìš©","ë¹„ë§¤í’ˆ","ë¦¬í¼","ë¦¬í¼ë¹„ì‹œ"],
    "ë””ì§€í„¸/ê°€ì „": ["ê´€ë¶€ê°€ì„¸","ë¶€ê°€ì„¸","í•´ì™¸ì§êµ¬","ë¦¬í¼","ë¦¬í¼ë¹„ì‹œ","ë²Œí¬"],
    "ìŠ¤í¬ì¸ /ë ˆì €": ["ë¬´ë£Œì¡°ë¦½","ê°€ì„±ë¹„ê°‘"],
}
STOP_PRESETS = {
    "ë„¤ì´ë²„_ì•ˆì „ê¸°ë³¸": {
        "global": STOPWORDS_GLOBAL,
        "by_cat": STOPWORDS_BY_CAT,
        "whitelist": [],
        "replace": ["ë¬´ë°°=> ", "ë¬´ë£Œë°°ì†¡=> ", "ì •í’ˆ=> "],
        "aggressive": False
    },
    "ê´‘ê³ í‘œí˜„_ê°•ë ¥ì°¨ë‹¨": {
        "global": STOPWORDS_GLOBAL + ["ì´ˆê°•ë ¥","ì´ˆì €ê°€","ê·¹ê°•","í˜œì","ëŒ€ë€","í’ˆì ˆì„ë°•","ì™„íŒì„ë°•","ë§ˆê°ì„ë°•"],
        "by_cat": STOPWORDS_BY_CAT,
        "whitelist": [],
        "replace": ["ë¬´ë°°=> ", "ë¬´ë£Œë°°ì†¡=> ", "ì •í’ˆ=> ", "í• ì¸=> "],
        "aggressive": True
    }
}
def _ensure_session_defaults():
    ss = st.session_state
    ss.setdefault("theme", "light")
    ss.setdefault("fx_base", "USD")
    ss.setdefault("sale_foreign", 1.00)
    ss.setdefault("m_base", "USD")
    ss.setdefault("purchase_foreign", 0.00)
    ss.setdefault("card_fee_pct", 4.00)
    ss.setdefault("market_fee_pct", 14.00)
    ss.setdefault("shipping_won", 0.0)
    ss.setdefault("margin_mode", "í¼ì„¼íŠ¸")
    ss.setdefault("margin_pct", 10.00)
    ss.setdefault("margin_won", 10000.0)

    # ê¸ˆì¹™ì–´ ë§¤ë‹ˆì € ìƒíƒœ
    ss.setdefault("STOP_GLOBAL", list(STOPWORDS_GLOBAL))
    ss.setdefault("STOP_BY_CAT", dict(STOPWORDS_BY_CAT))
    ss.setdefault("STOP_WHITELIST", [])
    ss.setdefault("STOP_REPLACE", ["ë¬´ë°°=> ", "ë¬´ë£Œë°°ì†¡=> ", "ì •í’ˆ=> "])
    ss.setdefault("STOP_AGGR", False)

    # ë¼ì¿ í… ì¥ë¥´ ë§¤í•‘ (âš ï¸ ì‹¤ì œ genreIdë¡œ êµì²´ ê¶Œì¥)
    ss.setdefault("rk_genre_map", {
        # ìƒ˜í”Œ: 'ë·°í‹°/ì½”ìŠ¤ë©”í‹±': '100901' ì²˜ëŸ¼ ì‹¤ì œ genreIdë¥¼ ë„£ì–´ì•¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë‹¬ë¼ì§‘ë‹ˆë‹¤.
        "ì „ì²´(ìƒ˜í”Œ)": "100283",
        "ë·°í‹°/ì½”ìŠ¤ë©”í‹±": "100901",
        "ì˜ë¥˜/íŒ¨ì…˜": "110371",
        "ê°€ì „/ë””ì§€í„¸": "211742",
        "ê°€êµ¬/ì¸í…Œë¦¬ì–´": "215783",
        "ì‹í’ˆ": "100316",
        "ìƒí™œ/ê±´ê°•": "215783",
        "ìŠ¤í¬ì¸ /ë ˆì €": "101070",
        "ë¬¸êµ¬/ì·¨ë¯¸": "101164",
    })

def _toggle_theme():
    st.session_state["theme"] = "dark" if st.session_state.get("theme","light")=="light" else "light"

def _inject_css():
    theme = st.session_state.get("theme","light")
    if theme == "dark":
        bg, fg, fg_sub = "#0e1117", "#e6edf3", "#b6c2cf"
        card_bg, border = "#11151c", "rgba(255,255,255,.08)"
        btn_bg, btn_bg_hover = "#2563eb", "#1e3fae"
        dark_fix_white_boxes = """
        [data-testid="stAppViewContainer"] .stTextInput input,
        [data-testid="stAppViewContainer"] .stNumberInput input,
        [data-testid="stAppViewContainer"] textarea,
        [data-testid="stAppViewContainer"] [data-baseweb="select"] *{
            background:#fff !important; color:#111 !important; -webkit-text-fill-color:#111 !important;
        }"""
        pill_rules = """
        [data-testid="stAppViewContainer"] .pill, [data-testid="stAppViewContainer"] .pill *{
            color:#fff !important; -webkit-text-fill-color:#fff !important;
        }"""
        force_black_rules = """
        .force-black, .force-black *{ color:#111 !important; -webkit-text-fill-color:#111 !important; }"""
    else:
        bg, fg, fg_sub = "#ffffff", "#111111", "#4b5563"
        card_bg, border = "#ffffff", "rgba(0,0,0,.06)"
        btn_bg, btn_bg_hover = "#2563eb", "#1e3fae"
        dark_fix_white_boxes = ""
        pill_rules = """
        [data-testid="stAppViewContainer"] .pill, [data-testid="stAppViewContainer"] .pill *{
            color:#111 !important; -webkit-text-fill-color:#111 !important;
        }
        [data-testid="stAppViewContainer"] .pill.pill-blue, [data-testid="stAppViewContainer"] .pill.pill-blue *{
            color:#fff !important; -webkit-text-fill-color:#fff !important;
        }"""
        force_black_rules = ""

    st.markdown(f"""
    <style>
    [data-testid="stAppViewContainer"]{{background:{bg} !important; color:{fg} !important;}}
    [data-testid="stAppViewContainer"] .card{{background:{card_bg}; border:1px solid {border};
        border-radius:14px; box-shadow:0 1px 6px rgba(0,0,0,.12);}}
    [data-testid="stAppViewContainer"] .stButton>button,
    [data-testid="stAppViewContainer"] [data-testid="stDownloadButton"]>button,
    [data-testid="stAppViewContainer"] a[role="button"]{{
        background:{btn_bg} !important; color:#fff !important; border-radius:10px !important; font-weight:700 !important;
    }}
    [data-testid="stSidebar"] *{{ color:#111 !important; }}
    {pill_rules}{dark_fix_white_boxes}{force_black_rules}
    </style>
    """, unsafe_allow_html=True)

def _responsive_probe():
    html = """
    <script>
    (function(){
      const bps=[900,1280,1600];
      const w=Math.max(document.documentElement.clientWidth||0, window.innerWidth||0);
      let bin=0; for(let i=0;i<bps.length;i++) if(w>=bps[i]) bin=i+1;
      const url=new URL(window.location);
      const curr=url.searchParams.get('vwbin');
      if(curr!==String(bin)){ url.searchParams.set('vwbin', String(bin)); window.location.replace(url.toString()); }
    })();
    </script>
    """
    st.components.v1.html(html, height=0, scrolling=False)

def _get_view_bin():
    try: raw = st.query_params.get("vwbin", "3")
    except Exception: raw = (st.experimental_get_query_params().get("vwbin", ["3"])[0])
    try: return max(0, min(3, int(raw)))
    except: return 3

def _sidebar():
    _ensure_session_defaults()
    _inject_css()
    with st.sidebar:
        c1, c2 = st.columns(2)
        with c1:
            st.toggle("ğŸŒ“ ë‹¤í¬", value=(st.session_state.get("theme","light")=="dark"),
                      on_change=_toggle_theme, key="__theme_toggle")
        with c2:
            st.toggle("ğŸŒ ë²ˆì—­ê¸°", value=False, key="__show_tr")
        # ê°„ë‹¨ íˆ´ë§Œ ìœ ì§€ (í™˜ìœ¨/ë§ˆì§„)
        with st.expander("ğŸ’± í™˜ìœ¨ ê³„ì‚°ê¸°", expanded=True):
            fx = st.selectbox("ê¸°ì¤€ í†µí™”", list(CURRENCIES.keys()), key="fx_base")
            v = st.number_input("íŒë§¤ê¸ˆì•¡ (ì™¸í™”)", value=float(st.session_state.get("sale_foreign",1.0)),
                                step=0.01, format="%.2f", key="sale_foreign")
            won = FX_DEFAULT[fx]*v
            st.markdown(f'<div class="pill pill-green">í™˜ì‚°: <b>{won:,.2f} ì›</b></div>', unsafe_allow_html=True)

        with st.expander("ğŸ“ˆ ë§ˆì§„ ê³„ì‚°ê¸°", expanded=True):
            m_base = st.selectbox("ë§¤ì… í†µí™”", list(CURRENCIES.keys()), key="m_base")
            purchase_foreign = st.number_input("ë§¤ì…ê¸ˆì•¡ (ì™¸í™”)", value=float(st.session_state.get("purchase_foreign",0.0)),
                                               step=0.01, format="%.2f", key="purchase_foreign")
            base_cost = FX_DEFAULT[m_base]*purchase_foreign
            card_fee = st.number_input("ì¹´ë“œìˆ˜ìˆ˜ë£Œ(%)", value=float(st.session_state.get("card_fee_pct",4.0)),
                                       step=0.01, format="%.2f", key="card_fee_pct")
            market_fee = st.number_input("ë§ˆì¼“ìˆ˜ìˆ˜ë£Œ(%)", value=float(st.session_state.get("market_fee_pct",14.0)),
                                         step=0.01, format="%.2f", key="market_fee_pct")
            shipping = st.number_input("ë°°ì†¡ë¹„(â‚©)", value=float(st.session_state.get("shipping_won",0.0)),
                                       step=100.0, format="%.0f", key="shipping_won")
            margin_mode = st.radio("ë§ˆì§„ ë°©ì‹", ["í¼ì„¼íŠ¸","í”ŒëŸ¬ìŠ¤"], horizontal=True, key="margin_mode")
            if margin_mode=="í¼ì„¼íŠ¸":
                margin_pct = st.number_input("ë§ˆì§„ìœ¨ (%)", value=float(st.session_state.get("margin_pct",10.0)),
                                             step=0.01, format="%.2f", key="margin_pct")
                target = base_cost*(1+card_fee/100)*(1+market_fee/100)*(1+margin_pct/100)+shipping
                st.markdown(f'<div class="pill pill-blue">íŒë§¤ê°€: <b>{target:,.2f} ì›</b></div>', unsafe_allow_html=True)
            else:
                margin_won = st.number_input("ë§ˆì§„ì•¡ (â‚©)", value=float(st.session_state.get("margin_won",10000.0)),
                                             step=100.0, format="%.0f", key="margin_won")
                target = base_cost*(1+card_fee/100)*(1+market_fee/100)+margin_won+shipping
                st.markdown(f'<div class="pill pill-blue">íŒë§¤ê°€: <b>{target:,.2f} ì›</b></div>', unsafe_allow_html=True)
import hashlib, hmac, base64 as b64

def _naver_signature(timestamp: str, method: str, uri: str, secret: str) -> str:
    msg = f"{timestamp}.{method}.{uri}"
    digest = hmac.new(bytes(secret, "utf-8"), bytes(msg, "utf-8"), hashlib.sha256).digest()
    return b64.b64encode(digest).decode("utf-8")

def _naver_keys_from_secrets():
    ak = _get_key("NAVER_API_KEY")
    sk = _get_key("NAVER_SECRET_KEY")
    cid= _get_key("NAVER_CUSTOMER_ID")
    return ak.strip(), sk.strip(), str(cid).strip()

def _naver_keywordstool(hint_keywords: list[str]) -> pd.DataFrame:
    api_key, sec_key, customer_id = _naver_keys_from_secrets()
    if not (requests and api_key and sec_key and customer_id and hint_keywords):
        return pd.DataFrame()

    base_url="https://api.naver.com"; uri="/keywordstool"; ts = str(round(time.time()*1000))
    headers = {"X-API-KEY": api_key, "X-Signature": _naver_signature(ts, "GET", uri, sec_key),
               "X-Timestamp": ts, "X-Customer": customer_id}
    params={ "hintKeywords": ",".join(hint_keywords), "includeHintKeywords": "0", "showDetail": "1" }
    try:
        r = requests.get(base_url+uri, headers=headers, params=params, timeout=12)
        r.raise_for_status()
    except Exception:
        return pd.DataFrame()

    try:
        data = r.json().get("keywordList", [])[:200]
        if not data: return pd.DataFrame()
        df = pd.DataFrame(data).rename(columns={
            "relKeyword":"í‚¤ì›Œë“œ","monthlyPcQcCnt":"PCì›”ê°„ê²€ìƒ‰ìˆ˜","monthlyMobileQcCnt":"Mobileì›”ê°„ê²€ìƒ‰ìˆ˜",
            "monthlyAvePcClkCnt":"PCì›”í‰ê· í´ë¦­ìˆ˜","monthlyAveMobileClkCnt":"Mobileì›”í‰ê· í´ë¦­ìˆ˜",
            "monthlyAvePcCtr":"PCì›”í‰ê· í´ë¦­ë¥ ","monthlyAveMobileCtr":"Mobileì›”í‰ê· í´ë¦­ë¥ ",
            "plAvgDepth":"ì›”í‰ê· ë…¸ì¶œê´‘ê³ ìˆ˜","compIdx":"ê´‘ê³ ê²½ìŸì •ë„",
        }).drop_duplicates(["í‚¤ì›Œë“œ"]).reset_index(drop=True)
        for c in ["PCì›”ê°„ê²€ìƒ‰ìˆ˜","Mobileì›”ê°„ê²€ìƒ‰ìˆ˜","PCì›”í‰ê· í´ë¦­ìˆ˜","Mobileì›”í‰ê· í´ë¦­ìˆ˜",
                  "PCì›”í‰ê· í´ë¦­ë¥ ","Mobileì›”í‰ê· í´ë¦­ë¥ ","ì›”í‰ê· ë…¸ì¶œê´‘ê³ ìˆ˜"]:
            df[c]=pd.to_numeric(df[c], errors="coerce")
        return df
    except Exception:
        return pd.DataFrame()

@st.cache_data(ttl=1800, show_spinner=False)
def _datalab_trend(groups: list, start_date: str, end_date: str, time_unit: str="week") -> pd.DataFrame:
    if not requests: return pd.DataFrame()
    cid = _get_key("NAVER_CLIENT_ID"); csec = _get_key("NAVER_CLIENT_SECRET")
    if not (cid and csec): return pd.DataFrame()

    url = "https://openapi.naver.com/v1/datalab/search"
    headers = {"X-Naver-Client-Id": cid, "X-Naver-Client-Secret": csec,
               "Content-Type": "application/json; charset=utf-8"}
    ref = (_get_key("NAVER_WEB_REFERER") or "").strip()
    if ref: headers["Referer"] = ref

    payload = { "startDate": start_date, "endDate": end_date,
                "timeUnit": time_unit, "keywordGroups": (groups or [])[:5] }
    try:
        r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=12)
        r.raise_for_status()
        rows=[]
        for gr in r.json().get("results", []):
            title = gr.get("title") or (gr.get("keywords") or [""])[0]
            df = pd.DataFrame(gr.get("data", []))
            if df.empty: continue
            df["keyword"] = title
            rows.append(df)
        if not rows: return pd.DataFrame()
        big = pd.concat(rows, ignore_index=True).rename(columns={"period":"ë‚ ì§œ","ratio":"ê²€ìƒ‰ì§€ìˆ˜"})
        pv = big.pivot_table(index="ë‚ ì§œ", columns="keyword", values="ê²€ìƒ‰ì§€ìˆ˜", aggfunc="mean")
        return pv.reset_index().sort_values("ë‚ ì§œ")
    except Exception:
        return pd.DataFrame()

def section_korea_ui():
    st.markdown('<div class="main">', unsafe_allow_html=True)
    st.caption("â€» ì§€í‘œ: ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API / íŠ¸ë Œë“œ: DataLab")
    c1, c2, c3 = st.columns([1,1,1])
    with c1: months = st.slider("ë¶„ì„ê¸°ê°„(ê°œì›”, í‘œì‹œ)", 1, 6, 3)
    with c2: device = st.selectbox("ë””ë°”ì´ìŠ¤", ["all","pc","mo"], index=0)
    with c3: src = st.selectbox("í‚¤ì›Œë“œ ì†ŒìŠ¤", ["ì§ì ‘ ì…ë ¥"], index=0)
    keywords_txt = st.text_area("í‚¤ì›Œë“œ(ì½¤ë§ˆë¡œ êµ¬ë¶„)", "í•¸ë“œë©”ì´ë“œì½”íŠ¸, ë‚¨ìì½”íŠ¸, ì—¬ìì½”íŠ¸", height=96)
    kw_list = [k.strip() for k in (keywords_txt or "").split(",") if k.strip()]

    opt1, opt2 = st.columns([1,1])
    with opt1: add_product = st.toggle("ë„¤ì´ë²„ì‡¼í•‘ â€˜ì „ì²´â€™ ìƒí’ˆìˆ˜ ìˆ˜ì§‘(ëŠë¦¼)", value=False)
    with opt2: table_mode = st.radio("í‘œ ëª¨ë“œ", ["A(ê²€ìƒ‰ì§€í‘œ)","B(ê²€ìƒ‰+ìˆœìœ„)","C(ê²€ìƒ‰+ìƒí’ˆìˆ˜+ìŠ¤ì½”ì–´)"], horizontal=True, index=2)

    if st.button("ë ˆì´ë” ì—…ë°ì´íŠ¸"):
        df = _naver_keywordstool(kw_list)
        if df.empty: st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); st.markdown("</div>", unsafe_allow_html=True); return

        if table_mode.startswith("A"):
            st.dataframe(df, use_container_width=True, height=430)
            st.download_button("CSV ë‹¤ìš´ë¡œë“œ", df.to_csv(index=False).encode("utf-8-sig"),
                               file_name="korea_keyword_A.csv", mime="text/csv")
            st.markdown("</div>", unsafe_allow_html=True); return

        df2 = df.copy()
        df2["ê²€ìƒ‰í•©ê³„"] = pd.to_numeric(df2["PCì›”ê°„ê²€ìƒ‰ìˆ˜"], errors="coerce").fillna(0) + \
                           pd.to_numeric(df2["Mobileì›”ê°„ê²€ìƒ‰ìˆ˜"], errors="coerce").fillna(0)
        df2["ê²€ìƒ‰ìˆœìœ„"] = df2["ê²€ìƒ‰í•©ê³„"].rank(ascending=False, method="min")

        if table_mode.startswith("B"):
            out = df2.sort_values("ê²€ìƒ‰ìˆœìœ„")
            st.dataframe(out, use_container_width=True, height=430)
            st.download_button("CSV ë‹¤ìš´ë¡œë“œ", out.to_csv(index=False).encode("utf-8-sig"),
                               file_name="korea_keyword_B.csv", mime="text/csv")
            st.markdown("</div>", unsafe_allow_html=True); return

        # C ëª¨ë“œ: (ì„ íƒ) ìƒí’ˆìˆ˜ + ì¢…í•©ë­í¬
        if add_product:
            # ëŠë ¤ì„œ ê¸°ë³¸ì€ ë” (ì›í•˜ëŠ” ê²½ìš°ì—ë§Œ í¬ë¡¤ë§)
            product_counts = [math.nan]*len(df2)  # ìë¦¬ë§Œ
        else:
            product_counts = [math.nan]*len(df2)

        df2["íŒë§¤ìƒí’ˆìˆ˜"] = product_counts
        df2["ìƒí’ˆìˆ˜ìˆœìœ„"] = df2["íŒë§¤ìƒí’ˆìˆ˜"].rank(na_option="bottom", method="min")
        df2["ìƒí’ˆë°œêµ´ëŒ€ìƒ"] = (df2["ê²€ìƒ‰ìˆœìœ„"] + df2["ìƒí’ˆìˆ˜ìˆœìœ„"]).rank(na_option="bottom", method="min")
        cols = ["í‚¤ì›Œë“œ","PCì›”ê°„ê²€ìƒ‰ìˆ˜","Mobileì›”ê°„ê²€ìƒ‰ìˆ˜","íŒë§¤ìƒí’ˆìˆ˜",
                "PCì›”í‰ê· í´ë¦­ìˆ˜","Mobileì›”í‰ê· í´ë¦­ìˆ˜","PCì›”í‰ê· í´ë¦­ë¥ ","Mobileì›”í‰ê· í´ë¦­ë¥ ",
                "ì›”í‰ê· ë…¸ì¶œê´‘ê³ ìˆ˜","ê´‘ê³ ê²½ìŸì •ë„","ê²€ìƒ‰ìˆœìœ„","ìƒí’ˆìˆ˜ìˆœìœ„","ìƒí’ˆë°œêµ´ëŒ€ìƒ"]
        out = df2[cols].sort_values("ìƒí’ˆë°œêµ´ëŒ€ìƒ")
        st.dataframe(out, use_container_width=True, height=430)
        st.download_button("CSV ë‹¤ìš´ë¡œë“œ", out.to_csv(index=False).encode("utf-8-sig"),
                           file_name="korea_keyword_C.csv", mime="text/csv")
    st.markdown("</div>", unsafe_allow_html=True)
def _rakuten_keys():
    app_id = _get_key("RAKUTEN_APP_ID")
    affiliate = _get_key("RAKUTEN_AFFILIATE_ID")
    return app_id, affiliate

@st.cache_data(ttl=900, show_spinner=False)
def _rk_fetch_rank_cached(genre_id: str, topn: int = 20, strip_emoji: bool=True) -> pd.DataFrame:
    app_id, affiliate = _rakuten_keys()

    def _clean(s: str) -> str:
        if not strip_emoji: return s
        # ì´ëª¨ì§€ ì œê±°
        return re.sub(r"[\U00010000-\U0010ffff]", "", s or "")

    # í‚¤ ì—†ìœ¼ë©´ ìƒ˜í”Œ
    if not (requests and app_id):
        rows=[{"rank":i+1,"keyword":_clean(f"[ìƒ˜í”Œ] í‚¤ì›Œë“œ {i+1} ãƒãƒ­ã‚¦ã‚£ãƒ³ ç§‹ ğŸ‚"),
               "shop":"ìƒ˜í”Œ","url":"https://example.com"} for i in range(topn)]
        return pd.DataFrame(rows)

    try:
        api = "https://app.rakuten.co.jp/services/api/IchibaItem/Ranking/20170628"
        params = {"applicationId": app_id, "genreId": str(genre_id).strip(), "hits": topn}
        if affiliate: params["affiliateId"] = affiliate
        r = requests.get(api, params=params, timeout=12)
        r.raise_for_status()
        items = r.json().get("Items", [])[:topn]
        rows=[]
        for it in items:
            node = it.get("Item", {})
            rows.append({
                "rank": node.get("rank"),
                "keyword": _clean(node.get("itemName","")),
                "shop": node.get("shopName",""),
                "url": node.get("itemUrl",""),
            })
        return pd.DataFrame(rows)
    except Exception:
        # ì‹¤íŒ¨ ì‹œ ìƒ˜í”Œ
        rows=[{"rank":i+1,"keyword":_clean(f"[ìƒ˜í”Œ] í‚¤ì›Œë“œ {i+1} ãƒãƒ­ã‚¦ã‚£ãƒ³ ç§‹ ğŸ‚"),
               "shop":"ìƒ˜í”Œ","url":"https://example.com"} for i in range(topn)]
        return pd.DataFrame(rows)

def section_rakuten_ui():
    st.markdown('<div id="rk-card" class="main">', unsafe_allow_html=True)
    colB, colC = st.columns([2,1])
    with colB:
        cat = st.selectbox("ë¼ì¿ í… ì¹´í…Œê³ ë¦¬",
                           ["ì „ì²´(ìƒ˜í”Œ)","ë·°í‹°/ì½”ìŠ¤ë©”í‹±","ì˜ë¥˜/íŒ¨ì…˜","ê°€ì „/ë””ì§€í„¸","ê°€êµ¬/ì¸í…Œë¦¬ì–´","ì‹í’ˆ","ìƒí™œ/ê±´ê°•","ìŠ¤í¬ì¸ /ë ˆì €","ë¬¸êµ¬/ì·¨ë¯¸"],
                           key="rk_cat")
    with colC:
        sample_only = st.checkbox("ìƒ˜í”Œ ë³´ê¸°", value=False, key="rk_sample")
        strip_emoji = st.toggle("ì´ëª¨ì§€ ì œê±°", value=True, key="rk_strip_emoji")

    genre_map = st.session_state.get("rk_genre_map", {})
    genre_id = (genre_map.get(cat) or "").strip() or "100283"  # ê¸°ë³¸ê°’

    with st.spinner("ë¼ì¿ í… ë­í‚¹ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
        df = (pd.DataFrame([{"rank":i+1,"keyword":f"[ìƒ˜í”Œ] í‚¤ì›Œë“œ {i+1}","shop":"ìƒ˜í”Œ","url":"https://example.com"} for i in range(20)])
              if sample_only else _rk_fetch_rank_cached(genre_id, topn=20, strip_emoji=strip_emoji))

    colcfg = {
        "rank": st.column_config.NumberColumn("rank", width="small"),
        "keyword": st.column_config.TextColumn("keyword", width="medium"),
        "shop": st.column_config.TextColumn("shop", width="small"),
        "url": st.column_config.LinkColumn("url", display_text="ì—´ê¸°", width="small"),
    }
    st.dataframe(df[["rank","keyword","shop","url"]], hide_index=True, use_container_width=True, height=430, column_config=colcfg)
    st.download_button("í‘œ CSV ë‹¤ìš´ë¡œë“œ", data=df.to_csv(index=False).encode("utf-8-sig"),
                       file_name="rakuten_ranking.csv", mime="text/csv")

    with st.expander("ğŸ”§ ì¥ë¥´ ë§¤í•‘ í¸ì§‘ (í™”ë©´ì—ëŠ” ìˆ¨ê¹€)", expanded=False):
        st.caption("ì¹´í…Œê³ ë¦¬ â†’ genreId ë§¤í•‘ì…ë‹ˆë‹¤. ì‹¤ì œ genreIdë¡œ ë°”ê¿”ì•¼ ì¹´í…Œê³ ë¦¬ë³„ ë­í‚¹ì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤.")
        for k in ["ë·°í‹°/ì½”ìŠ¤ë©”í‹±","ì˜ë¥˜/íŒ¨ì…˜","ê°€ì „/ë””ì§€í„¸","ê°€êµ¬/ì¸í…Œë¦¬ì–´","ì‹í’ˆ","ìƒí™œ/ê±´ê°•","ìŠ¤í¬ì¸ /ë ˆì €","ë¬¸êµ¬/ì·¨ë¯¸","ì „ì²´(ìƒ˜í”Œ)"]:
            st.session_state["rk_genre_map"][k] = st.text_input(k, st.session_state["rk_genre_map"].get(k,"100283"), key=f"rk_{k}")
        st.info("ì„¸ì…˜ì— ì €ì¥ë©ë‹ˆë‹¤. ì•± ì¬ì‹¤í–‰ ì‹œ ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒì•„ì˜¬ ìˆ˜ ìˆì–´ìš”.")
    st.markdown('</div>', unsafe_allow_html=True)
SEED_MAP = {
    "íŒ¨ì…˜ì˜ë¥˜": ["ì›í”¼ìŠ¤","ì½”íŠ¸","ë‹ˆíŠ¸","ì…”ì¸ ","ë¸”ë¼ìš°ìŠ¤"],
    "íŒ¨ì…˜ì¡í™”": ["ê°€ë°©","ì§€ê°‘","ëª¨ì","ìŠ¤ì¹´í”„","ë²¨íŠ¸"],
    "ë·°í‹°/ë¯¸ìš©": ["ì¿ ì…˜","ë¦½ìŠ¤í‹±","ì„ í¬ë¦¼","ë§ˆìŠ¤ì¹´ë¼","í† ë„ˆ"],
    "ë””ì§€í„¸/ê°€ì „": ["ë¸”ë£¨íˆ¬ìŠ¤ì´ì–´í°","ìŠ¤í”¼ì»¤","ëª¨ë‹ˆí„°","ë…¸íŠ¸ë¶","ë¡œë´‡ì²­ì†Œê¸°"],
    "ê°€êµ¬/ì¸í…Œë¦¬ì–´": ["ì†ŒíŒŒ","ì‹íƒ","í–‰ê±°","ìˆ˜ë‚©ì¥","ëŸ¬ê·¸"],
    "ìƒí™œ/ê±´ê°•": ["ì¹«ì†”","ì¹˜ì•½","ìƒ´í‘¸","ì„¸ì œ","ë¬¼í‹°ìŠˆ"],
    "ì‹í’ˆ": ["ê°„í¸ì‹","ì»¤í”¼","ì°¨","ê³¼ì","ì¦‰ì„ë°¥"],
    "ì¶œì‚°/ìœ¡ì•„": ["ê¸°ì €ê·€","ë¬¼í‹°ìŠˆ","ìœ ëª¨ì°¨","ì¹´ì‹œíŠ¸","ì•„ê¸°ë "],
    "ìŠ¤í¬ì¸ /ë ˆì €": ["ëŸ¬ë‹í™”","ìš”ê°€ë³µ","ìº í•‘ì˜ì","í…íŠ¸","ìì „ê±°"],
    "ìë™ì°¨/ê³µêµ¬": ["ë¸”ë™ë°•ìŠ¤","ì—”ì§„ì˜¤ì¼","ì°¨ëŸ‰ìš©ì²­ì†Œê¸°","ê³µêµ¬ì„¸íŠ¸","ì™€ì´í¼"],
    "ë„ì„œ/ì·¨ë¯¸/ì˜¤í”¼ìŠ¤": ["ë¬¸êµ¬ì„¸íŠ¸","ë‹¤ì´ì–´ë¦¬","ìŠ¤í‹°ì»¤","ë³´ë“œê²Œì„","í¼ì¦"],
    "ì—¬í–‰/ë¬¸í™”": ["ìºë¦¬ì–´","ì—¬ê¶Œì§€ê°‘","ëª©ë² ê°œ","ì—¬í–‰ìš©íŒŒìš°ì¹˜","ìŠ¬ë¦¬í¼"],
}

def section_category_keyword_lab():
    st.markdown('<div class="card"><div class="card-title">ì¹´í…Œê³ ë¦¬ â†’ í‚¤ì›Œë“œ Top20 & íŠ¸ë Œë“œ</div>', unsafe_allow_html=True)
    is_dark = (st.session_state.get("theme","light") == "dark")
    cA, cB, cC = st.columns([1,1,1])

    if is_dark: st.markdown("<div class='force-black'>", unsafe_allow_html=True)
    with cA: cat = st.selectbox("ì¹´í…Œê³ ë¦¬", list(SEED_MAP.keys()))
    with cB: time_unit = st.selectbox("ë‹¨ìœ„", ["week","month"], index=0)
    with cC: months = st.slider("ì¡°íšŒê¸°ê°„(ê°œì›”)", 1, 12, 3)
    if is_dark: st.markdown("</div>", unsafe_allow_html=True)

    start = (dt.date.today() - dt.timedelta(days=30 * months)).strftime("%Y-%m-%d")
    end   = (dt.date.today() - dt.timedelta(days=1)).strftime("%Y-%m-%d")

    seeds = SEED_MAP.get(cat, [])
    df = _naver_keywordstool(seeds)
    if df.empty:
        st.warning("í‚¤ì›Œë“œë„êµ¬ ì‘ë‹µì´ ë¹„ì—ˆìŠµë‹ˆë‹¤."); st.markdown("</div>", unsafe_allow_html=True); return

    df["ê²€ìƒ‰í•©ê³„"] = pd.to_numeric(df["PCì›”ê°„ê²€ìƒ‰ìˆ˜"], errors="coerce").fillna(0) + \
                      pd.to_numeric(df["Mobileì›”ê°„ê²€ìƒ‰ìˆ˜"], errors="coerce").fillna(0)
    top20 = df.sort_values("ê²€ìƒ‰í•©ê³„", ascending=False).head(20).reset_index(drop=True)
    st.dataframe(top20[["í‚¤ì›Œë“œ","ê²€ìƒ‰í•©ê³„","PCì›”ê°„ê²€ìƒ‰ìˆ˜","Mobileì›”ê°„ê²€ìƒ‰ìˆ˜","ì›”í‰ê· ë…¸ì¶œê´‘ê³ ìˆ˜","ê´‘ê³ ê²½ìŸì •ë„"]],
                 use_container_width=True, height=340)
    st.download_button("CSV ë‹¤ìš´ë¡œë“œ", top20.to_csv(index=False).encode("utf-8-sig"),
                       file_name=f"category_{cat}_top20.csv", mime="text/csv")

    topk = st.slider("ë¼ì¸ì°¨íŠ¸ í‚¤ì›Œë“œ ìˆ˜", 3, 10, 5)
    kws = top20["í‚¤ì›Œë“œ"].head(topk).tolist()
    groups = [{"groupName": k, "keywords": [k]} for k in kws]
    ts = _datalab_trend(groups, start, end, time_unit=time_unit)
    if ts.empty:
        st.info("DataLab íŠ¸ë Œë“œ ì‘ë‹µì´ ë¹„ì–´ ìˆì–´ìš”.")
    else:
        st.line_chart(ts.set_index("ë‚ ì§œ"))
    st.markdown("</div>", unsafe_allow_html=True)

def section_keyword_trend_widget():
    st.markdown('<div class="card"><div class="card-title">í‚¤ì›Œë“œ íŠ¸ë Œë“œ (ì§ì ‘ ì…ë ¥)</div>', unsafe_allow_html=True)
    kwtxt = st.text_input("í‚¤ì›Œë“œ(ì½¤ë§ˆ)", "ê°€ë°©, ì›í”¼ìŠ¤", key="kw_txt_direct")
    unit = st.selectbox("ë‹¨ìœ„", ["week","month"], index=0, key="kw_unit_direct")
    months = st.slider("ì¡°íšŒê¸°ê°„(ê°œì›”)", 1, 12, 3, key="kw_months_direct")
    if st.button("íŠ¸ë Œë“œ ì¡°íšŒ", key="kw_run_direct"):
        start = (dt.date.today() - dt.timedelta(days=30 * months)).strftime("%Y-%m-%d")
        end   = (dt.date.today() - dt.timedelta(days=1)).strftime("%Y-%m-%d")
        kws = [k.strip() for k in (kwtxt or "").split(",") if k.strip()]
        groups = [{"groupName": k, "keywords": [k]} for k in kws][:5]
        df = _datalab_trend(groups, start, end, time_unit=unit)
        if df.empty:
            st.error("DataLab ì‘ë‹µì´ ë¹„ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.dataframe(df, use_container_width=True, height=260)
            st.line_chart(df.set_index("ë‚ ì§œ"))
            st.download_button("CSV ë‹¤ìš´ë¡œë“œ", data=df.to_csv(index=False).encode("utf-8-sig"),
                               file_name="keyword_trend_direct.csv", mime="text/csv")
    st.markdown('</div>', unsafe_allow_html=True)
# ì œëª© ì •ì œìš© ê·œì¹™ (ê¸°ë³¸ ë¬¸ì ì™¸ ì œê±°/ì••ì¶•)
PATTERN_RE = re.compile(r"[^\w\sê°€-í£A-Za-z0-9+/Â·\-\|\(\)\[\]]", re.UNICODE)
LITERAL_RE = re.compile(r"\s{2,}")

_ALLOWED_BY_DOMAIN = {
    "ë¬´ë¦ë³´í˜¸ëŒ€": ["ë¬´ë¦","ë³´í˜¸ëŒ€","ê´€ì ˆ","ì••ë°•","í…Œì´í•‘","ë°´ë“œ","ì„œí¬í„°","ìŠ¬ë¦¬ë¸Œ","ìŠ¬ê°œê³¨","ì¬í™œ","ìš´ë™","ëŸ¬ë‹","í—¬ìŠ¤","ì¿ ì…˜"],
}
_BLOCK_LIST = {"ì–‘ì‚°","ë—ìë¦¬","ì§€ê°‘","ëª¨ì","ìš°ì‚°","ë¨¸ê·¸","í‚¤ë§","ìŠ¬ë¦¬í¼","ê°€ëœë“œ"}

def _dedupe_tokens(s:str)->str:
    seen=set(); out=[]
    for t in s.split():
        k=t.lower()
        if k in seen: continue
        seen.add(k); out.append(t)
    return " ".join(out)

def _truncate_bytes(text:str, max_bytes:int=50)->str:
    raw=text.encode("utf-8")
    if len(raw)<=max_bytes: return text
    cut=raw[:max_bytes]
    while True:
        try: s=cut.decode("utf-8"); break
        except UnicodeDecodeError: cut=cut[:-1]
    return s.rstrip()+"â€¦"

def _apply_filters_soft(text:str)->str:
    try:
        out = PATTERN_RE.sub(" ", text)
        out = LITERAL_RE.sub(" ", out)
    except Exception:
        out = text
    return re.sub(r"\s+"," ", out).strip()

def _seed_tokens(seed:str)->list[str]:
    toks = [t for t in re.split(r"[,\s/|]+", seed or "") if len(t)>=2]
    extras=[]
    for t in toks:
        if "ë¬´ë¦ë³´í˜¸ëŒ€" in t: extras += ["ë¬´ë¦","ë³´í˜¸ëŒ€"]
    return list(dict.fromkeys(toks+extras))

def _is_related_kw(kw:str, seed:str)->bool:
    if not kw: return False
    if kw in _BLOCK_LIST: return False
    allow = set(_seed_tokens(seed))
    dom=[]
    for s in allow:
        if s in _ALLOWED_BY_DOMAIN: dom += _ALLOWED_BY_DOMAIN[s]
    allow |= set(dom)
    return any(a in kw for a in allow)

@st.cache_data(ttl=3600, show_spinner=False)
def _cached_kstats(seed: str) -> pd.DataFrame:
    if not seed: return pd.DataFrame()
    df = _naver_keywordstool([seed])
    if df.empty: return pd.DataFrame()
    for c in ["PCì›”ê°„ê²€ìƒ‰ìˆ˜","Mobileì›”ê°„ê²€ìƒ‰ìˆ˜","ê´‘ê³ ê²½ìŸì •ë„"]:
        df[c] = pd.to_numeric(df.get(c,0), errors="coerce").fillna(0)
    df["ê²€ìƒ‰í•©ê³„"] = df["PCì›”ê°„ê²€ìƒ‰ìˆ˜"] + df["Mobileì›”ê°„ê²€ìƒ‰ìˆ˜"]
    return df

@st.cache_data(ttl=1200, show_spinner=False)
def _suggest_keywords_by_searchad_and_datalab(seed_kw:str, months:int=3, top_rel:int=15, strict:bool=True) -> pd.DataFrame:
    base = _cached_kstats(seed_kw)
    if base.empty or "í‚¤ì›Œë“œ" not in base.columns: return pd.DataFrame()
    df = base.copy()
    df = df[df["í‚¤ì›Œë“œ"].astype(str).str.strip().str.len()>0]
    df = df[df["í‚¤ì›Œë“œ"].astype(str)!=str(seed_kw)]
    df = df.sort_values("ê²€ìƒ‰í•©ê³„", ascending=False)
    if strict:
        df = df[df["í‚¤ì›Œë“œ"].apply(lambda k: _is_related_kw(str(k), seed_kw))]
    if df.empty and strict:
        # ë°±ì—…: ê´€ë ¨ì„± ì™„í™”
        df = base.copy()
        df = df[df["í‚¤ì›Œë“œ"].astype(str)!=str(seed_kw)].sort_values("ê²€ìƒ‰í•©ê³„", ascending=False)
    if df.empty: return pd.DataFrame()

    df = df.head(max(5,min(50,top_rel))).reset_index(drop=True)
    start=(dt.date.today()-dt.timedelta(days=30*months)).strftime("%Y-%m-%d")
    end=(dt.date.today()-dt.timedelta(days=1)).strftime("%Y-%m-%d")

    dl_means={}
    for i in range(0,len(df),5):
        chunk=df["í‚¤ì›Œë“œ"].tolist()[i:i+5]
        groups=[{"groupName":k,"keywords":[k]} for k in chunk]
        ts=_datalab_trend(groups,start,end,time_unit="week")
        if ts.empty:
            for k in chunk: dl_means.setdefault(k,0.0)
        else:
            for k in chunk:
                try: dl_means[k]=float(pd.to_numeric(ts.get(k),errors="coerce").mean())
                except: dl_means[k]=0.0
    df["dl_mean"]=df["í‚¤ì›Œë“œ"].map(dl_means).fillna(0.0)
    df["score"]=pd.to_numeric(df["ê²€ìƒ‰í•©ê³„"],errors="coerce").fillna(0)*(df["dl_mean"].clip(lower=0)/100.0)
    return df.sort_values(["score","ê²€ìƒ‰í•©ê³„"],ascending=[False,False]).reset_index(drop=True)

_FALLBACK_PAD={"ë¬´ë¦ë³´í˜¸ëŒ€":["ìŠ¤í¬ì¸ ","í—¬ìŠ¤","ëŸ¬ë‹","ê´€ì ˆë³´í˜¸","ì••ë°•ë°´ë“œ","í…Œì´í•‘","ë‚¨ë…€ê³µìš©","í”„ë¦¬ì‚¬ì´ì¦ˆ","ì¶©ê²©í¡ìˆ˜"]}

def _compose_titles(main_kw:str, attrs:list[str], sugg:list[str], min_chars:int=30, max_bytes:int=50, topn:int=10):
    base=[t for t in [main_kw]+attrs if t]
    if not sugg: sugg=_FALLBACK_PAD.get(main_kw,[]) or _seed_tokens(main_kw)
    candidates=[]
    L=min(len(sugg),5)
    for i in range(L):
        candidates.append(base+[sugg[i]])
        for j in range(i+1,L):
            candidates.append(base+[sugg[i],sugg[j]])
            for k in range(j+1,L):
                candidates.append(base+[sugg[i],sugg[j],sugg[k]])
    if not candidates: candidates=[base]
    out=[]; used=set()
    for toks in candidates:
        title=_apply_filters_soft(_dedupe_tokens(" ".join(toks)))
        if not title: continue
        if len(title)<min_chars:
            pad=[x for x in (sugg+attrs) if x and x not in toks]
            for p in pad:
                trial=_apply_filters_soft(_dedupe_tokens(title+" "+p))
                if len(trial.encode("utf-8"))>max_bytes: break
                title=trial
                if len(title)>=min_chars: break
        if len(title.encode("utf-8"))>max_bytes: title=_truncate_bytes(title,max_bytes)
        key=title.lower().strip()
        if key and key not in used:
            out.append(title); used.add(key)
        if len(out)>=topn: break
    return out[:topn]

def section_title_generator():
    st.markdown('<div class="card main"><div class="card-title">ìƒí’ˆëª… ìƒì„±ê¸° (ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ Â· Top-N)</div>', unsafe_allow_html=True)
    cA,cB=st.columns([1,2])
    with cA:
        brand=st.text_input("ë¸Œëœë“œ", placeholder="ì˜ˆ: ë¬´ì§€ / Apple")
        attrs=st.text_input("ì†ì„±(ì½¤ë§ˆ, ì„ íƒ)", placeholder="ì˜ˆ: ìŠ¤í¬ì¸ , í—¬ìŠ¤, ëŸ¬ë‹, ë‚¨ë…€ê³µìš©, ì••ë°•ë°´ë“œ")
    with cB:
        kws_raw=st.text_input("í‚¤ì›Œë“œ(ì½¤ë§ˆ, ì²« ë²ˆì§¸ê°€ ë©”ì¸)", placeholder="ì˜ˆ: ë¬´ë¦ë³´í˜¸ëŒ€, ê´€ì ˆë³´í˜¸, ì¶©ê²©í¡ìˆ˜")
        main_kw=next((k.strip() for k in (kws_raw or "").split(",") if k.strip()),"")

    c1,c2,c3,c4=st.columns([1,1,1,1])
    with c1: N=st.slider("ì¶”ì²œ ê°œìˆ˜",5,20,10,1)
    with c2: min_chars=st.slider("ìµœì†Œ ê¸€ì(ê¶Œì¥ 30~50)",30,50,35,1)
    with c3: max_chars=st.slider("ìµœëŒ€ ë°”ì´íŠ¸",30,50,50,1)
    with c4: months=st.slider("ê²€ìƒ‰ íŠ¸ë Œë“œ ê¸°ê°„(ê°œì›”)",1,6,3)
    relaxed=st.checkbox("ëŠìŠ¨í•œ ëª¨ë“œ(ì—°ê´€ì„± ì™„í™”/ë°±ì—…)", value=False)

    st.caption("â€» ìƒìœ„ í‚¤ì›Œë“œ: ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API + DataLab. 30ì/50ë°”ì´íŠ¸ ìë™ íŒ¨ë”©.")

    sugg_df=pd.DataFrame()
    if st.button("ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì²œ ë¶ˆëŸ¬ì˜¤ê¸° (ë°ì´í„°ë©+í‚¤ì›Œë“œë„êµ¬)"):
        if not main_kw: st.error("ë©”ì¸ í‚¤ì›Œë“œë¥¼ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("ì—°ê´€ í‚¤ì›Œë“œÂ·íŠ¸ë Œë“œ ìˆ˜ì§‘ ì¤‘â€¦"):
                sugg_df=_suggest_keywords_by_searchad_and_datalab(main_kw,months=months,top_rel=15,strict=(not relaxed))
            if sugg_df.empty: st.warning("ì¶”ì²œ ë°ì´í„° ì—†ìŒ")
            else:
                show=["í‚¤ì›Œë“œ","PCì›”ê°„ê²€ìƒ‰ìˆ˜","Mobileì›”ê°„ê²€ìƒ‰ìˆ˜","ê²€ìƒ‰í•©ê³„","dl_mean","score"]
                st.dataframe(sugg_df[show], use_container_width=True, height=320)
                st.download_button("ì¶”ì²œ í‚¤ì›Œë“œ CSV", data=sugg_df[show].to_csv(index=False).encode("utf-8-sig"),
                                   file_name=f"suggest_keywords_{main_kw}.csv", mime="text/csv")

    if st.button("ìƒí’ˆëª… ìƒì„±"):
        if not main_kw: st.error("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”."); st.markdown("</div>", unsafe_allow_html=True); return
        if sugg_df.empty: sugg_df=_suggest_keywords_by_searchad_and_datalab(main_kw,months=months,top_rel=15,strict=(not relaxed))
        at_list=[a.strip() for a in (attrs or "").split(",") if a.strip()]
        sugg=(sugg_df["í‚¤ì›Œë“œ"].tolist() if not sugg_df.empty else [])
        titles=_compose_titles(main_kw,at_list,sugg,min_chars=min_chars,max_bytes=max_chars,topn=N)
        def _fit_score(t): by=len(t.encode("utf-8")); fit=(max_chars-by) if by<=max_chars else 999; cov=sum(int(k in t) for k in (sugg[:10] if sugg else [])); return (fit,-cov)
        sorted_titles=sorted(titles,key=_fit_score); primary=sorted_titles[0] if sorted_titles else ""
        if primary:
            by=len(primary.encode("utf-8")); ch=len(primary)
            st.success(f"1ìˆœìœ„ â€” {primary} (ë¬¸ì {ch}/{max_chars} Â· ë°”ì´íŠ¸ {by}/{max_chars})")
        st.divider()
        for i,t in enumerate(sorted_titles,1):
            ch=len(t); by=len(t.encode("utf-8")); warn=[]
            if ch<min_chars: warn.append(f"{min_chars}ì ë¯¸ë§Œ")
            if by>max_chars: warn.append(f"{max_chars}ë°”ì´íŠ¸ ì´ˆê³¼")
            suf="" if not warn else " â€” "+" / ".join([f":red[{w}]" for w in warn])
            st.markdown(f"**{i}.** {t}  <span style='opacity:.7'>(ë¬¸ì {ch}/{max_chars} Â· ë°”ì´íŠ¸ {by}/{max_chars})</span>{suf}", unsafe_allow_html=True)
        st.download_button("ì œëª© CSV", data=pd.DataFrame({"title":sorted_titles}).to_csv(index=False).encode("utf-8-sig"),
                           file_name=f"titles_{main_kw}.csv", mime="text/csv")
    st.markdown("</div>", unsafe_allow_html=True)
def section_11st():
    try:
        from urllib.parse import quote as _q
    except Exception:
        def _q(s, safe=None): return s

    st.markdown('<div class="card main"><div class="card-title">11ë²ˆê°€ (ëª¨ë°”ì¼) â€” ì•„ë§ˆì¡´ ë² ìŠ¤íŠ¸</div>', unsafe_allow_html=True)
    ss = st.session_state
    ss.setdefault("__11st_token", str(int(time.time())))

    c1, c2 = st.columns([1,1])
    with c1:
        if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨ (11ë²ˆê°€)", key="btn_refresh_11st"):
            ss["__11st_token"] = str(int(time.time()))
    with c2:
        st.link_button("ìƒˆíƒ­ì—ì„œ ì—´ê¸° (ì•„ë§ˆì¡´ë² ìŠ¤íŠ¸)", "https://m.11st.co.kr/page/main/abest?tabId=ABEST&pageId=AMOBEST&ctgr1No=166160")

    # ì›Œì»¤ í”„ë¡ì‹œ(ìˆìœ¼ë©´ ì‚¬ìš©)
    base_proxy = (st.secrets.get("ELEVENST_PROXY", "") or globals().get("ELEVENST_PROXY", "")).rstrip("/")
    raw_url = "https://m.11st.co.kr/page/main/abest?tabId=ABEST&pageId=AMOBEST&ctgr1No=166160"

    src_base = raw_url if not base_proxy else f"{base_proxy}/?url={_q(raw_url, safe=':/?&=%')}&ua=mo&js=1&clean=1"
    token = ss["__11st_token"]

    html = f"""
    <style>
      .embed-11st-wrap {{ height: 960px; overflow: hidden; border-radius: 10px; }}
      .embed-11st-wrap iframe {{ width: 100%; height: 100%; border: 0; border-radius: 10px; background: transparent; }}
    </style>
    <div class="embed-11st-wrap"><iframe id="envy_11st_iframe" title="11st"></iframe></div>
    <script>
    (function(){{
        var base = {json.dumps(src_base)};
        var token = {json.dumps(token)};
        var want = base + (base.indexOf('?')>=0 ? '&' : '?') + 'r=' + token;
        var ifr = document.getElementById("envy_11st_iframe");
        if(!ifr) return;
        if(ifr.getAttribute('src') !== want) ifr.setAttribute('src', want);
        window.__ENVY_11ST_SRC = want;
    }})();
    </script>
    """
    st.components.v1.html(html, height=960, scrolling=False)
    st.markdown("</div>", unsafe_allow_html=True)
def section_itemscout_placeholder():
    st.markdown('<div class="card main"><div class="card-title">ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸</div>', unsafe_allow_html=True)
    st.info("ì„ë² ë“œëŠ” ë³´ë¥˜ì…ë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ì›ë³¸ í˜ì´ì§€ë¥¼ ìƒˆ íƒ­ì—ì„œ ì—¬ì„¸ìš”.")
    st.link_button("ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ ì§ì ‘ ì—´ê¸° (ìƒˆ íƒ­)", "https://app.itemscout.io/market/keyword")
    st.markdown('</div>', unsafe_allow_html=True)

def section_sellerlife_placeholder():
    st.markdown('<div class="card main"><div class="card-title">ì…€ëŸ¬ë¼ì´í”„</div>', unsafe_allow_html=True)
    st.info("ì„ë² ë“œëŠ” ë³´ë¥˜ì…ë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ì›ë³¸ í˜ì´ì§€ë¥¼ ìƒˆ íƒ­ì—ì„œ ì—¬ì„¸ìš”.")
    st.link_button("ì…€ëŸ¬ë¼ì´í”„ ì§ì ‘ ì—´ê¸° (ìƒˆ íƒ­)", "https://sellochomes.co.kr/sellerlife/")
    st.markdown('</div>', unsafe_allow_html=True)
def _stopwords_manager_ui(compact: bool = False):
    ss = st.session_state
    ss.setdefault("STOP_GLOBAL", list(STOPWORDS_GLOBAL))
    ss.setdefault("STOP_BY_CAT", dict(STOPWORDS_BY_CAT))
    ss.setdefault("STOP_WHITELIST", [])
    ss.setdefault("STOP_REPLACE", ["ë¬´ë°°=> ", "ë¬´ë£Œë°°ì†¡=> ", "ì •í’ˆ=> "])
    ss.setdefault("STOP_AGGR", False)

    if not compact:
        with st.expander("ğŸ”§ í”„ë¦¬ì…‹", expanded=False):
            preset = st.selectbox("í”„ë¦¬ì…‹", list(STOP_PRESETS.keys()), key="stop_preset_sel")
            if st.button("í”„ë¦¬ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°", key="stop_preset_load"):
                obj = STOP_PRESETS[preset]
                ss["STOP_GLOBAL"]   = list(obj.get("global", []))
                ss["STOP_BY_CAT"]   = dict(obj.get("by_cat", {}))
                ss["STOP_WHITELIST"]= list(obj.get("whitelist", []))
                ss["STOP_REPLACE"]  = list(obj.get("replace", []))
                ss["STOP_AGGR"]     = bool(obj.get("aggressive", False))
                st.success(f"í”„ë¦¬ì…‹ â€˜{preset}â€™ ì ìš© ì™„ë£Œ")

        tab_global, tab_cat, tab_white, tab_replace, tab_io = st.tabs(
            ["ì „ì—­ ê¸ˆì¹™ì–´", "ì¹´í…Œê³ ë¦¬ ê¸ˆì¹™ì–´", "í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸", "ì¹˜í™˜ ê·œì¹™", "ê°€ì ¸ì˜¤ê¸°/ë‚´ë ¤ë°›ê¸°"]
        )

        with tab_global:
            txt = st.text_area("ì „ì—­ ê¸ˆì¹™ì–´ (ì½¤ë§ˆ)", value=",".join(ss["STOP_GLOBAL"]), height=120, key="stop_glob_txt")
            if st.button("ì €ì¥(ì „ì—­)", key="stop_glob_save"):
                ss["STOP_GLOBAL"] = [t.strip() for t in txt.split(",") if t.strip()]
                st.success("ì „ì—­ ê¸ˆì¹™ì–´ ì €ì¥ ì™„ë£Œ")

        with tab_cat:
            all_cats = sorted(set(list(ss["STOP_BY_CAT"].keys()) + list(STOPWORDS_BY_CAT.keys()))) or \
                       ["íŒ¨ì…˜ì˜ë¥˜","íŒ¨ì…˜ì¡í™”","ë·°í‹°/ë¯¸ìš©","ìƒí™œ/ê±´ê°•","ë””ì§€í„¸/ê°€ì „","ìŠ¤í¬ì¸ /ë ˆì €"]
            cat = st.selectbox("ì¹´í…Œê³ ë¦¬", all_cats, key="stop_cat_sel")
            curr = ",".join(ss["STOP_BY_CAT"].get(cat, []))
            new = st.text_area("í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ê¸ˆì¹™ì–´ (ì½¤ë§ˆ)", value=curr, height=120, key=f"stop_cat_txt_{cat}")
            if st.button("ì €ì¥(ì¹´í…Œê³ ë¦¬)", key=f"stop_cat_save_{cat}"):
                ss["STOP_BY_CAT"][cat] = [t.strip() for t in new.split(",") if t.strip()]
                st.success(f"{cat} ì €ì¥ ì™„ë£Œ")
            ss["STOP_AGGR"] = st.toggle("ê³µê²©ì  ë¶€ë¶„ì¼ì¹˜ ì œê±°", value=bool(ss["STOP_AGGR"]), key="stop_aggr_ui")

        with tab_white:
            wt = st.text_area("í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸(í—ˆìš©, ì½¤ë§ˆ)", value=",".join(ss["STOP_WHITELIST"]), height=100, key="stop_white_txt")
            if st.button("ì €ì¥(í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸)", key="stop_white_save"):
                ss["STOP_WHITELIST"] = [t.strip() for t in wt.split(",") if t.strip()]
                st.success("í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ")

        with tab_replace:
            rp = st.text_area("ì¹˜í™˜ ê·œì¹™ (í˜•ì‹: src=>dst, ì½¤ë§ˆ)", value=",".join(ss["STOP_REPLACE"]), height=100, key="stop_repl_txt")
            if st.button("ì €ì¥(ì¹˜í™˜)", key="stop_repl_save"):
                ss["STOP_REPLACE"] = [t.strip() for t in rp.split(",") if t.strip()]
                st.success("ì¹˜í™˜ ê·œì¹™ ì €ì¥ ì™„ë£Œ")

        with tab_io:
            payload = {
                "global": ss["STOP_GLOBAL"],
                "by_cat": ss["STOP_BY_CAT"],
                "whitelist": ss["STOP_WHITELIST"],
                "replace": ss["STOP_REPLACE"],
                "aggressive": bool(ss["STOP_AGGR"]),
            }
            st.download_button("ì„¤ì • ë‚´ë ¤ë°›ê¸°(JSON)",
                               data=json.dumps(payload, ensure_ascii=False, indent=2).encode("utf-8"),
                               file_name="stopwords_profile.json", mime="application/json", key="stop_dl")
            up = st.file_uploader("ì„¤ì • ê°€ì ¸ì˜¤ê¸°(JSON)", type=["json"], key="stop_ul")
            if up:
                try:
                    obj = json.load(io.TextIOWrapper(up, encoding="utf-8"))
                    ss["STOP_GLOBAL"]   = list(obj.get("global", ss["STOP_GLOBAL"]))
                    ss["STOP_BY_CAT"]   = dict(obj.get("by_cat", ss["STOP_BY_CAT"]))
                    ss["STOP_WHITELIST"]= list(obj.get("whitelist", ss["STOP_WHITELIST"]))
                    ss["STOP_REPLACE"]  = list(obj.get("replace", ss["STOP_REPLACE"]))
                    ss["STOP_AGGR"]     = bool(obj.get("aggressive", ss["STOP_AGGR"]))
                    st.success("ì„¤ì • ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ")
                except Exception as e:
                    st.error(f"ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")

def section_stopwords_manager():
    st.markdown('<div class="card main"><div class="card-title">ê¸ˆì¹™ì–´ ë¦¬ìŠ¤íŠ¸ ê´€ë¦¬ì (í˜„ì—…ìš©)</div>', unsafe_allow_html=True)
    _stopwords_manager_ui(compact=False)
# ì‚¬ì´ë“œë°” & ë°˜ì‘í˜•
_ = _sidebar()
_responsive_probe()
vwbin = _get_view_bin()

st.title("ENVY â€” Season 1 (Dual Proxy Edition)")

# 1í–‰: ì¹´í…Œê³ ë¦¬/ì§ì ‘ ì…ë ¥ | ë ˆì´ë” | ìƒí’ˆëª… ìƒì„±ê¸°
row1_a, row1_b, row1_c = st.columns([4, 8, 4], gap="medium")
with row1_a:
    tab_cat, tab_direct = st.tabs(["ì¹´í…Œê³ ë¦¬", "ì§ì ‘ ì…ë ¥"])
    with tab_cat:    section_category_keyword_lab()
    with tab_direct: section_keyword_trend_widget()
with row1_b: section_rakuten_ui()
with row1_c: section_title_generator()
st.markdown('<div class="row-gap"></div>', unsafe_allow_html=True)

# 2í–‰: 11ë²ˆê°€ | ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ | ì…€ëŸ¬ë¼ì´í”„
c1, c2, c3 = st.columns([3, 3, 3], gap="medium")
with c1: section_11st()
with c2: section_itemscout_placeholder()
with c3: section_sellerlife_placeholder()
st.markdown('<div class="row-gap"></div>', unsafe_allow_html=True)
