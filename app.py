# === envy_app.py â€” Part 1 ===
import streamlit as st
import pandas as pd
import requests, time as _t, datetime, re, random
import urllib.parse as _u
from bs4 import BeautifulSoup

# ì™€ì´ë“œ ë ˆì´ì•„ì›ƒ
st.set_page_config(page_title="ENVY Full", layout="wide")

COMMON_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124 Safari/537.36",
    "Accept-Language": "ko,en;q=0.9",
    "Accept": "text/html,application/json;q=0.9,*/*;q=0.8",
}

# ë‹¤í¬ëª¨ë“œ í† ê¸€
if "dark_mode" not in st.session_state:
    st.session_state["dark_mode"] = False
st.session_state["dark_mode"] = st.sidebar.toggle("ğŸŒ— ë‹¤í¬ ëª¨ë“œ", value=st.session_state["dark_mode"], key="toggle_dark")

if st.session_state["dark_mode"]:
    st.markdown("""
    <style>
    body, .stApp { background:#0b1220; color:#e5e7eb; }
    .stDataFrame, .stTable { color:#e5e7eb; }
    </style>
    """, unsafe_allow_html=True)

# í˜ì´ì§€ ì „ì²´ í­ + ì¹´ë“œ ì™€ì´ë“œ
st.markdown("""
<style>
html, body, [data-testid="stAppViewContainer"] > .main {
  max-width: 100vw !important;
  padding-left: 16px !important;
  padding-right: 16px !important;
}
section[data-testid="stSidebar"] .block-container { padding:14px 16px !important; }
section[data-testid="stSidebar"] [data-testid="stVerticalBlock"]{ gap:12px !important; }
[data-testid="stHorizontalBlock"] { gap: 1.25rem !important; }
.envy-card {
  border:1px solid #e5e7eb; border-radius:12px; padding:20px;
  width: 100% !important; max-width: none !important; box-sizing: border-box;
}
.envy-card h3 { margin-top:0; margin-bottom:12px; }
.pill {border-radius:10px; padding:10px 12px; font-weight:700; font-size:14px; margin:6px 0 2px 0; border:1px solid;}
.pill.green  { background:#E6F4EA; color:#0F5132; border-color:#BADBCC; }
.pill.blue   { background:#E7F1FE; color:#0B3D91; border-color:#B6D0FF; }
.pill.yellow { background:#FFF4CC; color:#7A5D00; border-color:#FFE08A; }
.vspace { height:10px; }
</style>
""", unsafe_allow_html=True)

def fmt_money2(x: float) -> str:
    try: return f"{x:,.2f} ì›"
    except Exception: return "0.00 ì›"

def show_pill(where, label: str, value: str, color: str):
    where.markdown(f'<div class="pill {color}">{label}: {value}</div>', unsafe_allow_html=True)

# í”„ë¡ì‹œ ì…ë ¥ í—¬í¼(ì•ˆì „)
def proxy_input(label: str, default_url: str, key: str) -> str:
    return st.text_input(label, value=default_url, key=key)

# ìƒí’ˆëª… ìƒì„±ê¸° ìœ í‹¸
def _sanitize(t: str) -> str:
    return re.sub(r"\s+", " ", (t or "").replace(",", " ")).strip()

def build_titles(brand: str, base_kw: str, rel_candidates: list[dict],
                 ban_set: set[str], max_len: int, k: int = 5) -> list[str]:
    titles = []
    for cand in rel_candidates:
        kw = cand.get("keyword", "")
        if not kw: continue
        title = f"{brand} {base_kw} {kw}"
        if any(b in title.lower() for b in ban_set): continue
        title = _sanitize(title)[:max_len]
        if title and title not in titles: titles.append(title)
        if len(titles) >= k: break
    while len(titles) < k:
        fallback = _sanitize(f"{brand} {base_kw}")[:max_len]
        if fallback and fallback not in titles: titles.append(fallback)
        else: titles.append(_sanitize(brand)[:max_len])
        if len(titles) >= k: break
    return titles
# === envy_app.py â€” Part 2 ===
st.sidebar.header("â‘  í™˜ìœ¨ ê³„ì‚°ê¸°")
rate_map = {"USD": 1400.00, "EUR": 1500.00, "JPY": 9.50, "CNY": 190.00}

fx_cur = st.sidebar.selectbox("ê¸°ì¤€ í†µí™”", list(rate_map.keys()), index=0, key="fx_cur")
fx_rate = rate_map.get(fx_cur, 1400.0)
fx_price = st.sidebar.number_input(f"íŒë§¤ê¸ˆì•¡ ({fx_cur})", 0.0, 1e12, 1.00, 0.01, format="%.2f", key="fx_price")
fx_amount = fx_price * fx_rate
show_pill(st.sidebar, "í™˜ì‚° ê¸ˆì•¡", fmt_money2(fx_amount), "green")

st.sidebar.header("â‘¡ ë§ˆì§„ ê³„ì‚°ê¸° (v23)")
m_cur = st.sidebar.selectbox("ê¸°ì¤€ í†µí™”(íŒë§¤ê¸ˆì•¡)", list(rate_map.keys()), index=0, key="m_cur")
m_rate = rate_map.get(m_cur, 1400.0)
m_price = st.sidebar.number_input(f"íŒë§¤ê¸ˆì•¡ ({m_cur})", 0.0, 1e12, 1.00, 0.01, format="%.2f", key="m_price")
m_fx = m_price * m_rate
show_pill(st.sidebar, "íŒë§¤ê¸ˆì•¡(í™˜ì‚°)", fmt_money2(m_fx), "green")

st.sidebar.markdown('<div class="vspace"></div>', unsafe_allow_html=True)
fee_card   = st.sidebar.number_input("ì¹´ë“œìˆ˜ìˆ˜ë£Œ (%)", 0.00, 100.00, 4.00, 0.01, format="%.2f", key="fee_card")
fee_market = st.sidebar.number_input("ë§ˆì¼“ìˆ˜ìˆ˜ë£Œ (%)", 0.00, 100.00, 14.00, 0.01, format="%.2f", key="fee_market")
ship_cost  = st.sidebar.number_input("ë°°ì†¡ë¹„ (â‚©)",     0.00, 1e12,   0.00, 0.01, format="%.2f", key="ship_cost")
m_type = st.sidebar.radio("ë§ˆì§„ ë°©ì‹", ["í¼ì„¼íŠ¸ ë§ˆì§„(%)","ë”í•˜ê¸° ë§ˆì§„(â‚©)"], 0, key="m_type")
m_val  = st.sidebar.number_input("ë§ˆì§„ìœ¨/ê¸ˆì•¡", 0.00, 1e12, 10.00, 0.01, format="%.2f", key="m_val")

calc_price = m_fx * (1 + fee_card/100 + fee_market/100)
calc_price = calc_price * (1 + m_val/100) if m_type.startswith("í¼ì„¼íŠ¸") else calc_price + m_val
calc_price += ship_cost
profit = calc_price - m_fx
show_pill(st.sidebar, "ì˜ˆìƒ íŒë§¤ê°€", fmt_money2(calc_price), "blue")
show_pill(st.sidebar, "ìˆœì´ìµ(ë§ˆì§„)", fmt_money2(profit), "yellow")
# === envy_app.py â€” Part 3 ===

def _rot_ua():
    pool = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/124 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 Version/17.0 Safari/605.1.15",
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 Chrome/122 Safari/537.36",
    ]
    return random.choice(pool)

def _sleep_jitter(base=0.8, spread=0.6):
    _t.sleep(base + random.random()*spread)

def _proxied_url(proxy:str|None, target:str)->str:
    return f"{proxy}?target=" + _u.quote(target, safe="") if proxy else target

@st.cache_data(ttl=1800, show_spinner=False)
def fetch_datalab_top20(cid: str, start_date: str, end_date: str, proxy: str | None = None) -> pd.DataFrame:
    """ë„¤ì´ë²„ ë°ì´í„°ë© Top20 (í”„ë¡ì‹œ ì§€ì›, ì¿ í‚¤ ì˜ˆì—´, ì¬ì‹œë„, ì‹¤íŒ¨ ì‹œ ë”ë¯¸+ê²½ê³ )"""
    try:
        end = datetime.datetime.strptime(end_date, "%Y-%m-%d").date()
    except:
        end = datetime.date.today()
    yesterday = (end - datetime.timedelta(days=1)).strftime("%Y-%m-%d")

    s = requests.Session()
    entry = "https://datalab.naver.com/shoppingInsight/sCategory.naver"
    headers = {**COMMON_HEADERS, "User-Agent": _rot_ua(), "Referer": entry}

    # 1) ì¿ í‚¤ ì˜ˆì—´
    try: s.get(_proxied_url(proxy, entry), headers=headers, timeout=10)
    except: pass

    # 2) API
    api = "https://datalab.naver.com/shoppingInsight/getCategoryKeywordRank.naver"
    payload = {"cid": cid, "timeUnit":"date", "startDate":start_date, "endDate":yesterday, "device":"pc", "gender":"", "ages":""}
    post_headers = {**headers, "Content-Type":"application/x-www-form-urlencoded; charset=UTF-8", "X-Requested-With":"XMLHttpRequest"}

    last_err = None
    for _ in range(4):
        try:
            r = s.post(_proxied_url(proxy, api), headers=post_headers, data=payload, timeout=12)
            if r.status_code == 200 and r.text.strip():
                js = r.json()
                items = js.get("keywordList", [])
                if items:
                    rows = [{"rank": it.get("rank", i+1), "keyword": it.get("keyword",""), "search": it.get("ratio",0)}
                            for i, it in enumerate(items[:20])]
                    return pd.DataFrame(rows)
                last_err = "empty-list"
            else:
                last_err = f"http-{r.status_code}"
        except Exception as e:
            last_err = str(e)
        _sleep_jitter(0.9, 0.9)

    stub = pd.DataFrame({"rank": [1,2,3,4,5], "keyword": ["í‚¤ì›Œë“œA","í‚¤ì›Œë“œB","í‚¤ì›Œë“œC","í‚¤ì›Œë“œD","í‚¤ì›Œë“œE"], "search":[100,92,88,77,70]})
    stub.attrs["warning"] = f"DataLab í˜¸ì¶œ ì‹¤íŒ¨: {last_err} (í”„ë¡ì‹œ/ê¸°ê°„/CID í™•ì¸)"
    return stub

@st.cache_data(ttl=900, show_spinner=False)
def fetch_amazon_top(region: str = "JP", proxy: str | None = None) -> pd.DataFrame:
    """ì•„ë§ˆì¡´ ë² ìŠ¤íŠ¸ì…€ëŸ¬ (í”„ë¡ì‹œ ì§€ì›, ì§€ì—­í™” í—¤ë”, íŒŒì„œ ë³´ê°•, ì‹¤íŒ¨ ì‹œ ë”ë¯¸+ê²½ê³ )"""
    base = "https://www.amazon.co.jp" if region.upper() == "JP" else "https://www.amazon.com"
    url  = f"{base}/gp/bestsellers"
    hdr = {**COMMON_HEADERS, "User-Agent": _rot_ua()}
    hdr["Accept-Language"] = "ja-JP,ja;q=0.9,en;q=0.8" if region.upper()=="JP" else "en-US,en;q=0.9,ko;q=0.6"

    last_err = None
    for _ in range(3):
        try:
            r = requests.get(_proxied_url(proxy, url), headers=hdr, timeout=12)
            if r.status_code == 200 and r.text:
                soup = BeautifulSoup(r.text, "html.parser")
                titles, sels = [], [
                    ".p13n-sc-truncate",
                    "div._cDEzb_p13n-sc-css-line-clamp-3_g3dy1",
                    "div._cDEzb_p13n-sc-css-line-clamp-2_EWgCb",
                    "span.zg-text-center-align > div > a > div",
                    "a.a-link-normal.a-text-normal",
                    "div.a-section.a-spacing-small.p13n-sc-uncoverable-faceout > a > span",
                ]
                for sel in sels:
                    for el in soup.select(sel):
                        t = re.sub(r"\s+"," ", el.get_text(strip=True))
                        if t and t not in titles: titles.append(t)
                        if len(titles) >= 20: break
                    if len(titles) >= 20: break
                if titles:
                    return pd.DataFrame({"rank": range(1, len(titles)+1), "keyword": titles, "source":[f"Amazon {region.upper()}"]*len(titles)})
                last_err = "empty-parse"
            else:
                last_err = f"http-{r.status_code}"
        except Exception as e:
            last_err = str(e)
        _sleep_jitter(0.8, 0.8)

    df = pd.DataFrame({"rank": [1,2,3,4,5], "keyword":["ìƒ˜í”ŒA","ìƒ˜í”ŒB","ìƒ˜í”ŒC","ìƒ˜í”ŒD","ìƒ˜í”ŒE"], "source":[f"Amazon {region.upper()}"]*5})
    df.attrs["warning"] = f"Amazon íŒŒì‹± ì‹¤íŒ¨: {last_err} (í”„ë¡ì‹œ/ì°¨ë‹¨ ê°€ëŠ¥)"
    return df

# 11ë²ˆê°€ ëª¨ë°”ì¼ ë„ë©”ì¸ ë³´ì •
from urllib.parse import urlparse, urlunparse
def normalize_11st_mobile(url: str) -> str:
    try:
        u = urlparse(url.strip())
        if not u.scheme: u = urlparse("https://" + url.strip())
        host = u.netloc.lower()
        if "11st.co.kr" in host and not host.startswith("m."):
            host = "m.11st.co.kr"
        return urlunparse((u.scheme, host, u.path, u.params, u.query, u.fragment))
    except Exception:
        return "https://m.11st.co.kr"
# === envy_app.py â€” Part 4 ===
st.title("ğŸš€ ENVY v27.13 Full")

# â”€â”€ ìœ—ì¤„: ë°ì´í„°ë© / ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ / ì…€ëŸ¬ë¼ì´í”„
top1, top2, top3 = st.columns([1,1,1], gap="large")

with top1:
    st.markdown('<div class="envy-card">', unsafe_allow_html=True)
    st.markdown("### ë°ì´í„°ë©")
    cid_map = {
        "íŒ¨ì…˜ì˜ë¥˜":"50000002","íŒ¨ì…˜ì¡í™”":"50000001","í™”ì¥í’ˆ/ë¯¸ìš©":"50000007","ë””ì§€í„¸/ê°€ì „":"50000003",
        "ê°€êµ¬/ì¸í…Œë¦¬ì–´":"50000004","ìƒí™œ/ê±´ê°•":"50000005","ì‹í’ˆ":"50000006","ì¶œì‚°/ìœ¡ì•„":"50000008",
        "ìŠ¤í¬ì¸ /ë ˆì €":"50000009","ìë™ì°¨ìš©í’ˆ":"50000100",
    }
    dl_cat = st.selectbox("ì¹´í…Œê³ ë¦¬(10ê°œ)", list(cid_map.keys()), 5, key="dl_cat_main")
    proxy_dl = proxy_input("í”„ë¡ì‹œ(ë°ì´í„°ë©)", "https://envy-proxy.taesig0302.workers.dev", "dl_proxy_main")

    today = datetime.date.today()
    start = (today - datetime.timedelta(days=30)).strftime("%Y-%m-%d")
    end   = today.strftime("%Y-%m-%d")

    if st.button("ë°ì´í„°ë© ì¬ì‹œë„", key="btn_retry_dl"):
        fetch_datalab_top20.clear()

    df_dl = fetch_datalab_top20(cid_map[dl_cat], start, end, proxy_dl if proxy_dl else None)
    warn = getattr(df_dl, "attrs", {}).get("warning")
    if warn: st.warning(warn)
    st.dataframe(df_dl, use_container_width=True, height=260)
    st.caption("â€¢ í”„ë¡ì‹œê°€ POST ë°”ë””/í—¤ë”ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ëŠ” â€˜íˆ¬ëª… í”„ë¡ì‹œâ€™ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
    st.markdown('</div>', unsafe_allow_html=True)

with top2:
    st.markdown('<div class="envy-card"><h3>ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸</h3><p>ì—°ë™ ëŒ€ê¸° (ë³„ë„ API/í”„ë¡ì‹œ)</p></div>', unsafe_allow_html=True)

with top3:
    st.markdown('<div class="envy-card"><h3>ì…€ëŸ¬ë¼ì´í”„</h3><p>ì—°ë™ ëŒ€ê¸° (ë³„ë„ API/í”„ë¡ì‹œ)</p></div>', unsafe_allow_html=True)

# â”€â”€ ì•„ë«ì¤„: AI ë ˆì´ë” / 11ë²ˆê°€ / ìƒí’ˆëª… ìƒì„±ê¸°
bot1, bot2, bot3 = st.columns([1,1,1], gap="large")

with bot1:
    st.markdown('<div class="envy-card">', unsafe_allow_html=True)
    st.markdown("### AI í‚¤ì›Œë“œ ë ˆì´ë”")
    mode = st.radio("ëª¨ë“œ", ["êµ­ë‚´","ê¸€ë¡œë²Œ"], 0, horizontal=True, key="radar_mode_main")

    proxy_amz = proxy_input("í”„ë¡ì‹œ(ì•„ë§ˆì¡´)", "https://envy-proxy.taesig0302.workers.dev", "amz_proxy")
    if st.button("ì•„ë§ˆì¡´ ì¬ì‹œë„", key="btn_retry_amz"):
        fetch_amazon_top.clear()

    if mode == "êµ­ë‚´":
        st.dataframe(df_dl, use_container_width=True, height=300)
    else:
        region = st.selectbox("Amazon ì§€ì—­", ["JP","US"], 0, key="amz_region_main")
        df_amz = fetch_amazon_top(region=region, proxy=proxy_amz if proxy_amz else None)
        warn_amz = getattr(df_amz, "attrs", {}).get("warning")
        if warn_amz: st.warning(warn_amz)
        st.dataframe(df_amz, use_container_width=True, height=300)
        st.caption("â€¢ ë¹„ë¡œê·¸ì¸ ê³µê°œ ë² ìŠ¤íŠ¸ íŒŒì‹±. ì°¨ë‹¨ ì‹œ í”„ë¡ì‹œ/ì‹œê°„ì°¨ ì¬ì‹œë„ ê¶Œì¥.")
    st.markdown('</div>', unsafe_allow_html=True)

with bot2:
    st.markdown('<div class="envy-card">', unsafe_allow_html=True)
    st.markdown("### 11ë²ˆê°€ (ëª¨ë°”ì¼)")
    url_11 = st.text_input("11ë²ˆê°€ URL", "https://www.11st.co.kr/", key="url_11_main")
    mobile_11 = normalize_11st_mobile(url_11)
    st.components.v1.html(
        f"<iframe src='{mobile_11}' width='100%' height='520' style='border:1px solid #e5e7eb;border-radius:10px;' sandbox='allow-scripts allow-forms allow-same-origin allow-popups'></iframe>",
        height=540
    )
    st.markdown('</div>', unsafe_allow_html=True)

with bot3:
    st.markdown('<div class="envy-card">', unsafe_allow_html=True)
    st.markdown("### ìƒí’ˆëª… ìƒì„±ê¸°")
    brand   = st.text_input("ë¸Œëœë“œ", "envy", key="nm_brand_main")
    base_kw = st.text_input("ë² ì´ìŠ¤ í‚¤ì›Œë“œ", "K-coffee mix", key="nm_base_main")
    rel_kw  = st.text_input("ì—°ê´€í‚¤ì›Œë“œ", "Maxim, Kanu, Korea", key="nm_rel_main")
    ban_kw  = st.text_input("ê¸ˆì¹™ì–´", "copy, fake, replica", key="nm_ban_main")
    limit   = st.slider("ê¸€ììˆ˜ ì œí•œ", 10, 100, 80, key="nm_limit_main")

    # ì¶”ì²œìš© ì—°ê´€í‚¤ì›Œë“œ(ê²€ìƒ‰ëŸ‰ìˆ˜)
    rel_candidates = []
    if isinstance(df_dl, pd.DataFrame) and not df_dl.empty:
        rel_candidates = df_dl[['keyword','search']].dropna().head(12).to_dict("records")
    if not rel_candidates:
        tokens = [t.strip() for t in rel_kw.split(",") if t.strip()]
        rel_candidates = [{"keyword": t, "search": None} for t in tokens]

    st.markdown("#### ì¶”ì²œìš© ì—°ê´€í‚¤ì›Œë“œ (ê²€ìƒ‰ëŸ‰ìˆ˜)")
    df_reco = pd.DataFrame(rel_candidates)
    if not df_reco.empty:
        df_show = df_reco.rename(columns={"keyword":"ì—°ê´€í‚¤ì›Œë“œ","search":"ê²€ìƒ‰ëŸ‰ìˆ˜/ìŠ¤ì½”ì–´"})
        st.dataframe(df_show, use_container_width=True, height=210)

    if st.button("ì œëª© ìƒì„±", key="nm_gen_main"):
        ban_set = {b.strip().lower() for b in ban_kw.split(",") if b.strip()}
        titles = build_titles(brand, base_kw, rel_candidates, ban_set, limit, k=5)
        st.markdown("#### ì¶”ì²œ ì œëª© 5ê°€ì§€")
        for i, t in enumerate(titles, 1):
            st.code(f"{i}. {t}")
    st.markdown('</div>', unsafe_allow_html=True)
