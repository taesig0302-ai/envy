
# -*- coding: utf-8 -*-
# ENVY v21 â€” Layout & features per request

import os, re, math
from datetime import datetime, timedelta
from typing import List, Tuple
import requests
import pandas as pd
from bs4 import BeautifulSoup
import altair as alt
import streamlit as st

st.set_page_config(page_title="ENVY", page_icon="ğŸ¦Š", layout="wide")

# ---------- Branding ----------
st.markdown(r"""
<style>
.block-container { padding-top: 0.4rem; }
header, footer { visibility: hidden; height: 0; }
.topbar { display:flex; align-items:center; justify-content:space-between; gap:12px; margin:4px 0 10px 0; }
.brand { font-size:22px; font-weight:800; }
.badge { background:#111827; color:#fff; padding:2px 8px; border-radius:8px; font-size:12px; }
.note { font-size:12px; opacity:.7; }
.iframe-wrap { position:relative; width:100%; padding-top: 62%; border:1px solid rgba(0,0,0,.1); border-radius:8px; overflow:hidden; }
.iframe-wrap iframe { position:absolute; top:0; left:0; width:100%; height:100%; border:0; }
</style>
""", unsafe_allow_html=True)
st.markdown(r"""
<div class="topbar">
  <div class="brand">ENVY <span class="badge">v21</span></div>
  <div class="note">ì†Œì‹± Â· í‚¤ì›Œë“œ Â· ê°€ê²©</div>
</div>
""", unsafe_allow_html=True)

REQ_HEADERS = {"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"}

@st.cache_data(ttl=1800)
def fetch_html(url: str, timeout=12) -> str:
    r = requests.get(url, headers=REQ_HEADERS, timeout=timeout)
    r.raise_for_status()
    return r.text

def count_kor_bytes(text: str) -> Tuple[int,int]:
    chars = len(text)
    b = 0
    for ch in text:
        if re.match(r"[ã„±-í£]", ch): b += 3
        else: b += len(ch.encode("utf-8"))
    return chars, b

def apply_rules(t: str, rules: List[Tuple[str,str]]) -> str:
    for bad, repl in rules:
        t = re.sub(re.escape(bad), repl, t, flags=re.IGNORECASE)
    return " ".join(t.split())

def wt_recent(df: pd.DataFrame, col="ratio", w7=0.6, w3=0.3, w1=0.1) -> float:
    if df.empty: return 0.0
    s1 = df[col].tail(1).sum()
    s3 = df[col].tail(3).sum()
    s7 = df[col].tail(7).sum()
    return w7*s7 + w3*s3 + w1*s1

# ---------- Sidebar: í™˜ìœ¨ Â· ë§ˆì§„(ë‘ ëª¨ë“œ) ----------
st.sidebar.markdown("### âš™ï¸ ë§ˆì§„ ê³„ì‚°ê¸°")

cur_amt = st.sidebar.number_input("í˜„ì§€ ê¸ˆì•¡", min_value=0.0, value=0.0, step=1.0)
cur_code = st.sidebar.selectbox("í˜„ì§€ í†µí™”", ["USD","EUR","JPY","CNY"], index=0)
ship_domestic = st.sidebar.number_input("êµ­ì œë°°ì†¡ë¹„(=êµ­ë‚´ë°°ì†¡ë¹„)", min_value=0.0, value=0.0, step=100.0)
fee_card = st.sidebar.number_input("ì¹´ë“œ ìˆ˜ìˆ˜ë£Œ(%)", min_value=0.0, value=4.0, step=0.5)
fee_market = st.sidebar.number_input("ë§ˆì¼“ ìˆ˜ìˆ˜ë£Œ(%)", min_value=0.0, value=15.0, step=0.5)

margin_mode = st.sidebar.radio("ë§ˆì§„ ë°©ì‹", ["í¼ì„¼íŠ¸ë§ˆì§„(%)", "ë”í•˜ê¸°ë§ˆì§„(ì›)"], horizontal=False)
target_margin_pct = st.sidebar.number_input("ëª©í‘œ ë§ˆì§„(%)", min_value=0.0, value=40.0, step=1.0, disabled=(margin_mode!="í¼ì„¼íŠ¸ë§ˆì§„(%)"))
target_add_krw = st.sidebar.number_input("ë”í•˜ê¸° ë§ˆì§„(ì›)", min_value=0.0, value=0.0, step=100.0, disabled=(margin_mode!="ë”í•˜ê¸°ë§ˆì§„(ì›)"))

CC = {"USD":1391.7, "EUR":1510.0, "JPY":9.2, "CNY":191.3}
KRW_cost = cur_amt * CC[cur_code]
C_total = KRW_cost + ship_domestic
r_card = max(0.0, 1 - fee_card/100.0)
r_market = max(0.0, 1 - fee_market/100.0)

if margin_mode == "í¼ì„¼íŠ¸ë§ˆì§„(%)":
    r_margin = max(0.0, 1 - target_margin_pct/100.0)
    denom = r_card * r_market * r_margin
    est_sell = (C_total / denom) if denom > 0 else 0.0
else:
    denom = r_card * r_market
    est_sell = (C_total + target_add_krw) / denom if denom > 0 else 0.0

real_margin = est_sell - C_total
real_margin_rate = (real_margin / est_sell * 100) if est_sell else 0
st.sidebar.metric("ì˜ˆìƒ íŒë§¤ê°€", f"â‚©{est_sell:,.0f}")
st.sidebar.metric("ì˜ˆìƒ ìˆœì´ìµ(ë§ˆì§„)", f"â‚©{real_margin:,.0f} / {real_margin_rate:.1f}%")

# ---------- Top Row: DataLab / Itemscout / Recent-3d ----------
c1, c2, c3 = st.columns([1.6, 1.2, 1.0])

with c1:
    st.markdown("#### ğŸ“Š ë„¤ì´ë²„ ë°ì´í„°ë© â€” Top20 + íŠ¸ë Œë“œ")
    with st.expander("API í‚¤ ì„¤ì •", expanded=False):
        cid = st.text_input("Client ID", value=os.getenv("NAVER_CLIENT_ID",""))
        csec = st.text_input("Client Secret", value=os.getenv("NAVER_CLIENT_SECRET",""), type="password")
        st.caption("â€» í‚¤ ë¯¸ì…ë ¥ì‹œ ë°ëª¨ ì‹œë“œë¡œ ë™ì‘")

    cat = st.selectbox("ì¹´í…Œê³ ë¦¬", ["íŒ¨ì…˜ì˜ë¥˜","í™”ì¥í’ˆ/ë¯¸ìš©","ì‹í’ˆ","ìŠ¤í¬ì¸ /ë ˆì €","ìƒí™œ/ê±´ê°•","ë””ì§€í„¸/ê°€ì „","ì¶œì‚°/ìœ ì•„ë™","ê°€êµ¬/ì¸í…Œë¦¬ì–´","ë°˜ë ¤ë™ë¬¼","ë¬¸êµ¬/ì·¨ë¯¸"], index=0)
    period = st.radio("ê¸°ê°„", ["30ì¼","60ì¼","90ì¼"], horizontal=True, index=0)
    days = int(period.replace("ì¼",""))
    end_date = datetime.today().date()
    start_date = end_date - timedelta(days=days-1)

    SEED = {
        "íŒ¨ì…˜ì˜ë¥˜": ["ë§¨íˆ¬ë§¨","ìŠ¬ë™ìŠ¤","ì²­ë°”ì§€","ê°€ë””ê±´","ë¡±ìŠ¤ì»¤íŠ¸","ë¶€ì¸ ì»·","ì™€ì´ë“œíŒ¬ì¸ ","ì¡°ê±°íŒ¬ì¸ ","ë‹ˆíŠ¸","ì…”ì¸ ","ë¸”ë ˆì´ì €","í›„ë“œì§‘ì—…","ë¡±ì›í”¼ìŠ¤","íŠ¸ë ˆì´ë‹","ì—°ì²­ë°”ì§€","í‘ì²­ë°”ì§€","ìŠ¬ë¦¼í•","Aë¼ì¸ ìŠ¤ì»¤íŠ¸","ë‹ˆíŠ¸ì¡°ë¼","ë³´ì´í•"],
        "í™”ì¥í’ˆ/ë¯¸ìš©": ["ì¿ ì…˜","ì„ í¬ë¦¼","ë¦½ë°¤","ì•„ì´ì„€ë„ìš°","í´ë Œì§•í¼","ë§ˆìŠ¤ì¹´ë¼","ë¦½í‹´íŠ¸","í”„ë¼ì´ë¨¸","í† ë„ˆ","ì—ì„¼ìŠ¤","ì•°í”Œ","í”½ì„œ","ë¦½ì˜¤ì¼","ë¦½ê¸€ë¡œìŠ¤","ì•„ì´ë¸Œë¡œìš°","ì‰ì´ë”©","í•˜ì´ë¼ì´í„°","ë¸”ëŸ¬ì…”","ì„¸ëŸ¼","í´ë Œì§•ì˜¤ì¼"],
        "ì‹í’ˆ": ["ë¼ë©´","ì»¤í”¼","ì°¸ì¹˜","ìŠ¤íŒ¸","ì ¤ë¦¬","ê°„ì‹","ê³¼ì","ì´ˆì½œë¦¿","ê¹€","ê²¬ê³¼","ì‹œë¦¬ì–¼","ê³¼ì¼","ê¹€ìë°˜","í–‡ë°˜","ì¦‰ì„êµ­","ë§Œë‘","ì¹˜ì¦ˆ","ìš°ìœ ","ìš”ê±°íŠ¸","ì‹ë¹µ"],
        "ìŠ¤í¬ì¸ /ë ˆì €": ["ëŸ°ë‹í™”","ìš”ê°€ë§¤íŠ¸","í…Œë‹ˆìŠ¤ê³µ","ë°°ë“œë¯¼í„´ë¼ì¼“","ì¶•êµ¬ê³µ","í—¬ìŠ¤ì¥ê°‘","ë¬´ë¦ë³´í˜¸ëŒ€","ìˆ˜ì˜ëª¨","ìŠ¤ë…¸í´","ìì „ê±°ì¥ê°‘","ìŠ¤í¬ì¸ ì–‘ë§","ë¼ì¼“ê°€ë°©","í•˜í”„íŒ¬ì¸ ","í”¼í´ë³¼","ì›Œí‚¹í™”","í—¬ìŠ¤ë²¨íŠ¸","ë¤ë²¨","í¼ë¡¤ëŸ¬","ë³´í˜¸ëŒ€","ë°°ë“œë¯¼í„´ê³µ"],
        "ìƒí™œ/ê±´ê°•": ["í–‰ì£¼","ìˆ˜ì„¸ë¯¸","ë¹¨ë˜ë°”êµ¬ë‹ˆ","ì„¸íƒë§","ë¬¼í‹°ìŠˆ","ìˆ˜ë‚©í•¨","íœ´ì§€í†µ","ë°©í–¥ì œ","ì²­ì†Œê¸°","í•„í„°","ì œìŠµì œ","ë°©ì¶©ì œ","ê³ ë¬´ì¥ê°‘","ìš•ì‹¤í™”","ë°œë§¤íŠ¸","ì¹«ì†”","ì¹˜ì•½","ìƒ´í‘¸","ë¦°ìŠ¤","ë°”ë””ì›Œì‹œ"],
        "ë””ì§€í„¸/ê°€ì „": ["ë¬´ì„ ë§ˆìš°ìŠ¤","í‚¤ë³´ë“œ","ì¶©ì „ê¸°","Cíƒ€ì…ì¼€ì´ë¸”","í—ˆë¸Œ","USB","SSD","HDD","ëª¨ë‹ˆí„°ì•”","ì›¹ìº ","ë§ˆì´í¬","í—¤ë“œì…‹","ìŠ¤í”¼ì»¤","íƒœë¸”ë¦¿ê±°ì¹˜ëŒ€","ëª¨ë°”ì¼ë°°í„°ë¦¬","ê³µìœ ê¸°","ëœì¹´ë“œ","ë¼ìš°í„°","TVìŠ¤í‹±","ë¡œë´‡ì²­ì†Œê¸°"],
        "ì¶œì‚°/ìœ ì•„ë™": ["ê¸°ì €ê·€","ë¬¼í‹°ìŠˆ","ì –ë³‘","ìœ ì‚°ê· ","ë¶„ìœ ","ì•„ê¸°ì„¸ì œ","ì•„ê¸°ë¡œì…˜","ì•„ê¸°ìˆ˜ê±´","ì•„ê¸°ìš•ì¡°","í„±ë°›ì´","ì¹˜ë°œê¸°","ì½§ë¬¼í¡ì…ê¸°","ì²´ì˜¨ê³„","ìŠ¬ë¦½ìˆ˜íŠ¸","ì –ë³‘ì†Œë…ê¸°","ì•„ê¸°ë² ê°œ","ìœ ëª¨ì°¨ê±¸ì´","íœ´ëŒ€ìš©ê¸°ì €ê·€","ë³´ì˜¨ë³‘","ì»µ"],
        "ê°€êµ¬/ì¸í…Œë¦¬ì–´": ["ëŸ¬ê·¸","ì¿ ì…˜","ì»¤íŠ¼","ë¸”ë¼ì¸ë“œ","ê±°ìš¸","ìˆ˜ë‚©ì¥","ì„ ë°˜","í–‰ê±°","ì±…ìƒ","ì˜ì","ìŠ¤íˆ´","ì‚¬ì´ë“œí…Œì´ë¸”","ì‹íƒë“±","LEDë“±","ë””í“¨ì €","ì•¡ì","ì¹¨ëŒ€ì»¤ë²„","ì´ë¶ˆì»¤ë²„","ë² ê°œì»¤ë²„","ë¬´ë“œë“±"],
        "ë°˜ë ¤ë™ë¬¼": ["ë°°ë³€íŒ¨ë“œ","ê±´ì‹ì‚¬ë£Œ","ìŠµì‹ì‚¬ë£Œ","ê°„ì‹ìŠ¤í‹±","ì¸„ë¥´","ìº£ë‹¢","ì¥ë‚œê°","í•˜ë„¤ìŠ¤","ë¦¬ë“œì¤„","ìŠ¤í¬ë˜ì³","ìº£íƒ€ì›Œ","ëª¨ë˜","ë§¤íŠ¸","ê¸‰ì‹ê¸°","ê¸‰ìˆ˜ê¸°","ë°©ì„","í•˜ìš°ìŠ¤","ë¸ŒëŸ¬ì‹œ","ë°œí†±ê¹ì´","ë¯¸ìš©ê°€ìœ„"],
        "ë¬¸êµ¬/ì·¨ë¯¸": ["ì ¤íœ","ë³¼íœ","ë…¸íŠ¸","ë‹¤ì´ì–´ë¦¬","í¬ìŠ¤íŠ¸ì‡","í˜•ê´‘íœ","ìˆ˜ì±„í™”ë¬¼ê°","íŒ”ë ˆíŠ¸","ë§ˆì¹´","ì—°í•„","ì§€ìš°ê°œ","ìŠ¤ì¼€ì¹˜ë¶","ì»¬ëŸ¬ë§ë¶","í‚¤íŠ¸","í¼ì¦","ë³´ë“œê²Œì„","í…Œì´í”„ì»¤í„°","ì»¤íŒ…ë§¤íŠ¸","ë„ì•ˆì§‘","í´ë¦½"],
    }

    @st.cache_data(ttl=900)
    def datalab_search_trend(client_id: str, client_secret: str, keywords: List[str], start: str, end: str) -> pd.DataFrame:
        url = "https://openapi.naver.com/v1/datalab/search"
        headers = {"X-Naver-Client-Id": client_id, "X-Naver-Client-Secret": client_secret, "Content-Type":"application/json"}
        groups = [{"groupName": kw, "keywords":[kw]} for kw in keywords]
        body = {"startDate": start, "endDate": end, "timeUnit":"date", "keywordGroups": groups, "device":"pc,mobile", "ages":[], "gender":""}
        r = requests.post(url, headers=headers, json=body, timeout=10)
        r.raise_for_status()
        js = r.json()
        rows = []
        for res in js.get("results", []):
            kw = res.get("title")
            for point in res.get("data", []):
                rows.append({"keyword": kw, "date": point["period"], "ratio": point["ratio"]})
        df = pd.DataFrame(rows)
        if not df.empty:
            df["date"] = pd.to_datetime(df["date"])
        return df

    try:
        if cid and csec:
            df_ts = datalab_search_trend(cid, csec, SEED[cat], (datetime.today()-timedelta(days=days-1)).date().isoformat(), datetime.today().date().isoformat())
            tops = []
            for kw, g in df_ts.groupby("keyword"):
                tops.append({"keyword": kw, "score_recent": round(wt_recent(g, "ratio"), 2)})
            df_top = pd.DataFrame(tops).sort_values("score_recent", ascending=False).head(20).reset_index(drop=True)
            df_top.index = df_top.index + 1
            st.success("API ëª¨ë“œ: ìµœê·¼ì„± ê°€ì¤‘ Top20")
        else:
            raise RuntimeError("í‚¤ ë¯¸ì…ë ¥")
    except Exception as e:
        st.warning(f"API ë¯¸ì‚¬ìš©/ì‹¤íŒ¨ â†’ ë°ëª¨ Top20 ì‚¬ìš© ({e})")
        df_top = pd.DataFrame({"keyword": SEED[cat][:20]})
        df_top["score_recent"] = 0.0
        df_top.index = df_top.index + 1

    st.dataframe(df_top.rename_axis("rank").reset_index(), use_container_width=True, hide_index=True)

    # ì˜¤ë¥¸ìª½ ì‘ì€ ê·¸ë˜í”„(Top5 ë¼ì¸) â€” íŒ¨ë„ ì•ˆ í‘œì‹œ (expander X)
    if cid and csec and not df_top.empty:
        pick = df_top["keyword"].head(5).tolist()
        frames = []
        for kw in pick:
            dfp = datalab_search_trend(cid, csec, [kw], (datetime.today()-timedelta(days=days-1)).date().isoformat(), datetime.today().date().isoformat())
            dfp["keyword"] = kw
            frames.append(dfp)
        if frames:
            df_plot = pd.concat(frames)
            chart = alt.Chart(df_plot).mark_line().encode(
                x="date:T", y="ratio:Q", color="keyword:N", tooltip=["keyword:N","date:T","ratio:Q"]
            ).properties(height=200).interactive()
            st.altair_chart(chart, use_container_width=True)
    else:
        st.caption("API í‚¤ ì…ë ¥ ì‹œ íŠ¸ë Œë“œ ê·¸ë˜í”„ í‘œì‹œ")

with c2:
    st.markdown("#### ğŸ” ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ â€” CSV/HTML")
    csvfile = st.file_uploader("CSV ì—…ë¡œë“œ (ë‚´ë³´ë‚´ê¸° íŒŒì¼)", type=["csv"], key="is_csv_v21")
    if csvfile:
        try:
            df_is = pd.read_csv(csvfile)
            st.dataframe(df_is.head(50), use_container_width=True)
        except Exception as e:
            st.error(f"CSV íŒŒì‹± ì‹¤íŒ¨: {e}")
    html_txt = st.text_area("HTML ì†ŒìŠ¤ ë¶™ì—¬ë„£ê¸°", height=120, key="is_html_v21")
    if st.button("HTMLì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ", key="is_btn_v21"):
        try:
            soup = BeautifulSoup(html_txt, "html.parser")
            texts = [t.get_text(" ", strip=True) for t in soup.find_all(["a","span","div"])]
            from collections import Counter
            cand = []
            for t in texts:
                if 1 <= len(t) <= 30 and re.search(r"[ê°€-í£A-Za-z]", t):
                    cand.append(t)
            cnt = Counter(cand)
            df_html_kw = pd.DataFrame(cnt.most_common(50), columns=["keyword","freq"])
            st.dataframe(df_html_kw, use_container_width=True)
        except Exception as e:
            st.error(f"ì¶”ì¶œ ì‹¤íŒ¨: {e}")

with c3:
    st.markdown("#### ğŸ† ìµœê·¼ 3ì¼ ë² ìŠ¤íŠ¸ (Placeholder)")
    demo_b3 = pd.DataFrame({
        "#": list(range(1,11)),
        "ìƒí’ˆëª…": [f"ë°ëª¨ ìƒí’ˆ {i}" for i in range(1,11)],
        "ê°€ê²©": [i*10000 for i in range(1,11)]
    })
    st.dataframe(demo_b3, use_container_width=True, hide_index=True)

# ---------- Bottom Row: 11ë²ˆê°€ / ì†Œì‹± ë ˆì´ë” / íƒ€ì´í‹€ ----------
b1, b2 = st.columns([1.4, 1.6])

with b1:
    st.markdown("#### ğŸ›ï¸ 11ë²ˆê°€ ì•„ë§ˆì¡´ ë² ìŠ¤íŠ¸ (ëª¨ë°”ì¼ â€” ìš”ì•½ í‘œ)")
    url_11 = st.text_input("URL", value="https://m.11st.co.kr/MW/html/main.html", key="u11_v21")
    if st.button("ë¶ˆëŸ¬ì˜¤ê¸°", key="u11_btn_v21"):
        try:
            html = fetch_html(url_11)
            soup = BeautifulSoup(html, "html.parser")
            items = []
            selectors = ["li", "div"]
            for sel in selectors:
                for li in soup.select(sel):
                    txt = li.get_text(" ", strip=True)
                    if not txt: continue
                    m = re.search(r"(\d{1,3}(?:,\d{3})+)\s*ì›", txt)
                    price = int(m.group(1).replace(",","")) if m else None
                    a = li.find("a", href=True)
                    link = ""
                    if a:
                        href = a["href"]
                        link = ("https:" + href) if href.startswith("//") else href
                    img = li.find("img")
                    thumb = img["src"] if img and img.has_attr("src") else ""
                    items.append({"ìƒí’ˆëª…": txt[:120], "ê°€ê²©": price, "ë§í¬": link, "ì¸ë„¤ì¼": thumb})
                    if len(items) >= 100: break
                if items: break
            df11 = pd.DataFrame(items)
            if df11.empty:
                st.warning("íŒŒì‹± ê²°ê³¼ê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤. (êµ¬ì¡°ë³€ê²½/ì°¨ë‹¨ ê°€ëŠ¥)")
            else:
                st.dataframe(df11, use_container_width=True, hide_index=True)
                st.download_button("CSV ë‹¤ìš´ë¡œë“œ", data=df11.to_csv(index=False).encode("utf-8-sig"), file_name="11st_best.csv", mime="text/csv")
        except Exception as e:
            st.error(f"ìš”ì²­ ì‹¤íŒ¨: {e}")
    st.caption("â€» ì§ì ‘ ì„ë² ë“œëŠ” ì •ì±…ìƒ ì°¨ë‹¨ë  ìˆ˜ ìˆì–´ ìš”ì•½í‘œë¡œ ëŒ€ì²´.")

with b2:
    st.markdown("#### ğŸ§­ AI ì†Œì‹± ë ˆì´ë” â€” ì ìˆ˜")
    # ë ˆì´ë” ê³„ì‚°: ë°ì´í„°ë© Top20 ì ìˆ˜ + ë…¸ì¶œ ê°€ì¤‘ì¹˜
    if 'df_top' in locals() and not df_top.empty:
        df_kw_score = df_top[["keyword","score_recent"]].copy()
        expo_w = st.slider("ë…¸ì¶œ ê°€ì¤‘ì¹˜(11ë²ˆê°€)", 0.0, 20.0, 10.0, 1.0)
        df_kw_score["score"] = df_kw_score["score_recent"] + expo_w
        df_kw_score = df_kw_score.sort_values("score", ascending=False).reset_index(drop=True)
        st.dataframe(df_kw_score.head(20), use_container_width=True)
        ch = alt.Chart(df_kw_score.head(15)).mark_bar().encode(
            x=alt.X("score:Q", title="score"),
            y=alt.Y("keyword:N", sort="-x", title="keyword"),
            tooltip=["keyword","score"]
        ).properties(height=240)
        st.altair_chart(ch, use_container_width=True)
    else:
        st.info("ë°ì´í„°ë© Top20ì´ ìƒì„±ë˜ë©´ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.")

# ---- íƒ€ì´í‹€ ìƒì„±ê¸° + ê¸ˆì¹™ì–´ (í•˜ë‹¨ ì „ì²´ í­) ----
st.markdown("#### âœï¸ ìƒí’ˆëª… ìƒì„±ê¸° + ğŸš« ê¸ˆì¹™ì–´")
brand = st.text_input("ë¸Œëœë“œ", value="", key="brand_v21")
base = st.text_input("ê¸°ë³¸ ë¬¸ì¥", value="", key="base_v21")
kw_raw = st.text_input("í‚¤ì›Œë“œ(,)", value="ìŠ¬ë™ìŠ¤, ì™€ì´ë“œ, ê¸°ëª¨", key="kraw_v21")
limit_chars = st.number_input("ìµœëŒ€ ê¸€ììˆ˜", 1, 120, 50, key="lchars_v21")
limit_bytes = st.number_input("ìµœëŒ€ ë°”ì´íŠ¸ìˆ˜", 1, 200, 80, key="lbytes_v21")

if "ban_df" not in st.session_state:
    st.session_state["ban_df"] = pd.DataFrame({"ê¸ˆì¹™ì–´":["ë¬´ë£Œë°°ì†¡","ì¦ì •","ì´ˆíŠ¹ê°€"],"ëŒ€ì²´ì–´":["","","íŠ¹ê°€"]})
ban_df = st.data_editor(st.session_state["ban_df"], num_rows="dynamic", use_container_width=True, key="bandf_v21")
st.session_state["ban_df"] = ban_df
rules = [(r["ê¸ˆì¹™ì–´"], r["ëŒ€ì²´ì–´"]) for _, r in ban_df.dropna().iterrows() if r["ê¸ˆì¹™ì–´"]]

def gen_titles(brand, base, kws, rules, limit_chars, limit_bytes, n=5):
    out = []
    for i in range(n):
        kk = kws[i:] + kws[:i]
        title = " ".join([brand, base, " ".join(kk)]).strip()
        title = apply_rules(title, rules)
        ch, bt = count_kor_bytes(title)
        while (ch > limit_chars or bt > limit_bytes) and kk:
            kk = kk[:-1]
            title = " ".join([brand, base, " ".join(kk)]).strip()
            title = apply_rules(title, rules)
            ch, bt = count_kor_bytes(title)
        out.append({"ì œëª©": title, "ê¸€ììˆ˜": ch, "ë°”ì´íŠ¸": bt})
    return pd.DataFrame(out)

if st.button("ì œëª© 5ê°œ ìƒì„±", key="gent_v21"):
    kws = [k.strip() for k in kw_raw.split(",") if k.strip()]
    df_titles = gen_titles(brand, base, kws, rules, limit_chars, limit_bytes, n=5)
    st.dataframe(df_titles, use_container_width=True, hide_index=True)

st.caption("Â© ENVY v21 â€” Classic UI + ìš”êµ¬ ë°˜ì˜")
