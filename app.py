# -*- coding: utf-8 -*-
# ENVY â€” Season 1 (Dual Proxy Edition, Radar tabs=êµ­ë‚´/í•´ì™¸, Rakuten scope radio removed, row1 ratio 8:5:3)
# ì´ë²ˆ ë²„ì „:
# - ìƒí’ˆëª… ìƒì„±ê¸° ì¹´ë“œ ë‚´ë¶€ íƒ­: [ìƒì„±ê¸° | ê¸ˆì¹™ì–´ ê´€ë¦¬]
# - ì™¸ë¶€ ê¸ˆì¹™ì–´ ì„¹ì…˜ì€ ìœ ì§€(ì„ íƒ). ë™ì¼ ì„¸ì…˜í‚¤ ê³µìœ ë¡œ ë™ê¸°í™”ë¨.
# - ì‚¬ì´ë“œë°”: ë‹¤í¬+ë²ˆì—­ê¸° í† ê¸€ / ë²ˆì—­ê¸° ON: ë²ˆì—­ê¸° í¼ì¹¨Â·ê³„ì‚°ê¸° ì ‘í˜, OFF: ê³„ì‚°ê¸° í¼ì¹¨Â·ë²ˆì—­ê¸° ì ‘í˜
# - ë‹¤í¬ëª¨ë“œ ì‹œì•ˆì„± íŒ¨ì¹˜(ë©”ì¸ì˜ì—­ ìœ„ì ¯ ì „ë¶€ ìƒ‰ìƒ ë°˜ì „) + ë¼ì´íŠ¸ ëª¨ë“œ ëŒ€ë¹„ ê°•í™”
# - ë„¤ì´ë²„ í‚¤ì›Œë“œë„êµ¬ ì‹¤íŒ¨ ì‹œ ê°„ë‹¨ ë””ë²„ê·¸ ë©”ì‹œì§€ í‘œì‹œ

import base64, time, re, math, json, io, datetime as dt
from pathlib import Path
from urllib.parse import quote

import pandas as pd
import streamlit as st

# -------- Optional imports --------
try:
    import requests
except Exception:
    requests = None

try:
    from deep_translator import GoogleTranslator
except Exception:
    GoogleTranslator = None

st.set_page_config(page_title="ENVY â€” Season 1 (Dual Proxy Edition)", layout="wide")

# =========================
# 0) GLOBALS & DEFAULT KEYS
# =========================
SHOW_ADMIN_BOX = False

# Proxies (Cloudflare Worker)
NAVER_PROXY      = "https://envy-proxy.taesig0302.workers.dev"
ELEVENST_PROXY   = "https://worker-11stjs.taesig0302.workers.dev"
ITEMSCOUT_PROXY  = "https://worker-itemscoutjs.taesig0302.workers.dev"
SELLERLIFE_PROXY = "https://worker-sellerlifejs.taesig0302.workers.dev"

# ---- Default credentials (secrets ê°€ ìˆìœ¼ë©´ secrets ìš°ì„ ) ----
DEFAULT_KEYS = {
    # Rakuten
    "RAKUTEN_APP_ID": "1043271015809337425",
    "RAKUTEN_AFFILIATE_ID": "4c723498.cbfeca46.4c723499.1deb6f77",

    # NAVER Searchad(ê²€ìƒ‰ê´‘ê³  API / í‚¤ì›Œë“œë„êµ¬)
    "NAVER_API_KEY": "0100000000785cf1d8f039b13a5d3c3d1262b84e9ad4a046637e8887bbd003051b0d2a5cdf",
    "NAVER_SECRET_KEY": "AQAAAAB4XPHY8DmxOl08PRJiuE6ao1LN3lh0kF9rOJ4m5b8O5g==",
    "NAVER_CUSTOMER_ID": "2274338",

    # NAVER Developers (DataLab Open API)  â† ì—¬ê¸° ìµœì‹ ê°’ìœ¼ë¡œ êµì²´
    "NAVER_CLIENT_ID": "T27iw3tyujrM1nG_shFT",
    "NAVER_CLIENT_SECRET": "s59xKPYLz1",

    # ì„ íƒ: DataLab Referer(í—ˆìš© ë„ë©”ì¸ ë“±ë¡ ì‹œ) â€” í•„ìš” ì—†ìœ¼ë©´ ë¹„ì›Œë‘ê¸°
    "NAVER_WEB_REFERER": ""

    # (ì˜µì…˜) DataLab Refererê°€ í•„ìš”í•œ í™˜ê²½ì´ë©´ secrets.toml ì— NAVER_WEB_REFERER ë¥¼ ë„£ì–´ë„ ë¨
}
def _get_key(name: str) -> str:
    return (st.secrets.get(name, "") or DEFAULT_KEYS.get(name, "")).strip()

# Simple FX
CURRENCIES = {
    "USD":{"kr":"ë¯¸êµ­ ë‹¬ëŸ¬","symbol":"$","unit":"USD"},
    "EUR":{"kr":"ìœ ë¡œ","symbol":"â‚¬","unit":"EUR"},
    "JPY":{"kr":"ì¼ë³¸ ì—”","symbol":"Â¥","unit":"JPY"},
    "CNY":{"kr":"ì¤‘êµ­ ìœ„ì•ˆ","symbol":"å…ƒ","unit":"CNY"},
}
FX_DEFAULT = {"USD":1400.0,"EUR":1500.0,"JPY":10.0,"CNY":200.0}

# =========================
# Stopwords â€” ì „ì—­/ì¹´í…Œê³ ë¦¬ + í”„ë¦¬ì…‹
# =========================
STOPWORDS_GLOBAL = [
    # ê´‘ê³ /í–‰ì‚¬/ê°€ê²© ê³¼ì¥
    "ë¬´ë£Œë°°ì†¡","ë¬´ë°°","ì´ˆíŠ¹ê°€","íŠ¹ê°€","í•«ë”œ","ìµœì €ê°€","ì„¸ì¼","sale","ì´ë²¤íŠ¸","ì‚¬ì€í’ˆ","ì¦ì •",
    "ì¿ í°","ì—­ëŒ€ê¸‰","ì—­ëŒ€ê°€","í­íƒ„ì„¸ì¼","ì›ê°€","ì •ê°€","íŒŒê²©","ì´ˆëŒ€ë°•","í• ì¸í­","í˜œíƒê°€",
    # ìš´ì˜/AS ë¦¬ìŠ¤í¬
    "íŒŒì†","í™˜ë¶ˆ","êµí™˜","ì¬ê³ ","í’ˆì ˆ","í•œì •ìˆ˜ëŸ‰","ê¸´ê¸‰","ê¸‰ì²˜","íŠ¹íŒ",
    # ê³¼ë„í•œ ë§ˆì¼€íŒ… í‘œí˜„/ì´ëª¨ì§€
    "mustbuy","ê°•ì¶”","ì¶”ì²œ","ì¶”ì²œí…œ","ğŸ”¥","ğŸ’¥","â­","best","ë² ìŠ¤íŠ¸"
]
STOPWORDS_BY_CAT = {
    "íŒ¨ì…˜ì˜ë¥˜":   ["ë£¨ì¦ˆí•","ë¹…ì‚¬ì´ì¦ˆ","ì´ˆìŠ¬ë¦¼","ê·¹ì„¸ì‚¬","ì´ˆê²½ëŸ‰","ì™•ì˜¤ë²„","ëª¸ë§¤ë³´ì •"],
    "íŒ¨ì…˜ì¡í™”":   ["ë¬´ë£Œê°ì¸","ì‚¬ì€í’ˆì§€ê¸‰","ì„¸íŠ¸ì¦ì •"],
    "ë·°í‹°/ë¯¸ìš©":  ["ì •í’ˆë³´ì¥","ë³‘í–‰ìˆ˜ì…","ë²Œí¬","ë¦¬í•„ë§Œ","ìƒ˜í”Œ","í…ŒìŠ¤í„°"],
    "ìƒí™œ/ê±´ê°•":  ["ê³µìš©","ë¹„ë§¤í’ˆ","ë¦¬í¼","ë¦¬í¼ë¹„ì‹œ"],
    "ë””ì§€í„¸/ê°€ì „": ["ê´€ë¶€ê°€ì„¸","ë¶€ê°€ì„¸","í•´ì™¸ì§êµ¬","ë¦¬í¼","ë¦¬í¼ë¹„ì‹œ","ë²Œí¬"],
    "ìŠ¤í¬ì¸ /ë ˆì €": ["ë¬´ë£Œì¡°ë¦½","ê°€ì„±ë¹„ê°‘"],
}
STOP_PRESETS = {
    "ë„¤ì´ë²„_ì•ˆì „ê¸°ë³¸": {
        "global": STOPWORDS_GLOBAL, "by_cat": STOPWORDS_BY_CAT, "whitelist": [],
        "replace": ["ë¬´ë°°=> ", "ë¬´ë£Œë°°ì†¡=> ", "ì •í’ˆ=> "], "aggressive": False
    },
    "ê´‘ê³ í‘œí˜„_ê°•ë ¥ì°¨ë‹¨": {
        "global": STOPWORDS_GLOBAL + ["ì´ˆê°•ë ¥","ì´ˆì €ê°€","ê·¹ê°•","í˜œì","ëŒ€ë€","í’ˆì ˆì„ë°•","ì™„íŒì„ë°•","ë§ˆê°ì„ë°•"],
        "by_cat": STOPWORDS_BY_CAT, "whitelist": [],
        "replace": ["ë¬´ë°°=> ", "ë¬´ë£Œë°°ì†¡=> ", "ì •í’ˆ=> ", "í• ì¸=> "], "aggressive": True
    }
}

# =========================
# 1) UI defaults & CSS
# =========================
def _ensure_session_defaults():
    ss = st.session_state
    ss.setdefault("theme", "light")
    ss.setdefault("fx_base", "USD")
    ss.setdefault("sale_foreign", 1.00)
    ss.setdefault("m_base", "USD")
    ss.setdefault("purchase_foreign", 0.00)
    ss.setdefault("card_fee_pct", 4.00)
    ss.setdefault("market_fee_pct", 14.00)
    ss.setdefault("shipping_won", 0.0)
    ss.setdefault("margin_mode", "í¼ì„¼íŠ¸")
    ss.setdefault("margin_pct", 10.00)
    ss.setdefault("margin_won", 10000.0)
    # Stopwords manager ìƒíƒœ
    ss.setdefault("STOP_GLOBAL", list(STOPWORDS_GLOBAL))
    ss.setdefault("STOP_BY_CAT", dict(STOPWORDS_BY_CAT))
    ss.setdefault("STOP_WHITELIST", [])
    ss.setdefault("STOP_REPLACE", ["ë¬´ë°°=> ", "ë¬´ë£Œë°°ì†¡=> ", "ì •í’ˆ=> "])
    ss.setdefault("STOP_AGGR", False)
    # Rakuten genre map
    ss.setdefault("rk_genre_map", {
        "ì „ì²´(ìƒ˜í”Œ)": "100283","ë·°í‹°/ì½”ìŠ¤ë©”í‹±": "100283","ì˜ë¥˜/íŒ¨ì…˜": "100283","ê°€ì „/ë””ì§€í„¸": "100283",
        "ê°€êµ¬/ì¸í…Œë¦¬ì–´": "100283","ì‹í’ˆ": "100283","ìƒí™œ/ê±´ê°•": "100283","ìŠ¤í¬ì¸ /ë ˆì €": "100283","ë¬¸êµ¬/ì·¨ë¯¸": "100283",
    })

def _toggle_theme():
    st.session_state["theme"] = "dark" if st.session_state.get("theme", "light") == "light" else "light"

def _inject_css():
    """
    ë©”ì¸ ë·°: ë‹¤í¬/ë¼ì´íŠ¸ í† ê¸€ ë°˜ì˜
    ì‚¬ì´ë“œë°”: í•­ìƒ ë¼ì´íŠ¸ í†¤ ê³ ì •(ì‹œì•ˆì„±), ë‚´ë¶€ë§Œ ìŠ¤í¬ë¡¤(100vh sticky)
    ì‚¬ì´ë“œë°” ì»¬ëŸ¬ pill ë³µêµ¬
    """
    theme = st.session_state.get("theme", "light")

    # ===== ë©”ì¸ ì˜ì—­ íŒ”ë ˆíŠ¸(í† ê¸€ ë°˜ì˜) =====
    if theme == "dark":
        bg = "#0e1117"; fg = "#e6edf3"; fg_sub = "#b6c2cf"; card_bg = "#11151c"
        border = "rgba(255,255,255,.08)"; btn_bg = "#2563eb"; btn_bg_hover = "#1e3fae"
        pill_shadow = "0 2px 10px rgba(0,0,0,.35)"
        pill_green_bg, pill_green_bd, pill_green_fg = "linear-gradient(180deg, #0f5132 0%, #0b3d26 100%)", "rgba(86,207,150,.35)", "#d1fae5"
        pill_blue_bg,  pill_blue_bd,  pill_blue_fg  = "linear-gradient(180deg, #0b3b8a 0%, #092a63 100%)", "rgba(147,197,253,.35)", "#dbeafe"
        pill_yellow_bg, pill_yellow_bd, pill_yellow_fg = "linear-gradient(180deg, #7a5c0a 0%, #5b4307 100%)", "rgba(252,211,77,.35)", "#fef3c7"
        pill_warn_bg,  pill_warn_bd,  pill_warn_fg  = "linear-gradient(180deg, #5c1a1a 0%, #3d1010 100%)", "rgba(248,113,113,.35)", "#fee2e2"
    else:
        bg = "#ffffff"; fg = "#111111"; fg_sub = "#4b5563"; card_bg = "#ffffff"
        border = "rgba(0,0,0,.06)"; btn_bg = "#2563eb"; btn_bg_hover = "#1e3fae"
        pill_shadow = "0 2px 10px rgba(0,0,0,.08)"
        pill_green_bg, pill_green_bd, pill_green_fg = "linear-gradient(180deg, #d1fae5 0%, #a7f3d0 100%)", "rgba(16,185,129,.35)", "#065f46"
        pill_blue_bg,  pill_blue_bd,  pill_blue_fg  = "linear-gradient(180deg, #dbeafe 0%, #bfdbfe 100%)", "rgba(59,130,246,.35)", "#1e3a8a"
        pill_yellow_bg, pill_yellow_bd, pill_yellow_fg = "linear-gradient(180deg, #fef3c7 0%, #fde68a 100%)", "rgba(234,179,8,.35)", "#7c2d12"
        pill_warn_bg,  pill_warn_bd,  pill_warn_fg  = "linear-gradient(180deg, #fee2e2 0%, #fecaca 100%)", "rgba(239,68,68,.35)", "#7f1d1d"

    # ===== ì‚¬ì´ë“œë°”(í•­ìƒ ë¼ì´íŠ¸ ê³ ì •) íŒ”ë ˆíŠ¸ =====
    sb_bg   = "#f6f8fb"
    sb_fg   = "#111111"
    sb_sub  = "#4b5563"
    sb_card = "#ffffff"
    sb_bd   = "rgba(0,0,0,.06)"

    st.markdown(f"""
    <style>
      /* =========================
         ë©”ì¸ ì»¨í…Œì´ë„ˆ(ë‹¤í¬/ë¼ì´íŠ¸ ì ìš©)
         ========================= */
      [data-testid="stAppViewContainer"] {{
        background:{bg} !important; color:{fg} !important;
      }}
      [data-testid="stAppViewContainer"] h1,
      [data-testid="stAppViewContainer"] h2,
      [data-testid="stAppViewContainer"] h3,
      [data-testid="stAppViewContainer"] h4,
      [data-testid="stAppViewContainer"] h5,
      [data-testid="stAppViewContainer"] h6,
      [data-testid="stAppViewContainer"] p,
      [data-testid="stAppViewContainer"] li,
      [data-testid="stAppViewContainer"] span,
      [data-testid="stAppViewContainer"] label,
      [data-testid="stAppViewContainer"] .stMarkdown,
      [data-testid="stAppViewContainer"] .stMarkdown * {{ color:{fg} !important; }}
      [data-testid="stAppViewContainer"] [data-baseweb="select"] *,
      [data-testid="stAppViewContainer"] [data-baseweb="input"] input,
      [data-testid="stAppViewContainer"] .stNumberInput input,
      [data-testid="stAppViewContainer"] .stTextInput input {{ color:{fg} !important; }}
      [data-testid="stAppViewContainer"] input::placeholder {{ color:{fg_sub} !important; opacity:.9 !important; }}

      [data-testid="stAppViewContainer"] .card {{
        background:{card_bg}; border:1px solid {border}; border-radius:14px;
        box-shadow:0 1px 6px rgba(0,0,0,.12);
      }}

      [data-testid="stAppViewContainer"] .stButton>button {{
        background:{btn_bg} !important; color:#fff !important;
        border:1px solid rgba(255,255,255,.08) !important;
        border-radius:10px !important; font-weight:700 !important;
      }}
      [data-testid="stAppViewContainer"] .stButton>button:hover {{
        background:{btn_bg_hover} !important; border-color:rgba(255,255,255,.15) !important;
      }}

      .pill {{
        display:block; width:100%; border-radius:12px;
        padding:.70rem .95rem; font-weight:800;
        letter-spacing:.1px; box-shadow:{pill_shadow};
        border:1px solid transparent; margin:.35rem 0 .5rem 0;
      }}
      .pill span {{ opacity:.8; font-weight:700; }}

      /* ë©”ì¸/ì‚¬ì´ë“œë°” ê³µí†µ pill ìƒ‰ìƒ */
      .pill-green {{ background:{pill_green_bg}; border-color:{pill_green_bd}; color:{pill_green_fg}; }}
      .pill-blue  {{ background:{pill_blue_bg};  border-color:{pill_blue_bd};  color:{pill_blue_fg}; }}
      .pill-yellow{{ background:{pill_yellow_bg};border-color:{pill_yellow_bd};color:{pill_yellow_fg}; }}
      .pill-warn  {{ background:{pill_warn_bg};  border-color:{pill_warn_bd};  color:{pill_warn_fg}; }}

      .envy-chip-warn {{
        display:inline-block; padding:.35rem .7rem;
        border-radius:9999px; font-weight:700;
        background:{pill_warn_bg}; border:1px solid {pill_warn_bd};
        color:{pill_warn_fg};
      }}

      /* =========================
         ì‚¬ì´ë“œë°”: í•­ìƒ ë¼ì´íŠ¸ í†¤ + ë‚´ë¶€ ìŠ¤í¬ë¡¤ë§Œ í—ˆìš©
         ========================= */
      [data-testid="stSidebar"] {{
        background:{sb_bg} !important;
        color:{sb_fg} !important;
        overflow:hidden !important;                /* ë°”ê¹¥ìª½ ìŠ¤í¬ë¡¤ ì ê¸ˆ */
      }}
      /* ì‚¬ì´ë“œë°” ì»¨í…ì¸  ë˜í¼ë§Œ ìŠ¤í¬ë¡¤ */
      [data-testid="stSidebar"] [data-testid="stSidebarContent"] {{
        position: sticky; top: 0;
        height: 100vh; max-height: 100vh;
        overflow-y: auto !important;
        padding-bottom: 1rem;
      }}
      /* ì‚¬ì´ë“œë°” ë‚´ë¶€ UI ëŒ€ë¹„(í•­ìƒ ë¼ì´íŠ¸) */
      [data-testid="stSidebar"] *,
      [data-testid="stSidebar"] .stMarkdown,
      [data-testid="stSidebar"] .stMarkdown * {{ color:{sb_fg} !important; }}
      [data-testid="stSidebar"] input::placeholder {{ color:{sb_sub} !important; opacity:.9 !important; }}
      [data-testid="stSidebar"] .card {{
        background:{sb_card}; border:1px solid {sb_bd}; border-radius:14px;
        box-shadow:0 1px 6px rgba(0,0,0,.08);
      }}
      [data-testid="stSidebar"] [data-baseweb="select"] *,
      [data-testid="stSidebar"] [data-baseweb="input"] input,
      [data-testid="stSidebar"] .stNumberInput input,
      [data-testid="stSidebar"] .stTextInput input {{ color:{sb_fg} !important; }}

      /* ì‚¬ì´ë“œë°” í† ê¸€/ë¼ë””ì˜¤ ë ˆì´ë¸”ë„ ë¼ì´íŠ¸ë¡œ ê³ ì • */
      [data-testid="stSidebar"] .stRadio label,
      [data-testid="stSidebar"] .stCheckbox label,
      [data-testid="stSidebar"] label {{ color:{sb_fg} !important; }}
    </style>
    """, unsafe_allow_html=True)

# =========================
# 2) Responsive
# =========================
def _responsive_probe():
    html = """
    <script>
    (function(){
      const bps=[900,1280,1600];
      const w=Math.max(document.documentElement.clientWidth||0, window.innerWidth||0);
      let bin=0; for(let i=0;i<bps.length;i++) if(w>=bps[i]) bin=i+1;
      const url=new URL(window.location); const curr=url.searchParams.get('vwbin');
      if(curr!==String(bin)){ url.searchParams.set('vwbin', String(bin)); window.location.replace(url.toString()); }
    })();
    </script>
    """
    st.components.v1.html(html, height=0, scrolling=False)

def _get_view_bin():
    try:
        raw = st.query_params.get("vwbin", "3")
    except Exception:
        raw = (st.experimental_get_query_params().get("vwbin", ["3"])[0])
    try:
        return max(0, min(3, int(raw)))
    except:
        return 3

# =========================
# 3) Generic proxy iframe
# =========================
def _proxy_iframe(proxy_base: str, target_url: str, height: int = 860, scroll=True, key=None):
    proxy = (proxy_base or "").strip().rstrip("/")
    url   = f"{proxy}/?url={quote(target_url, safe=':/?&=%')}"
    h     = int(height)
    try:
        st.iframe(url, height=h); return
    except Exception:
        pass
    try:
        st.components.v1.iframe(url, height=h, scrolling=bool(scroll)); return
    except Exception:
        pass
    st.markdown(f'<iframe src="{url}" style="width:100%;height:{h}px;border:0;border-radius:10px;"></iframe>',
                unsafe_allow_html=True)

def _proxy_iframe_with_title(proxy_base: str, target_url: str, height: int = 860, key: str = "naver_home"):
    proxy = (proxy_base or "").strip().rstrip("/")
    url   = f"{proxy}/?url={quote(target_url, safe=':/?&=%')}"
    h     = int(height)
    html  = f'''
<div id="{key}-wrap" class="main" style="width:100%;overflow:hidden;">
  <div id="{key}-title"
       style="display:inline-block;border-radius:9999px;padding:.40rem .9rem;
              font-weight:800;background:#dbe6ff;border:1px solid #88a8ff;color:#09245e;margin:0 0 .5rem 0;">
    DataLab
  </div>
  <iframe src="{url}" style="width:100%;height:{h}px;border:0;border-radius:10px"></iframe>
</div>
<script>
(function(){{
  var titleEl=document.getElementById("{key}-title");
  window.addEventListener("message",function(e){{
    try{{var d=e.data||{{}}; if(d.__envy && d.kind==="title" && d.title) titleEl.textContent=d.title;}}catch(_){{
    }}
  }},false);
}})();
</script>
'''
    st.components.v1.html(html, height=h+56, scrolling=False)

# =========================
# 4) Sidebar (theme + translator toggle + calculators)
# =========================
def _sidebar():
    # ê¸°ë³¸ ì„¸ì…˜ + CSS
    _ensure_session_defaults()
    _inject_css()
    # ì•Œë¦¼ì„¼í„°ê°€ ì—†ëŠ” ê²½ìš°ì—ë„ ì£½ì§€ ì•Šë„ë¡ ë°©ì–´
    try:
        _inject_alert_center()
    except Exception:
        pass

    with st.sidebar:
        # â€”â€”â€” ë¡œê³ : ì›í˜• 64px ê³ ì • â€”â€”â€”
        st.markdown("""
        <style>
          [data-testid="stSidebar"] .logo-circle{
            width:64px;height:64px;border-radius:9999px;overflow:hidden;
            margin:.35rem auto .6rem auto; box-shadow:0 2px 8px rgba(0,0,0,.12);
            border:1px solid rgba(0,0,0,.06);
          }
          [data-testid="stSidebar"] .logo-circle img{
            width:100%;height:100%;object-fit:cover;display:block;
          }
        </style>
        """, unsafe_allow_html=True)

        lp = Path(__file__).parent / "logo.png"
        if lp.exists():
            b64 = base64.b64encode(lp.read_bytes()).decode("ascii")
            st.markdown(
                f'<div class="logo-circle"><img src="data:image/png;base64,{b64}"></div>',
                unsafe_allow_html=True
            )

        # í† ê¸€
        c1, c2 = st.columns(2)
        with c1:
            st.toggle("ğŸŒ“ ë‹¤í¬",
                      value=(st.session_state.get("theme","light")=="dark"),
                      on_change=_toggle_theme, key="__theme_toggle")
        with c2:
            st.toggle("ğŸŒ ë²ˆì—­ê¸°", value=False, key="__show_translator")

        show_tr = st.session_state.get("__show_translator", False)

        # ---- ìœ„ì ¯ë“¤ ----
        def translator_block(expanded=True):
            with st.expander("ğŸŒ êµ¬ê¸€ ë²ˆì—­ê¸°", expanded=expanded):
                LANG_LABELS_SB = {
                    "auto":"ìë™ ê°ì§€","ko":"í•œêµ­ì–´","en":"ì˜ì–´","ja":"ì¼ë³¸ì–´","zh-CN":"ì¤‘êµ­ì–´(ê°„ì²´)",
                    "zh-TW":"ì¤‘êµ­ì–´(ë²ˆì²´)","vi":"ë² íŠ¸ë‚¨ì–´","th":"íƒœêµ­ì–´","id":"ì¸ë„ë„¤ì‹œì•„ì–´",
                    "de":"ë…ì¼ì–´","fr":"í”„ë‘ìŠ¤ì–´","es":"ìŠ¤í˜ì¸ì–´","it":"ì´íƒˆë¦¬ì•„ì–´","pt":"í¬ë¥´íˆ¬ê°ˆì–´"
                }
                def _code_sb(x): return {v:k for k,v in LANG_LABELS_SB.items()}.get(x, x)
                src_label = st.selectbox("ì›ë¬¸ ì–¸ì–´", list(LANG_LABELS_SB.values()),
                                         index=list(LANG_LABELS_SB.keys()).index("auto"), key="sb_tr_src")
                tgt_label = st.selectbox("ë²ˆì—­ ì–¸ì–´", list(LANG_LABELS_SB.values()),
                                         index=list(LANG_LABELS_SB.keys()).index("ko"), key="sb_tr_tgt")
                text_in = st.text_area("í…ìŠ¤íŠ¸", height=120, key="sb_tr_in")
                if st.button("ë²ˆì—­ ì‹¤í–‰", key="sb_tr_btn"):
                    try:
                        from deep_translator import GoogleTranslator as _GT
                        src_code = _code_sb(src_label); tgt_code = _code_sb(tgt_label)
                        out_main = _GT(source=src_code, target=tgt_code).translate(text_in or "")
                        st.text_area(f"ê²°ê³¼ ({tgt_label})", value=out_main, height=120, key="sb_tr_out_main")
                        if tgt_code != "ko":
                            out_ko = _GT(source=tgt_code, target="ko").translate(out_main or "")
                            st.text_area("ê²°ê³¼ (í•œêµ­ì–´)", value=out_ko, height=120, key="sb_tr_out_ko")
                    except Exception as e:
                        st.error(f"ë²ˆì—­ ì¤‘ ì˜¤ë¥˜: {e}")

        def fx_block(expanded=True):
            with st.expander("ğŸ’± í™˜ìœ¨ ê³„ì‚°ê¸°", expanded=expanded):
                fx_base = st.selectbox("ê¸°ì¤€ í†µí™”", list(CURRENCIES.keys()),
                                       index=list(CURRENCIES.keys()).index(st.session_state.get("fx_base","USD")),
                                       key="fx_base")
                sale_foreign = st.number_input("íŒë§¤ê¸ˆì•¡ (ì™¸í™”)",
                                               value=float(st.session_state.get("sale_foreign",1.0)),
                                               step=0.01, format="%.2f", key="sale_foreign")
                won = FX_DEFAULT[fx_base]*sale_foreign
                st.markdown(
                    f'<div class="pill pill-green">í™˜ì‚° ê¸ˆì•¡: <b>{won:,.2f} ì›</b>'
                    f'<span style="opacity:.75;font-weight:700"> ({CURRENCIES[fx_base]["symbol"]})</span></div>',
                    unsafe_allow_html=True
                )
                st.caption(f"í™˜ìœ¨ ê¸°ì¤€: {FX_DEFAULT[fx_base]:,.2f} â‚©/{CURRENCIES[fx_base]['unit']}")

        def margin_block(expanded=True):
            with st.expander("ğŸ“ˆ ë§ˆì§„ ê³„ì‚°ê¸°", expanded=expanded):
                m_base = st.selectbox("ë§¤ì… í†µí™”", list(CURRENCIES.keys()),
                                      index=list(CURRENCIES.keys()).index(st.session_state.get("m_base","USD")),
                                      key="m_base")
                purchase_foreign = st.number_input("ë§¤ì…ê¸ˆì•¡ (ì™¸í™”)",
                                                   value=float(st.session_state.get("purchase_foreign",0.0)),
                                                   step=0.01, format="%.2f", key="purchase_foreign")
                base_cost_won = FX_DEFAULT[m_base]*purchase_foreign if purchase_foreign>0 \
                                else FX_DEFAULT[st.session_state.get("fx_base","USD")]*st.session_state.get("sale_foreign",1.0)
                st.markdown(f'<div class="pill pill-green">ì›ê°€(â‚©): <b>{base_cost_won:,.2f} ì›</b></div>', unsafe_allow_html=True)
                c1, c2 = st.columns(2)
                with c1:
                    card_fee = st.number_input("ì¹´ë“œìˆ˜ìˆ˜ë£Œ(%)",
                                               value=float(st.session_state.get("card_fee_pct",4.0)),
                                               step=0.01, format="%.2f", key="card_fee_pct")
                with c2:
                    market_fee = st.number_input("ë§ˆì¼“ìˆ˜ìˆ˜ë£Œ(%)",
                                                 value=float(st.session_state.get("market_fee_pct",14.0)),
                                                 step=0.01, format="%.2f", key="market_fee_pct")
                shipping_won = st.number_input("ë°°ì†¡ë¹„(â‚©)",
                                               value=float(st.session_state.get("shipping_won",0.0)),
                                               step=100.0, format="%.0f", key="shipping_won")
                mode = st.radio("ë§ˆì§„ ë°©ì‹", ["í¼ì„¼íŠ¸","í”ŒëŸ¬ìŠ¤"], horizontal=True, key="margin_mode")
                if mode=="í¼ì„¼íŠ¸":
                    margin_pct = st.number_input("ë§ˆì§„ìœ¨ (%)",
                                                 value=float(st.session_state.get("margin_pct",10.0)),
                                                 step=0.01, format="%.2f", key="margin_pct")
                    target_price = base_cost_won*(1+card_fee/100)*(1+market_fee/100)*(1+margin_pct/100)+shipping_won
                    margin_value = target_price - base_cost_won; desc=f"{margin_pct:.2f}%"
                else:
                    margin_won = st.number_input("ë§ˆì§„ì•¡ (â‚©)",
                                                 value=float(st.session_state.get("margin_won",10000.0)),
                                                 step=100.0, format="%.0f", key="margin_won")
                    target_price = base_cost_won*(1+card_fee/100)*(1+market_fee/100)+margin_won+shipping_won
                    margin_value = margin_won; desc=f"+{margin_won:,.0f}"
                st.markdown(f'<div class="pill pill-blue">íŒë§¤ê°€: <b>{target_price:,.2f} ì›</b></div>', unsafe_allow_html=True)
                st.markdown(f'<div class="pill pill-yellow">ìˆœì´ìµ(ë§ˆì§„): <b>{margin_value:,.2f} ì›</b> â€” {desc}</div>', unsafe_allow_html=True)

        # í† ê¸€ ìƒíƒœì— ë”°ë¼ í¼ì¹¨
        if show_tr:
            translator_block(expanded=True); fx_block(expanded=False); margin_block(expanded=False)
        else:
            fx_block(expanded=True); margin_block(expanded=True); translator_block(expanded=False)

        # ê´€ë¦¬ì ë°•ìŠ¤(ì˜µì…˜)
        if SHOW_ADMIN_BOX:
            st.divider()
            st.text_input("PROXY_URL(ë””ë²„ê·¸)", key="PROXY_URL", help="Cloudflare Worker ì£¼ì†Œ (ì˜µì…˜)")

# =========================
# 5) Rakuten Ranking
# =========================
def _rakuten_keys():
    app_id = _get_key("RAKUTEN_APP_ID")
    affiliate = _get_key("RAKUTEN_AFFILIATE_ID")
    return app_id, affiliate

@st.cache_data(ttl=900, show_spinner=False)
def _rk_fetch_rank_cached(genre_id: str, topn: int = 20, strip_emoji: bool=True) -> pd.DataFrame:
    app_id, affiliate = _rakuten_keys()
    def _clean(s: str) -> str:
        if not strip_emoji: return s
        return re.sub(r"[\U00010000-\U0010ffff]", "", s or "")
    if not (requests and app_id):
        rows=[{"rank":i+1,"keyword":_clean(f"[ìƒ˜í”Œ] í‚¤ì›Œë“œ {i+1} ãƒãƒ­ã‚¦ã‚£ãƒ³ ç§‹ ğŸ‚"),
               "shop":"ìƒ˜í”Œ","url":"https://example.com"} for i in range(topn)]
        return pd.DataFrame(rows)
    def _do():
        api = "https://app.rakuten.co.jp/services/api/IchibaItem/Ranking/20170628"
        params = {"applicationId": app_id, "genreId": str(genre_id).strip(), "hits": topn}
        if affiliate: params["affiliateId"] = affiliate
        r = requests.get(api, params=params, timeout=12)
        r.raise_for_status()
        items = r.json().get("Items", [])[:topn]
        rows=[]
        for it in items:
            node = it.get("Item", {})
            rows.append({
                "rank": node.get("rank"),
                "keyword": _clean(node.get("itemName","")),
                "shop": node.get("shopName",""),
                "url": node.get("itemUrl",""),
            })
        return pd.DataFrame(rows)
    try:
        return _do()
    except Exception:
        rows=[{"rank":i+1,"keyword":_clean(f"[ìƒ˜í”Œ] í‚¤ì›Œë“œ {i+1} ãƒãƒ­ã‚¦ã‚£ãƒ³ ç§‹ ğŸ‚"),
               "shop":"ìƒ˜í”Œ","url":"https://example.com"} for i in range(topn)]
        return pd.DataFrame(rows)

def section_rakuten_ui():
    st.markdown('<div id="rk-card" class="main">', unsafe_allow_html=True)
    colB, colC = st.columns([2,1])
    with colB:
        cat = st.selectbox("ë¼ì¿ í… ì¹´í…Œê³ ë¦¬",
                           ["ì „ì²´(ìƒ˜í”Œ)","ë·°í‹°/ì½”ìŠ¤ë©”í‹±","ì˜ë¥˜/íŒ¨ì…˜","ê°€ì „/ë””ì§€í„¸","ê°€êµ¬/ì¸í…Œë¦¬ì–´","ì‹í’ˆ","ìƒí™œ/ê±´ê°•","ìŠ¤í¬ì¸ /ë ˆì €","ë¬¸êµ¬/ì·¨ë¯¸"], key="rk_cat")
    with colC:
        sample_only = st.checkbox("ìƒ˜í”Œ ë³´ê¸°", value=False, key="rk_sample")
    strip_emoji = st.toggle("ì´ëª¨ì§€ ì œê±°", value=True, key="rk_strip_emoji")
    genre_map = st.session_state.get("rk_genre_map", {})
    genre_id = (genre_map.get(cat) or "").strip() or "100283"
    with st.spinner("ë¼ì¿ í… ë­í‚¹ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
        df = (pd.DataFrame([{"rank":i+1,"keyword":f"[ìƒ˜í”Œ] í‚¤ì›Œë“œ {i+1}","shop":"ìƒ˜í”Œ","url":"https://example.com"} for i in range(20)])
              if sample_only else _rk_fetch_rank_cached(genre_id, topn=20, strip_emoji=strip_emoji))
    colcfg = {
        "rank": st.column_config.NumberColumn("rank", width="small"),
        "keyword": st.column_config.TextColumn("keyword", width="medium"),
        "shop": st.column_config.TextColumn("shop", width="small"),
        "url": st.column_config.LinkColumn("url", display_text="ì—´ê¸°", width="small"),
    }
    st.dataframe(df[["rank","keyword","shop","url"]], hide_index=True, use_container_width=True, height=430, column_config=colcfg)
    st.download_button("í‘œ CSV ë‹¤ìš´ë¡œë“œ", data=df.to_csv(index=False).encode("utf-8-sig"),
                       file_name="rakuten_ranking.csv", mime="text/csv")
    with st.expander("ğŸ”§ ì¥ë¥´ ë§¤í•‘ í¸ì§‘ (í™”ë©´ì—ëŠ” ìˆ¨ê¹€)", expanded=False):
        st.caption("ì¹´í…Œê³ ë¦¬ â†’ genreId ë§¤í•‘ì…ë‹ˆë‹¤. ì˜¬ë°”ë¥¸ genreIdë¡œ ë°”ê¾¸ê³  ì €ì¥í•˜ì„¸ìš”.")
        g1, g2 = st.columns(2)
        with g1:
            for k in ["ë·°í‹°/ì½”ìŠ¤ë©”í‹±","ì˜ë¥˜/íŒ¨ì…˜","ê°€êµ¬/ì¸í…Œë¦¬ì–´","ìŠ¤í¬ì¸ /ë ˆì €","ë¬¸êµ¬/ì·¨ë¯¸"]:
                st.session_state["rk_genre_map"][k] = st.text_input(k, st.session_state["rk_genre_map"].get(k,"100283"), key=f"rk_{k}")
        with g2:
            for k in ["ê°€ì „/ë””ì§€í„¸","ì‹í’ˆ","ìƒí™œ/ê±´ê°•","ì „ì²´(ìƒ˜í”Œ)"]:
                st.session_state["rk_genre_map"][k] = st.text_input(k, st.session_state["rk_genre_map"].get(k,"100283"), key=f"rk_{k}")
        st.info("ì„¸ì…˜ì— ì €ì¥ë©ë‹ˆë‹¤. ì•± ì¬ì‹¤í–‰ ì‹œ ì´ˆê¸°ê°’ìœ¼ë¡œ ëŒì•„ì˜¬ ìˆ˜ ìˆì–´ìš”.")
    st.markdown('</div>', unsafe_allow_html=True)

# =========================
# 6) Korea Radar (Naver Searchad API)
# =========================
import hashlib, hmac, base64 as b64

def _naver_signature(timestamp: str, method: str, uri: str, secret: str) -> str:
    msg = f"{timestamp}.{method}.{uri}"
    digest = hmac.new(bytes(secret, "utf-8"), bytes(msg, "utf-8"), hashlib.sha256).digest()
    return b64.b64encode(digest).decode("utf-8")

def _naver_keys_from_secrets():
    ak = _get_key("NAVER_API_KEY"); sk = _get_key("NAVER_SECRET_KEY"); cid= _get_key("NAVER_CUSTOMER_ID")
    return ak.strip(), sk.strip(), str(cid).strip()

def _naver_keywordstool(hint_keywords: list[str]) -> pd.DataFrame:
    api_key, sec_key, customer_id = _naver_keys_from_secrets()
    if not (requests and api_key and sec_key and customer_id and hint_keywords):
        return pd.DataFrame()
    base_url="https://api.naver.com"; uri="/keywordstool"; ts = str(round(time.time()*1000))
    headers = {"X-API-KEY": api_key, "X-Signature": _naver_signature(ts, "GET", uri, sec_key),
               "X-Timestamp": ts, "X-Customer": customer_id}
    params={ "hintKeywords": ",".join(hint_keywords), "includeHintKeywords": "0", "showDetail": "1" }
    try:
        r = requests.get(base_url+uri, headers=headers, params=params, timeout=12)
        r.raise_for_status()
    except Exception as e:
        code = getattr(getattr(e, "response", None), "status_code", "N/A")
        st.markdown(f"<div class='envy-chip-warn main'>í‚¤ì›Œë“œë„êµ¬ í˜¸ì¶œ ì‹¤íŒ¨ Â· HTTP {code} â€” í‚¤/ì‹œê·¸ë‹ˆì²˜/ê¶Œí•œ í™•ì¸</div>", unsafe_allow_html=True)
        return pd.DataFrame()

    try:
        data = r.json().get("keywordList", [])[:200]
        if not data: return pd.DataFrame()
        df = pd.DataFrame(data).rename(columns={
            "relKeyword":"í‚¤ì›Œë“œ","monthlyPcQcCnt":"PCì›”ê°„ê²€ìƒ‰ìˆ˜","monthlyMobileQcCnt":"Mobileì›”ê°„ê²€ìƒ‰ìˆ˜",
            "monthlyAvePcClkCnt":"PCì›”í‰ê· í´ë¦­ìˆ˜","monthlyAveMobileClkCnt":"Mobileì›”í‰ê· í´ë¦­ìˆ˜",
            "monthlyAvePcCtr":"PCì›”í‰ê· í´ë¦­ë¥ ","monthlyAveMobileCtr":"Mobileì›”í‰ê· í´ë¦­ë¥ ",
            "plAvgDepth":"ì›”í‰ê· ë…¸ì¶œê´‘ê³ ìˆ˜","compIdx":"ê´‘ê³ ê²½ìŸì •ë„",
        }).drop_duplicates(["í‚¤ì›Œë“œ"]).set_index("í‚¤ì›Œë“œ").reset_index()
        num_cols=["PCì›”ê°„ê²€ìƒ‰ìˆ˜","Mobileì›”ê°„ê²€ìƒ‰ìˆ˜","PCì›”í‰ê· í´ë¦­ìˆ˜","Mobileì›”í‰ê· í´ë¦­ìˆ˜","PCì›”í‰ê· í´ë¦­ë¥ ","Mobileì›”í‰ê· í´ë¦­ë¥ ","ì›”í‰ê· ë…¸ì¶œê´‘ê³ ìˆ˜"]
        for c in num_cols: df[c]=pd.to_numeric(df[c], errors="coerce")
        return df
    except Exception:
        return pd.DataFrame()

def _count_product_from_shopping(keyword: str) -> int|None:
    if not requests: return None
    try:
        url=f"https://search.shopping.naver.com/search/all?where=all&frm=NVSCTAB&query={quote(keyword)}"
        r=requests.get(url, timeout=10); r.raise_for_status()
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(r.text, "html.parser")
        a_tags = soup.select("a.subFilter_filter__3Y-uy")
        for a in a_tags:
            if "ì „ì²´" in a.text:
                span = a.find("span")
                if span:
                    txt = span.get_text().replace(",","").strip()
                    return int(re.sub(r"[^0-9]", "", txt) or "0")
        return None
    except Exception:
        return None

def section_korea_ui():
    st.markdown('<div class="main">', unsafe_allow_html=True)
    st.caption("â€» ê²€ìƒ‰ì§€í‘œëŠ” ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API(í‚¤ì›Œë“œë„êµ¬) ê¸°ì¤€, ìƒí’ˆìˆ˜ëŠ” ë„¤ì´ë²„ì‡¼í•‘ â€˜ì „ì²´â€™ íƒ­ í¬ë¡¤ë§ ê¸°ì¤€ì…ë‹ˆë‹¤.")
    c1, c2, c3 = st.columns([1,1,1])
    with c1:
        months = st.slider("ë¶„ì„ê¸°ê°„(ê°œì›”, í‘œì‹œìš©)", 1, 6, 3)
    with c2:
        device = st.selectbox("ë””ë°”ì´ìŠ¤", ["all","pc","mo"], index=0)
    with c3:
        src = st.selectbox("í‚¤ì›Œë“œ ì†ŒìŠ¤", ["ì§ì ‘ ì…ë ¥"], index=0)

    keywords_txt = st.text_area("í‚¤ì›Œë“œ(ì½¤ë§ˆë¡œ êµ¬ë¶„)", "í•¸ë“œë©”ì´ë“œì½”íŠ¸, ë‚¨ìì½”íŠ¸, ì—¬ìì½”íŠ¸", height=96)
    kw_list = [k.strip() for k in (keywords_txt or "").split(",") if k.strip()]
    opt1, opt2 = st.columns([1,1])
    with opt1:
        add_product = st.toggle("ë„¤ì´ë²„ì‡¼í•‘ â€˜ì „ì²´â€™ ìƒí’ˆìˆ˜ ìˆ˜ì§‘(ëŠë¦¼)", value=False)
    with opt2:
        table_mode = st.radio("í‘œ ëª¨ë“œ", ["A(ê²€ìƒ‰ì§€í‘œ)","B(ê²€ìƒ‰+ìˆœìœ„)","C(ê²€ìƒ‰+ìƒí’ˆìˆ˜+ìŠ¤ì½”ì–´)"], horizontal=True, index=2)

    if st.button("ë ˆì´ë” ì—…ë°ì´íŠ¸", use_container_width=False):
        with st.spinner("ë„¤ì´ë²„ í‚¤ì›Œë“œë„êµ¬ ì¡°íšŒ ì¤‘â€¦"):
            df = _naver_keywordstool(kw_list)
        if df.empty:
            st.markdown("<div class='envy-chip-warn main'>ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (API/ê¶Œí•œ/ì¿¼í„° ë˜ëŠ” í‚¤ì›Œë“œ í™•ì¸)</div>", unsafe_allow_html=True)
            st.markdown("</div>", unsafe_allow_html=True)
            return

        if table_mode.startswith("A"):
            st.dataframe(df, use_container_width=True, height=430)
            st.download_button("CSV ë‹¤ìš´ë¡œë“œ", df.to_csv(index=False).encode("utf-8-sig"),
                               file_name="korea_keyword_A.csv", mime="text/csv")
            st.markdown("</div>", unsafe_allow_html=True)
            return

        df2 = df.copy()
        df2["ê²€ìƒ‰í•©ê³„"] = (pd.to_numeric(df2["PCì›”ê°„ê²€ìƒ‰ìˆ˜"], errors="coerce").fillna(0) +
                           pd.to_numeric(df2["Mobileì›”ê°„ê²€ìƒ‰ìˆ˜"], errors="coerce").fillna(0))
        df2["ê²€ìƒ‰ìˆœìœ„"] = df2["ê²€ìƒ‰í•©ê³„"].rank(ascending=False, method="min")

        if table_mode.startswith("B"):
            out = df2.sort_values("ê²€ìƒ‰ìˆœìœ„")
            st.dataframe(out, use_container_width=True, height=430)
            st.download_button("CSV ë‹¤ìš´ë¡œë“œ", out.to_csv(index=False).encode("utf-8-sig"),
                               file_name="korea_keyword_B.csv", mime="text/csv")
            st.markdown("</div>", unsafe_allow_html=True)
            return

        product_counts = []
        if add_product:
            with st.spinner("ë„¤ì´ë²„ì‡¼í•‘ ìƒí’ˆìˆ˜ ìˆ˜ì§‘ ì¤‘â€¦(í‚¤ì›Œë“œ ìˆ˜ì— ë”°ë¼ ìˆ˜ ë¶„ ì†Œìš”)"):
                for k in df2["í‚¤ì›Œë“œ"]:
                    cnt = _count_product_from_shopping(k)
                    product_counts.append(cnt if cnt is not None else math.nan)
        else:
            product_counts = [math.nan]*len(df2)

        df2["íŒë§¤ìƒí’ˆìˆ˜"] = product_counts
        df2["ìƒí’ˆìˆ˜ìˆœìœ„"] = df2["íŒë§¤ìƒí’ˆìˆ˜"].rank(na_option="bottom", method="min")
        df2["ìƒí’ˆë°œêµ´ëŒ€ìƒ"] = (df2["ê²€ìƒ‰ìˆœìœ„"] + df2["ìƒí’ˆìˆ˜ìˆœìœ„"]).rank(na_option="bottom", method="min")

        cols = ["í‚¤ì›Œë“œ","PCì›”ê°„ê²€ìƒ‰ìˆ˜","Mobileì›”ê°„ê²€ìƒ‰ìˆ˜","íŒë§¤ìƒí’ˆìˆ˜",
                "PCì›”í‰ê· í´ë¦­ìˆ˜","Mobileì›”í‰ê· í´ë¦­ìˆ˜","PCì›”í‰ê· í´ë¦­ë¥ ","Mobileì›”í‰ê· í´ë¦­ë¥ ",
                "ì›”í‰ê· ë…¸ì¶œê´‘ê³ ìˆ˜","ê´‘ê³ ê²½ìŸì •ë„","ê²€ìƒ‰ìˆœìœ„","ìƒí’ˆìˆ˜ìˆœìœ„","ìƒí’ˆë°œêµ´ëŒ€ìƒ"]
        out = df2[cols].sort_values("ìƒí’ˆë°œêµ´ëŒ€ìƒ")
        st.dataframe(out, use_container_width=True, height=430)
        st.download_button("CSV ë‹¤ìš´ë¡œë“œ", out.to_csv(index=False).encode("utf-8-sig"),
                           file_name="korea_keyword_C.csv", mime="text/csv")
    st.markdown("</div>", unsafe_allow_html=True)

# =========================
# 7) DataLab Trend (Open API) + Category â†’ Top20 UI (+ Direct Trend)
# =========================
@st.cache_data(ttl=1800, show_spinner=False)
def _datalab_trend(
    groups: list,
    start_date: str,
    end_date: str,
    time_unit: str = "week",
    device: str = "",
    gender: str = "",
    ages: list | None = None
) -> pd.DataFrame:
    if not requests:
        return pd.DataFrame()

    cid  = _get_key("NAVER_CLIENT_ID")
    csec = _get_key("NAVER_CLIENT_SECRET")
    if not (cid and csec):
        return pd.DataFrame()

    url = "https://openapi.naver.com/v1/datalab/search"
    headers = {
        "X-Naver-Client-Id": cid,
        "X-Naver-Client-Secret": csec,
        "Content-Type": "application/json; charset=utf-8",
    }
    # ë“±ë¡ëœ Referer ê°€ ìˆì„ ë•Œë§Œ ì¶”ê°€ (ì—†ìœ¼ë©´ ë„£ì§€ ì•ŠìŒ)
    ref = (_get_key("NAVER_WEB_REFERER") or "").strip()
    if ref:
        headers["Referer"] = ref

    payload = {
        "startDate": start_date,
        "endDate": end_date,
        "timeUnit": time_unit,
        "keywordGroups": (groups or [])[:5]
    }

    try:
        r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=12)
        r.raise_for_status()
        js = r.json()

        out = []
        for gr in js.get("results", []):
            name = gr.get("title") or (gr.get("keywords") or [""])[0]
            tmp = pd.DataFrame(gr.get("data", []))
            if tmp.empty:
                continue
            tmp["keyword"] = name
            out.append(tmp)

        if not out:
            return pd.DataFrame()

        big = pd.concat(out, ignore_index=True)
        big.rename(columns={"period": "ë‚ ì§œ", "ratio": "ê²€ìƒ‰ì§€ìˆ˜"}, inplace=True)
        pivot = big.pivot_table(index="ë‚ ì§œ", columns="keyword", values="ê²€ìƒ‰ì§€ìˆ˜", aggfunc="mean")
        return pivot.reset_index().sort_values("ë‚ ì§œ")

    except requests.HTTPError as e:
        try:
            msg = r.text
        except Exception:
            msg = str(e)
        st.error(f"DataLab HTTP {r.status_code}: {msg}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"DataLab í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

SEED_MAP = {
    "íŒ¨ì…˜ì˜ë¥˜":   ["ì›í”¼ìŠ¤","ì½”íŠ¸","ë‹ˆíŠ¸","ì…”ì¸ ","ë¸”ë¼ìš°ìŠ¤"],
    "íŒ¨ì…˜ì¡í™”":   ["ê°€ë°©","ì§€ê°‘","ëª¨ì","ìŠ¤ì¹´í”„","ë²¨íŠ¸"],
    "ë·°í‹°/ë¯¸ìš©":  ["ì¿ ì…˜","ë¦½ìŠ¤í‹±","ì„ í¬ë¦¼","ë§ˆìŠ¤ì¹´ë¼","í† ë„ˆ"],
    "ìƒí™œ/ê±´ê°•":  ["ì¹«ì†”","ì¹˜ì•½","ìƒ´í‘¸","ì„¸ì œ","ë¬¼í‹°ìŠˆ"],
    "ë””ì§€í„¸/ê°€ì „": ["ë¸”ë£¨íˆ¬ìŠ¤ì´ì–´í°","ìŠ¤í”¼ì»¤","ëª¨ë‹ˆí„°","ë…¸íŠ¸ë¶","ë¡œë´‡ì²­ì†Œê¸°"],
    "ìŠ¤í¬ì¸ /ë ˆì €": ["ëŸ¬ë‹í™”","ìš”ê°€ë³µ","ìº í•‘ì˜ì","í…íŠ¸","ìì „ê±°"],
}

def section_category_keyword_lab():
    st.markdown('<div class="card"><div class="card-title">ì¹´í…Œê³ ë¦¬ â†’ í‚¤ì›Œë“œ Top20 & íŠ¸ë Œë“œ</div>', unsafe_allow_html=True)
    cA, cB, cC = st.columns([1,1,1])
    with cA:
        cat = st.selectbox("ì¹´í…Œê³ ë¦¬", list(SEED_MAP.keys()))
    with cB:
        time_unit = st.selectbox("ë‹¨ìœ„", ["week", "month"], index=0)
    with cC:
        months = st.slider("ì¡°íšŒê¸°ê°„(ê°œì›”)", 1, 12, 3)
    start = (dt.date.today() - dt.timedelta(days=30 * months)).strftime("%Y-%m-%d")
    end   = (dt.date.today() - dt.timedelta(days=1)).strftime("%Y-%m-%d")

    seeds = SEED_MAP.get(cat, [])
    df = _naver_keywordstool(seeds)
    if df.empty:
        err = st.session_state.pop("__datalab_error", None)
        st.warning("í‚¤ì›Œë“œë„êµ¬ ì‘ë‹µì´ ë¹„ì—ˆìŠµë‹ˆë‹¤. (API/ê¶Œí•œ/ì¿¼í„° í™•ì¸)" + (f" Â· {err}" if err else ""))
        st.markdown('</div>', unsafe_allow_html=True); return

    df["ê²€ìƒ‰í•©ê³„"] = pd.to_numeric(df["PCì›”ê°„ê²€ìƒ‰ìˆ˜"], errors="coerce").fillna(0) + \
                     pd.to_numeric(df["Mobileì›”ê°„ê²€ìƒ‰ìˆ˜"], errors="coerce").fillna(0)
    top20 = df.sort_values("ê²€ìƒ‰í•©ê³„", ascending=False).head(20).reset_index(drop=True)
    st.dataframe(top20[["í‚¤ì›Œë“œ","ê²€ìƒ‰í•©ê³„","PCì›”ê°„ê²€ìƒ‰ìˆ˜","Mobileì›”ê°„ê²€ìƒ‰ìˆ˜","ì›”í‰ê· ë…¸ì¶œê´‘ê³ ìˆ˜","ê´‘ê³ ê²½ìŸì •ë„"]],
                 use_container_width=True, height=340)
    st.download_button("CSV ë‹¤ìš´ë¡œë“œ", top20.to_csv(index=False).encode("utf-8-sig"),
                       file_name=f"category_{cat}_top20.csv", mime="text/csv")

    topk = st.slider("ë¼ì¸ì°¨íŠ¸ í‚¤ì›Œë“œ ìˆ˜", 3, 10, 5, help="ìƒìœ„ Nê°œ í‚¤ì›Œë“œë§Œ íŠ¸ë Œë“œë¥¼ ê·¸ë¦½ë‹ˆë‹¤.")
    kws = top20["í‚¤ì›Œë“œ"].head(topk).tolist()
    groups = [{"groupName": k, "keywords": [k]} for k in kws]
    ts = _datalab_trend(groups, start, end, time_unit=time_unit)
    if ts.empty:
        err = st.session_state.pop("__datalab_error", None)
        st.info("DataLab íŠ¸ë Œë“œ ì‘ë‹µì´ ë¹„ì–´ ìˆì–´ìš”. (Client ID/Secret, Referer/í™˜ê²½, ë‚ ì§œ/ë‹¨ìœ„ í™•ì¸)" + (f" Â· {err}" if err else ""))
    else:
        try:
            st.line_chart(ts.set_index("ë‚ ì§œ"))
        except Exception:
            st.dataframe(ts, use_container_width=True, height=260)
    st.markdown('</div>', unsafe_allow_html=True)

def section_keyword_trend_widget():
    st.markdown('<div class="card"><div class="card-title">í‚¤ì›Œë“œ íŠ¸ë Œë“œ (ì§ì ‘ ì…ë ¥)</div>', unsafe_allow_html=True)
    kwtxt  = st.text_input("í‚¤ì›Œë“œ(ì½¤ë§ˆ)", "ê°€ë°©, ì›í”¼ìŠ¤", key="kw_txt")
    unit   = st.selectbox("ë‹¨ìœ„", ["week", "month"], index=0, key="kw_unit")
    months = st.slider("ì¡°íšŒê¸°ê°„(ê°œì›”)", 1, 12, 3, key="kw_months")
    if st.button("íŠ¸ë Œë“œ ì¡°íšŒ", key="kw_run"):
        start = (dt.date.today() - dt.timedelta(days=30 * months)).strftime("%Y-%m-%d")
        end   = (dt.date.today() - dt.timedelta(days=1)).strftime("%Y-%m-%d")
        kws = [k.strip() for k in (kwtxt or "").split(",") if k.strip()]
        groups = [{"groupName": k, "keywords": [k]} for k in kws][:5]
        df = _datalab_trend(groups, start, end, time_unit=unit)
        if df.empty:
            err = st.session_state.pop("__datalab_error", None)
            st.error("DataLab íŠ¸ë Œë“œ ì‘ë‹µì´ ë¹„ì–´ ìˆì–´ìš”. (Client ID/Secret, Referer/í™˜ê²½, ê¶Œí•œ/ì¿¼í„°/ë‚ ì§œ/ë‹¨ìœ„ í™•ì¸)" + (f" Â· {err}" if err else ""))
        else:
            st.dataframe(df, use_container_width=True, height=260)
            st.line_chart(df.set_index("ë‚ ì§œ"))
    st.markdown('</div>', unsafe_allow_html=True)

# =========================
# 8) Radar Card (tabs: êµ­ë‚´ -> í•´ì™¸)
# =========================
def section_radar():
    st.markdown('<div class="card main"><div class="card-title">AI í‚¤ì›Œë“œ ë ˆì´ë”</div>', unsafe_allow_html=True)
    tab_domestic, tab_overseas = st.tabs(["êµ­ë‚´", "í•´ì™¸"])
    with tab_domestic:
        section_korea_ui()
    with tab_overseas:
        section_rakuten_ui()
    st.markdown('</div>', unsafe_allow_html=True)

# =========================
# Stopwords Manager UI (ê³µìš©) â€” ìƒì„±ê¸° íƒ­/ì™¸ë¶€ ì„¹ì…˜ì—ì„œ ì¬ì‚¬ìš©
# =========================
def _stopwords_manager_ui(compact: bool = False):
    ss = st.session_state
    ss.setdefault("STOP_GLOBAL", list(STOPWORDS_GLOBAL))
    ss.setdefault("STOP_BY_CAT", dict(STOPWORDS_BY_CAT))
    ss.setdefault("STOP_WHITELIST", [])
    ss.setdefault("STOP_REPLACE", ["ë¬´ë°°=> ", "ë¬´ë£Œë°°ì†¡=> ", "ì •í’ˆ=> "])
    ss.setdefault("STOP_AGGR", False)

    # í”„ë¦¬ì…‹(ì»´íŒ©íŠ¸ ëª¨ë“œì—ì„  ìˆ¨ê¹€)
    if not compact:
        with st.expander("ğŸ”§ í”„ë¦¬ì…‹", expanded=False):
            preset = st.selectbox("í”„ë¦¬ì…‹", list(STOP_PRESETS.keys()), key="stop_preset_sel")
            if st.button("í”„ë¦¬ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°", key="stop_preset_load"):
                obj = STOP_PRESETS[preset]
                ss["STOP_GLOBAL"]    = list(obj.get("global", []))
                ss["STOP_BY_CAT"]    = dict(obj.get("by_cat", {}))
                ss["STOP_WHITELIST"] = list(obj.get("whitelist", []))
                ss["STOP_REPLACE"]   = list(obj.get("replace", []))
                ss["STOP_AGGR"]      = bool(obj.get("aggressive", False))
                st.success(f"í”„ë¦¬ì…‹ â€˜{preset}â€™ ì ìš© ì™„ë£Œ")

    tab_global, tab_cat, tab_white, tab_replace, tab_io = st.tabs(
        ["ì „ì—­ ê¸ˆì¹™ì–´", "ì¹´í…Œê³ ë¦¬ ê¸ˆì¹™ì–´", "í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸", "ì¹˜í™˜ ê·œì¹™", "ê°€ì ¸ì˜¤ê¸°/ë‚´ë ¤ë°›ê¸°"]
    )

    with tab_global:
        txt = st.text_area("ì „ì—­ ê¸ˆì¹™ì–´ (ì½¤ë§ˆ)", value=",".join(ss["STOP_GLOBAL"]), height=120, key="stop_glob_txt")
        if st.button("ì €ì¥(ì „ì—­)", key="stop_glob_save"):
            ss["STOP_GLOBAL"] = [t.strip() for t in txt.split(",") if t.strip()]
            st.success("ì „ì—­ ê¸ˆì¹™ì–´ ì €ì¥ ì™„ë£Œ")

    with tab_cat:
        all_cats = sorted(set(list(ss["STOP_BY_CAT"].keys()) + list(STOPWORDS_BY_CAT.keys()))) or \
                   ["íŒ¨ì…˜ì˜ë¥˜","íŒ¨ì…˜ì¡í™”","ë·°í‹°/ë¯¸ìš©","ìƒí™œ/ê±´ê°•","ë””ì§€í„¸/ê°€ì „","ìŠ¤í¬ì¸ /ë ˆì €"]
        cat = st.selectbox("ì¹´í…Œê³ ë¦¬", all_cats, key="stop_cat_sel")
        curr = ",".join(ss["STOP_BY_CAT"].get(cat, []))
        new  = st.text_area("í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ê¸ˆì¹™ì–´ (ì½¤ë§ˆ)", value=curr, height=120, key=f"stop_cat_txt_{cat}")
        c1, c2 = st.columns([1,1])
        with c1:
            if st.button("ì €ì¥(ì¹´í…Œê³ ë¦¬)", key=f"stop_cat_save_{cat}"):
                ss["STOP_BY_CAT"][cat] = [t.strip() for t in new.split(",") if t.strip()]
                st.success(f"{cat} ì €ì¥ ì™„ë£Œ")
        with c2:
            ss["STOP_AGGR"] = st.toggle("ê³µê²©ì  ë¶€ë¶„ì¼ì¹˜ ì œê±°", value=bool(ss["STOP_AGGR"]), key="stop_aggr_ui")

    with tab_white:
        wt = st.text_area("í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸(í—ˆìš©, ì½¤ë§ˆ)", value=",".join(ss["STOP_WHITELIST"]), height=100, key="stop_white_txt")
        if st.button("ì €ì¥(í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸)", key="stop_white_save"):
            ss["STOP_WHITELIST"] = [t.strip() for t in wt.split(",") if t.strip()]
            st.success("í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ")

    with tab_replace:
        rp = st.text_area("ì¹˜í™˜ ê·œì¹™ (í˜•ì‹: src=>dst, ì½¤ë§ˆ)", value=",".join(ss["STOP_REPLACE"]), height=100, key="stop_repl_txt")
        if st.button("ì €ì¥(ì¹˜í™˜)", key="stop_repl_save"):
            ss["STOP_REPLACE"] = [t.strip() for t in rp.split(",") if t.strip()]
            st.success("ì¹˜í™˜ ê·œì¹™ ì €ì¥ ì™„ë£Œ")

    with tab_io:
        payload = {
            "global": ss["STOP_GLOBAL"],
            "by_cat": ss["STOP_BY_CAT"],
            "whitelist": ss["STOP_WHITELIST"],
            "replace": ss["STOP_REPLACE"],
            "aggressive": bool(ss["STOP_AGGR"]),
        }
        st.download_button("ì„¤ì • ë‚´ë ¤ë°›ê¸°(JSON)",
                           data=json.dumps(payload, ensure_ascii=False, indent=2).encode("utf-8"),
                           file_name="stopwords_profile.json", mime="application/json", key="stop_dl")
        up = st.file_uploader("ì„¤ì • ê°€ì ¸ì˜¤ê¸°(JSON)", type=["json"], key="stop_ul")
        if up:
            try:
                obj = json.load(io.TextIOWrapper(up, encoding="utf-8"))
                ss["STOP_GLOBAL"]    = list(obj.get("global", ss["STOP_GLOBAL"]))
                ss["STOP_BY_CAT"]    = dict(obj.get("by_cat", ss["STOP_BY_CAT"]))
                ss["STOP_WHITELIST"] = list(obj.get("whitelist", ss["STOP_WHITELIST"]))
                ss["STOP_REPLACE"]   = list(obj.get("replace", ss["STOP_REPLACE"]))
                ss["STOP_AGGR"]      = bool(obj.get("aggressive", ss["STOP_AGGR"]))
                st.success("ì„¤ì • ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ")
            except Exception as e:
                st.error(f"ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")

# =========================
# 9) ìƒí’ˆëª… ì¶”ì²œ ìƒì„±ê¸° â€” ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ìµœì í™”(Top-N, ê¸ˆì¹™ì–´/ë¸Œëœë“œ ë³´í˜¸)
# =========================

PATTERN_STOPWORDS_GEN = [
    r"í¬ë¥´ë…¸", r"ì„¹ìŠ¤|ì„¹ì“°|ì…ìŠ¤|ìŒ•ìŠ¤", r"ì„¹ë„êµ¬", r"ì˜¤ë‚˜í™€", r"ì‚¬ì •ì§€ì—°", r"ì• ë„",
    r"ìŒë€|ìŒëª¨|ìŒë¶€|ì„±êµ|ì„±ê¸°", r"ì‹œë¶€íŠ¸ë¼ë¯¼|sibutramine", r"ì‹¤ë°ë‚˜í•„|sildenafil",
    r"íƒ€ë‹¤ë¼í•„|tadalafil", r"ë°”ë°ë‚˜í•„|vardenafil", r"ìš”í˜ë¹ˆ|yohim", r"ì—í˜ë“œë¦°",
    r"DMAA|DMBA|DNP", r"ë¶í•œ|ì¸ë¯¼ê³µí™”êµ­|êµ­ê¸°", r"(ì´|ê¶Œì´|íˆ¬ì‹œê²½|ì¹¼|ìƒˆì´)"
]
SEEDED_NONBRAND_LITERALS = ["ê°•ê°„","ì‚´ì¸","ëª°ì¹´","ë„ì´¬","íˆë¡œë½•","ìˆ˜ë©´ì œ","ì•„ë™","ì„ì‚°ë¶€","ì‹ ìƒì•„"]

_BRAND_ASCII_RE = re.compile(r"^[A-Za-z0-9][A-Za-z0-9\-\& ]{1,24}$")
_BRAND_KO_SUFFIX = ("ë‚˜ì´í‚¤","ì•„ë””ë‹¤ìŠ¤","ë‰´ë°œë€ìŠ¤","ìƒ¤ë„¬","ë£¨ì´ë¹„í†µ","êµ¬ì°Œ","í”„ë¼ë‹¤","ë””ì˜¬",
                    "ëª½í´ë ˆì–´","ìŠ¤íƒ€ë²…ìŠ¤","ë¼ì¸í”„ë Œì¦ˆ","í—¬ë¡œí‚¤í‹°","í¬ì¼“ëª¬")

def _is_brandish(x:str)->bool:
    x=(x or "").strip()
    if not x: return False
    if _BRAND_ASCII_RE.match(x): return True
    if any(x.endswith(s) for s in _BRAND_KO_SUFFIX): return True
    return False

PATTERN_RE = re.compile("|".join(PATTERN_STOPWORDS_GEN), re.IGNORECASE)
LITERAL_RE  = re.compile("|".join(re.escape(w) for w in SEEDED_NONBRAND_LITERALS), re.IGNORECASE)

def _apply_filters(text:str, brand_allow:set[str]|None=None)->str:
    brand_allow = {*(brand_allow or set())}
    guard={}
    def protect(tok):
        key=f"Â§{len(guard)}Â§"; guard[key]=tok; return key
    out=text
    for b in sorted(brand_allow, key=len, reverse=True):
        out = re.sub(rf"(?i)\b{re.escape(b)}\b", lambda m: protect(m.group(0)), out)
    out = PATTERN_RE.sub(" ", out)
    out = LITERAL_RE.sub(" ", out)
    out = re.sub(r"\s+"," ", out).strip()
    for k,v in guard.items(): out = out.replace(k,v)
    return out

def _dedupe_tokens(s:str)->str:
    seen=set(); out=[]
    for t in s.split():
        k=t.lower()
        if k in seen: continue
        seen.add(k); out.append(t)
    return " ".join(out)

def _truncate_bytes(text:str, max_bytes:int=50)->str:
    raw=text.encode("utf-8")
    if len(raw)<=max_bytes: return text
    cut=raw[:max_bytes]
    while True:
        try: s=cut.decode("utf-8"); break
        except UnicodeDecodeError: cut=cut[:-1]
    return s.rstrip()+"â€¦"

@st.cache_data(ttl=3600, show_spinner=False)
def _cached_kstats(seed: str) -> pd.DataFrame:
    if not seed: return pd.DataFrame()
    try:
        df = _naver_keywordstool([seed])
    except Exception:
        return pd.DataFrame()
    if df.empty: return pd.DataFrame()
    df["ê²€ìƒ‰í•©ê³„"] = pd.to_numeric(df.get("PCì›”ê°„ê²€ìƒ‰ìˆ˜",0), errors="coerce").fillna(0) + \
                     pd.to_numeric(df.get("Mobileì›”ê°„ê²€ìƒ‰ìˆ˜",0), errors="coerce").fillna(0)
    df["ê´‘ê³ ê²½ìŸì •ë„"] = pd.to_numeric(df.get("ê´‘ê³ ê²½ìŸì •ë„",0), errors="coerce").fillna(0.0)
    return df

def _make_candidates(brand:str, main_kw:str, attrs:list[str], df:pd.DataFrame,
                     N:int, pool_top:int, min_chars:int, max_chars:int,
                     use_competition:bool=True)->list[str]:
    if df.empty or "í‚¤ì›Œë“œ" not in df.columns:
        ranked=[]
    else:
        dd=df.copy()
        if use_competition:
            lam=2.0
            dd["íš¨ìœ¨ì ìˆ˜"]=dd["ê²€ìƒ‰í•©ê³„"]/(1.0+lam*dd["ê´‘ê³ ê²½ìŸì •ë„"].clip(lower=0.0))
            dd=dd.sort_values(["íš¨ìœ¨ì ìˆ˜","ê²€ìƒ‰í•©ê³„"], ascending=[False,False])
        else:
            dd=dd.sort_values("ê²€ìƒ‰í•©ê³„", ascending=False)
        ranked=[x for x in dd["í‚¤ì›Œë“œ"].tolist() if x and x!=main_kw][:pool_top]

    base=[t for t in [brand, main_kw]+attrs if t]
    allow={brand.strip()} | ({main_kw} if _is_brandish(main_kw) else set())
    out=[]; used=set()

    for off in range(min(5, N)):
        for span in (1,2,3):
            if len(out)>=N: break
            chosen=[]
            for i in range(span):
                idx=off+i
                if idx<len(ranked): chosen.append(ranked[idx])
            tokens=base[:]
            for kw in chosen:
                tmp=" ".join(tokens+[kw])
                if _apply_filters(tmp, allow)!=tmp: continue
                if len(tmp)>max_chars: continue
                tokens.append(kw)
            fill=off+span
            while len(" ".join(tokens))<min_chars and fill<len(ranked):
                kw=ranked[fill]; fill+=1
                if kw in tokens: continue
                tmp=" ".join(tokens+[kw])
                if _apply_filters(tmp, allow)!=tmp: continue
                if len(tmp)>max_chars: break
                tokens.append(kw)

            title=" ".join(tokens)
            title=_apply_filters(title, allow)
            title=_dedupe_tokens(title)
            if len(title.encode("utf-8"))>50: title=_truncate_bytes(title, 50)
            k=title.lower().strip()
            if k and k not in used:
                out.append(title); used.add(k)
            if len(out)>=N: break

    i=0
    while len(out)<N and i<len(ranked):
        kw=ranked[i]; i+=1
        title=" ".join(base+[kw])
        title=_apply_filters(title, allow)
        title=_dedupe_tokens(title)
        if len(title.encode("utf-8"))>50: title=_truncate_bytes(title, 50)
        k=title.lower().strip()
        if k and k not in used:
            out.append(title); used.add(k)
    return out[:N]

def _seo_score(title:str, df:pd.DataFrame, w_len:int, w_cover:int, w_pen:int)->dict:
    score=0; reasons=[]
    chars=len(title); by=len(title.encode("utf-8"))
    if 30<=chars<=50 and by<=50:
        score+=w_len; reasons.append(f"ê¸¸ì´ ì í•©(+{w_len})")
    else:
        gain=max(0, w_len - min(abs(chars-40), w_len))
        score+=gain; reasons.append(f"ê¸¸ì´ ë³´ì •(+{gain})")
    cov_gain=0; hit=0
    if not df.empty and "í‚¤ì›Œë“œ" in df.columns:
        top=df.sort_values("ê²€ìƒ‰í•©ê³„",ascending=False).head(10)["í‚¤ì›Œë“œ"].tolist()
        hit=sum(1 for k in top if re.search(rf"(?i)\b{re.escape(k)}\b", title))
        cov_gain=int(round(w_cover * hit/max(len(top),1)))
    score+=cov_gain; reasons.append(f"ìƒìœ„í‚¤ì›Œë“œ í¬í•¨ {cov_gain}/{w_cover}(Top10={hit})")
    if PATTERN_RE.search(title) or LITERAL_RE.search(title):
        score-=w_pen; reasons.append(f"ê¸ˆì¹™ì–´(-{w_pen})")
    return {"score": max(0,min(100,score)), "reasons": reasons, "chars": chars, "bytes": by}

def section_title_generator():
    st.markdown('<div class="card main"><div class="card-title">ìƒí’ˆëª… ìƒì„±ê¸° (ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ Â· Top-N)</div>', unsafe_allow_html=True)

    cA,cB = st.columns([1,2])
    with cA:
        brand = st.text_input("ë¸Œëœë“œ", placeholder="ì˜ˆ: Apple / ë¬´ì§€")
        attrs = st.text_input("ì†ì„±(ì½¤ë§ˆ, ì„ íƒ)", placeholder="ì˜ˆ: ì •í’ˆ, í•œì •íŒ, ì ‘ì´ì‹, ì•Œë£¨ë¯¸ëŠ„")
    with cB:
        kws_raw = st.text_input("í‚¤ì›Œë“œ(ì½¤ë§ˆ)", placeholder="ì˜ˆ: ë…¸íŠ¸ë¶ ìŠ¤íƒ ë“œ, ì ‘ì´ì‹")
        main_kw = next((k.strip() for k in (kws_raw or "").split(",") if k.strip()), "")

    c1,c2,c3,c4 = st.columns([1,1,1,1])
    with c1:
        N = st.slider("ì¶”ì²œ ê°œìˆ˜", 5, 20, 10, 1)
    with c2:
        pool_top = st.slider("í™•ì¥ Pool(ìƒìœ„ ê²€ìƒ‰ì–´)", 5, 30, 20, 1)
    with c3:
        min_chars = st.slider("ìµœì†Œ ê¸€ì(ê¶Œì¥ 30~50)", 30, 50, 35, 1)
    with c4:
        max_chars = st.slider("ìµœëŒ€ ê¸€ì", 30, 50, 50, 1)

    c5,c6,c7 = st.columns([1,1,1])
    with c5:
        use_comp = st.toggle("ê²½ìŸë„ ë³´ì • ì‚¬ìš©", value=True)
    with c6:
        w_len = st.slider("ê°€ì¤‘ì¹˜Â·ê¸¸ì´", 10, 50, 30, 1)
    with c7:
        w_cover = st.slider("ê°€ì¤‘ì¹˜Â·ì»¤ë²„ë¦¬ì§€", 10, 70, 55, 1)
    w_pen = st.slider("ê°€ì¤‘ì¹˜Â·íŒ¨ë„í‹°", 10, 40, 25, 1)

    if st.button("ìƒí’ˆëª… ìƒì„±"):
        if not main_kw:
            st.error("í‚¤ì›Œë“œë¥¼ í•˜ë‚˜ ì´ìƒ ì…ë ¥í•˜ì„¸ìš”."); return
        at_list = [a.strip() for a in (attrs or "").split(",") if a.strip()]

        with st.spinner("ì—°ê´€ í‚¤ì›Œë“œ/ê²€ìƒ‰ëŸ‰ ìˆ˜ì§‘â€¦"):
            df_stats = _cached_kstats(main_kw)

        titles = _make_candidates(
            brand=brand, main_kw=main_kw, attrs=at_list,
            df=df_stats, N=N, pool_top=pool_top,
            min_chars=min_chars, max_chars=max_chars,
            use_competition=use_comp
        )

        rows=[]
        for t in titles:
            sc=_seo_score(t, df_stats, w_len, w_cover, w_pen)
            rows.append({"title": t, "SEOì ìˆ˜": sc["score"],
                         "ì‚¬ìœ ": " / ".join(sc["reasons"]), "ë¬¸ììˆ˜": sc["chars"], "ë°”ì´íŠ¸": sc["bytes"]})
        df_out=pd.DataFrame(rows).sort_values("SEOì ìˆ˜", ascending=False)

        st.success(f"ìƒì„± ì™„ë£Œ Â· {len(df_out)}ê±´")

        mode = st.radio("ê²°ê³¼ í‘œì‹œ", ["ì¹´ë“œ", "í‘œ"], horizontal=True, index=0)
        if mode == "ì¹´ë“œ":
            for i, r in enumerate(df_out.itertuples(index=False), 1):
                warn=[]
                if r.ë¬¸ììˆ˜ < 30: warn.append("30ì ë¯¸ë§Œ")
                if r.ë°”ì´íŠ¸ > 50: warn.append("50ë°”ì´íŠ¸ ì´ˆê³¼")
                suf = "" if not warn else " â€” " + " / ".join([f":red[{w}]" for w in warn])
                st.markdown(
                    f"**{i}.** {r.title}  "
                    f"<span style='opacity:.7'>(ë¬¸ì {r.ë¬¸ììˆ˜}/50 Â· ë°”ì´íŠ¸ {r.ë°”ì´íŠ¸}/50 Â· SEO {r.SEOì ìˆ˜})</span>{suf}",
                    unsafe_allow_html=True
                )
        else:
            st.dataframe(
                df_out[["title","SEOì ìˆ˜","ë¬¸ììˆ˜","ë°”ì´íŠ¸","ì‚¬ìœ "]].reset_index(drop=True),
                use_container_width=True, height=360
            )
        st.download_button(
            "CSV ë‹¤ìš´ë¡œë“œ",
            data=df_out[["title"]].to_csv(index=False).encode("utf-8-sig"),
            file_name="titles_topN.csv",
            mime="text/csv",
        )
    st.markdown("</div>", unsafe_allow_html=True)

# =========================
# 10) ê¸°íƒ€ ì¹´ë“œ
# =========================
def _11st_abest_url():
    return ("https://m.11st.co.kr/page/main/abest?tabId=ABEST&pageId=AMOBEST&ctgr1No=166160&_ts=%d" % int(time.time()))
def section_11st():
    st.markdown('<div class="card main"><div class="card-title">11ë²ˆê°€ (ëª¨ë°”ì¼) â€” ì•„ë§ˆì¡´ ë² ìŠ¤íŠ¸</div>', unsafe_allow_html=True)
    _proxy_iframe(ELEVENST_PROXY, _11st_abest_url(), height=900, scroll=True, key="abest")
    st.markdown('</div>', unsafe_allow_html=True)
def section_itemscout_placeholder():
    st.markdown('<div class="card main"><div class="card-title">ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸</div>', unsafe_allow_html=True)
    st.info("ì„ë² ë“œ ë³´ë¥˜ ì¤‘ì…ë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ì›ë³¸ í˜ì´ì§€ë¥¼ ìƒˆ íƒ­ì—ì„œ ì—¬ì„¸ìš”.")
    st.link_button("ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ ì§ì ‘ ì—´ê¸°(ìƒˆ íƒ­)", "https://app.itemscout.io/market/keyword")
    st.markdown('</div>', unsafe_allow_html=True)
def section_sellerlife_placeholder():
    st.markdown('<div class="card main"><div class="card-title">ì…€ëŸ¬ë¼ì´í”„</div>', unsafe_allow_html=True)
    st.info("ì„ë² ë“œ ë³´ë¥˜ ì¤‘ì…ë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ì›ë³¸ í˜ì´ì§€ë¥¼ ìƒˆ íƒ­ì—ì„œ ì—¬ì„¸ìš”.")
    st.link_button("ì§ì ‘ ì—´ê¸°(ìƒˆ íƒ­)", "https://sellochomes.co.kr/sellerlife/")
    st.markdown('</div>', unsafe_allow_html=True)

# =========================
# ì™¸ë¶€ Stopwords ì„¹ì…˜(ì„ íƒ)
# =========================
def section_stopwords_manager():
    st.markdown('<div class="card main"><div class="card-title">ê¸ˆì¹™ì–´ ë¦¬ìŠ¤íŠ¸ ê´€ë¦¬ì (í˜„ì—…ìš©)</div>', unsafe_allow_html=True)
    _stopwords_manager_ui(compact=False)

# =========================
# 11) Layout â€” row1: Radar | (ì¹´í…Œê³ ë¦¬ or ì§ì ‘ ì…ë ¥) | ìƒí’ˆëª… ìƒì„±ê¸°
# =========================
_ = _sidebar()
_responsive_probe()
vwbin = _get_view_bin()

st.title("ENVY â€” Season 1 (Dual Proxy Edition)")

# 1í–‰
row1_a, row1_b, row1_c = st.columns([8, 4, 4], gap="medium")
with row1_a:
    section_radar()
with row1_b:
    tab_cat, tab_direct = st.tabs(["ì¹´í…Œê³ ë¦¬", "ì§ì ‘ ì…ë ¥"])
    with tab_cat:
        section_category_keyword_lab()
    with tab_direct:
        section_keyword_trend_widget()
with row1_c:
    section_title_generator()

st.markdown('<div class="row-gap"></div>', unsafe_allow_html=True)

# 2í–‰
c1, c2, c3 = st.columns([3, 3, 3], gap="medium")
with c1:
    section_11st()
with c2:
    section_itemscout_placeholder()
with c3:
    section_sellerlife_placeholder()

st.markdown('<div class="row-gap"></div>', unsafe_allow_html=True)
