# =========================
# ENVY â€” Season 1 (one-file, parts in order)
# =========================
import os, re, json
from datetime import date, timedelta
from typing import Any, List, Dict
from collections import defaultdict
from urllib.parse import quote

import streamlit as st
import pandas as pd
import numpy as np

# ì™¸ë¶€ ëª¨ë“ˆ(ë¯¸ì„¤ì¹˜ ì‹œ ì•ˆë‚´ë§Œ)
try:
    import requests
except Exception:
    requests = None

try:
    from deep_translator import GoogleTranslator
except Exception:
    GoogleTranslator = None


# =========================
# Part 1 â€” ì‚¬ì´ë“œë°” (ë¡œê³  + í™˜ìœ¨/ë§ˆì§„ ê³„ì‚°ê¸° + í”„ë¡ì‹œ ì…ë ¥)
# =========================
CURRENCIES = {
    "USD": {"kr": "ë¯¸êµ­ ë‹¬ëŸ¬", "symbol": "$", "unit": "USD"},
    "EUR": {"kr": "ìœ ë¡œ",     "symbol": "â‚¬", "unit": "EUR"},
    "JPY": {"kr": "ì¼ë³¸ ì—”",   "symbol": "Â¥", "unit": "JPY"},
    "CNY": {"kr": "ì¤‘êµ­ ìœ„ì•ˆ", "symbol": "å…ƒ","unit": "CNY"},
}
FX_DEFAULT = {"USD": 1400.0, "EUR": 1500.0, "JPY": 10.0, "CNY": 200.0}

def _ensure_session_defaults():
    ss = st.session_state
    ss.setdefault("theme", "light")
    ss.setdefault("PROXY_URL", "")
    # í™˜ìœ¨/ë§ˆì§„ ê³„ì‚°ê¸° ê¸°ë³¸ê°’
    ss.setdefault("fx_base", "USD")
    ss.setdefault("sale_foreign", 1.00)
    ss.setdefault("m_base", "USD")
    ss.setdefault("purchase_foreign", 0.00)
    ss.setdefault("card_fee_pct", 4.00)
    ss.setdefault("market_fee_pct", 14.00)
    ss.setdefault("shipping_won", 0.0)
    ss.setdefault("margin_mode", "í¼ì„¼íŠ¸")  # or "í”ŒëŸ¬ìŠ¤"
    ss.setdefault("margin_pct", 10.00)
    ss.setdefault("margin_won", 10000.0)

def _toggle_theme():
    st.session_state["theme"] = "dark" if st.session_state.get("theme","light")=="light" else "light"

def _inject_sidebar_css():
    theme = st.session_state.get("theme","light")
    bg, fg = ("#0e1117", "#e6edf3") if theme=="dark" else ("#ffffff","#111111")
    st.markdown(f"""
    <style>
      html, body, [data-testid="stAppViewContainer"] {{
        background-color:{bg} !important; color:{fg} !important;
      }}
      .block-container {{ padding-top:.8rem !important; padding-bottom:1rem !important; }}
      /* ì‚¬ì´ë“œë°” ê³ ì •(lock) â€” ë©”ì¸ì—ì„œ overflow ì¬í—ˆìš©ìœ¼ë¡œ ë®ì–´ì”€ */
      [data-testid="stSidebar"],
      [data-testid="stSidebar"] > div:first-child,
      [data-testid="stSidebar"] section {{
        height: 100vh !important; overflow: hidden !important;
        padding-top:.25rem !important; padding-bottom:.25rem !important;
      }}
      [data-testid="stSidebar"] ::-webkit-scrollbar {{ display:none !important; }}
      /* ê°„ê²©/ì…ë ¥ ê²½ëŸ‰í™” */
      [data-testid="stSidebar"] .stSelectbox,
      [data-testid="stSidebar"] .stNumberInput,
      [data-testid="stSidebar"] .stRadio,
      [data-testid="stSidebar"] .stMarkdown,
      [data-testid="stSidebar"] .stTextInput,
      [data-testid="stSidebar"] .stButton {{ margin:.14rem 0 !important; }}
      [data-baseweb="input"] input,
      .stNumberInput input,
      [data-baseweb="select"] div[role="combobox"] {{
        height:1.55rem !important; padding:.12rem !important; font-size:.92rem !important;
      }}
      /* ë¡œê³  */
      .logo-circle {{
        width:95px; height:95px; border-radius:50%; overflow:hidden;
        margin:.15rem auto .35rem auto; box-shadow:0 2px 8px rgba(0,0,0,.12);
        border:1px solid rgba(0,0,0,.06);
      }}
      .logo-circle img {{ width:100%; height:100%; object-fit:cover; }}
      /* ë°°ì§€ */
      .badge-green  {{ background:#e6ffcc; border:1px solid #b6f3a4; padding:6px 10px; border-radius:6px; color:#0b2e13; font-size:.86rem; }}
      .badge-blue   {{ background:#eef4ff; border:1px solid #bcd0ff; padding:6px 10px; border-radius:6px; color:#0a235a; font-size:.86rem; }}
      .badge-yellow {{ background:#fff7d6; border:1px solid #f1d27a; padding:6px 10px; border-radius:6px; color:#4a3b07; font-size:.86rem; }}
      .muted        {{ opacity:.8; font-size:.8rem; }}
      .info-box {{ background:rgba(0,0,0,.03); border:1px dashed rgba(0,0,0,.08); padding:.6rem; border-radius:.5rem; }}
    </style>
    """, unsafe_allow_html=True)

def render_sidebar() -> dict:
    _ensure_session_defaults()
    _inject_sidebar_css()

    result = {}
    with st.sidebar:
        # ë¡œê³ 
        from pathlib import Path
        lp = Path(__file__).parent / "logo.png"
        if lp.exists():
            import base64
            b64 = base64.b64encode(lp.read_bytes()).decode("ascii")
            st.markdown(f'<div class="logo-circle"><img src="data:image/png;base64,{b64}"></div>', unsafe_allow_html=True)
        else:
            st.caption("logo.png ë¥¼ ì•± íŒŒì¼ê³¼ ê°™ì€ í´ë”ì— ë‘ë©´ ë¡œê³ ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

        # í…Œë§ˆ í† ê¸€
        st.toggle("ğŸŒ“ ë‹¤í¬ ëª¨ë“œ", value=(st.session_state.get("theme","light")=="dark"), on_change=_toggle_theme, key="__theme_toggle")

        # â‘  í™˜ìœ¨ ê³„ì‚°ê¸°
        st.markdown("### â‘  í™˜ìœ¨ ê³„ì‚°ê¸°")
        base = st.selectbox("ê¸°ì¤€ í†µí™”", list(CURRENCIES.keys()),
                            index=list(CURRENCIES.keys()).index(st.session_state["fx_base"]),
                            key="fx_base")
        sale_foreign = st.number_input("íŒë§¤ê¸ˆì•¡ (ì™¸í™”)", value=float(st.session_state["sale_foreign"]), step=0.01, format="%.2f", key="sale_foreign")
        won = FX_DEFAULT[base] * sale_foreign
        st.markdown(
            f'<div class="badge-green">í™˜ì‚° ê¸ˆì•¡: <b>{won:,.2f} ì›</b> '
            f'<span class="muted">({CURRENCIES[base]["kr"]} â€¢ {CURRENCIES[base]["symbol"]})</span></div>',
            unsafe_allow_html=True
        )
        st.caption(f"í™˜ìœ¨ ê¸°ì¤€: {FX_DEFAULT[base]:,.2f} â‚©/{CURRENCIES[base]['unit']}")

        # â‘¡ ë§ˆì§„ ê³„ì‚°ê¸°
        st.markdown("### â‘¡ ë§ˆì§„ ê³„ì‚°ê¸°")
        m_base = st.selectbox("ë§¤ì… í†µí™”", list(CURRENCIES.keys()),
                              index=list(CURRENCIES.keys()).index(st.session_state["m_base"]),
                              key="m_base")
        purchase_foreign = st.number_input("ë§¤ì…ê¸ˆì•¡ (ì™¸í™”)", value=float(st.session_state["purchase_foreign"]), step=0.01, format="%.2f", key="purchase_foreign")
        base_cost_won = FX_DEFAULT[m_base] * purchase_foreign if purchase_foreign>0 else won
        st.markdown(f'<div class="badge-green">ì›ê°€(â‚©): <b>{base_cost_won:,.2f} ì›</b></div>', unsafe_allow_html=True)

        colf1, colf2 = st.columns(2)
        with colf1:
            card_fee = st.number_input("ì¹´ë“œìˆ˜ìˆ˜ë£Œ(%)", value=float(st.session_state["card_fee_pct"]), step=0.01, format="%.2f", key="card_fee_pct")
        with colf2:
            market_fee = st.number_input("ë§ˆì¼“ìˆ˜ìˆ˜ë£Œ(%)", value=float(st.session_state["market_fee_pct"]), step=0.01, format="%.2f", key="market_fee_pct")
        shipping_won = st.number_input("ë°°ì†¡ë¹„(â‚©)", value=float(st.session_state["shipping_won"]), step=100.0, format="%.0f", key="shipping_won")

        mode = st.radio("ë§ˆì§„ ë°©ì‹", ["í¼ì„¼íŠ¸","í”ŒëŸ¬ìŠ¤"], horizontal=True, key="margin_mode")
        if mode == "í¼ì„¼íŠ¸":
            margin_pct = st.number_input("ë§ˆì§„ìœ¨ (%)", value=float(st.session_state["margin_pct"]), step=0.01, format="%.2f", key="margin_pct")
            target_price = base_cost_won * (1 + card_fee/100) * (1 + market_fee/100) * (1 + margin_pct/100) + shipping_won
            margin_value = target_price - base_cost_won
            margin_desc = f"{margin_pct:.2f}%"
        else:
            margin_won = st.number_input("ë§ˆì§„ì•¡ (â‚©)", value=float(st.session_state["margin_won"]), step=100.0, format="%.0f", key="margin_won")
            target_price = base_cost_won * (1 + card_fee/100) * (1 + market_fee/100) + margin_won + shipping_won
            margin_value = margin_won
            margin_desc = f"+{margin_won:,.0f}"

        st.markdown(f'<div class="badge-blue">íŒë§¤ê°€: <b>{target_price:,.2f} ì›</b></div>', unsafe_allow_html=True)
        st.markdown(f'<div class="badge-yellow">ìˆœì´ìµ(ë§ˆì§„): <b>{margin_value:,.2f} ì›</b> â€” {margin_desc}</div>', unsafe_allow_html=True)

        # í•˜ë‹¨: PROXY_URL + í”„ë¡œê·¸ë¨ ì •ë³´
        st.divider()
        st.markdown("##### í”„ë¡ì‹œ/í™˜ê²½")
        st.text_input("PROXY_URL (Cloudflare Worker ë“±)", value=st.session_state.get("PROXY_URL",""), key="PROXY_URL", help="ì˜ˆ: https://envy-proxy.example.workers.dev/")
        st.markdown("""
            <div class="info-box">
              <b>ENVY</b> ì‚¬ì´ë“œë°” ì •ë³´ëŠ” ê³ ì •ì…ë‹ˆë‹¤.<br/>
              Â· ë¡œê³ /í™˜ìœ¨/ë§ˆì§„ ê³„ì‚°ê¸°: ë³€ê²½ ê¸ˆì§€<br/>
              Â· PROXY_URL: 11ë²ˆê°€/ë°ì´í„°ë©/ì„ë² ë“œìš©(í•„ìš”ì‹œ)<br/>
              Â· ë‹¤í¬/ë¼ì´íŠ¸ ëª¨ë“œëŠ” ìƒë‹¨ í† ê¸€
            </div>
        """, unsafe_allow_html=True)

    result.update({
        "fx_base": base,
        "sale_foreign": sale_foreign,
        "converted_won": won,
        "purchase_base": m_base,
        "purchase_foreign": purchase_foreign,
        "base_cost_won": base_cost_won,
        "card_fee_pct": card_fee,
        "market_fee_pct": market_fee,
        "shipping_won": shipping_won,
        "margin_mode": mode,
        "target_price": target_price,
        "margin_value": margin_value,
    })
    return result


# =========================
# Part 2 â€” ê³µìš© ìœ í‹¸ + ì „ì—­ CSS
# =========================
LANG_LABELS = {
    "auto":"ìë™ ê°ì§€",
    "ko":"í•œêµ­ì–´","en":"ì˜ì–´","ja":"ì¼ë³¸ì–´",
    "zh-CN":"ì¤‘êµ­ì–´(ê°„ì²´)","zh-TW":"ì¤‘êµ­ì–´(ë²ˆì²´)",
    "vi":"ë² íŠ¸ë‚¨ì–´","th":"íƒœêµ­ì–´","id":"ì¸ë„ë„¤ì‹œì•„ì–´",
    "de":"ë…ì¼ì–´","fr":"í”„ë‘ìŠ¤ì–´","es":"ìŠ¤í˜ì¸ì–´","it":"ì´íƒˆë¦¬ì•„ì–´","pt":"í¬ë¥´íˆ¬ê°ˆì–´",
}

def lang_label_to_code(label_or_code:str) -> str:
    rev = {v:k for k,v in LANG_LABELS.items()}
    return rev.get(label_or_code, label_or_code)

def toast_ok(msg:str): st.toast(f"âœ… {msg}")
def toast_warn(msg:str): st.toast(f"âš ï¸ {msg}")
def toast_err(msg:str): st.toast(f"âŒ {msg}")

def inject_global_css():
    st.markdown("""
    <style>
      .block-container { max-width: 1680px !important; padding-top:.8rem !important; padding-bottom:1rem !important; }
      html, body { overflow: auto !important; } /* ë³¸ë¬¸ ìŠ¤í¬ë¡¤ í—ˆìš© */
      [data-testid="stSidebar"] section { overflow-y: auto !important; } /* ì‚¬ì´ë“œë°” ë‚´ë¶€ ìŠ¤í¬ë¡¤ í—ˆìš© */
      h2, h3 { margin-top: .4rem !important; }
    </style>
    """, unsafe_allow_html=True)


# =========================
# Part 3 â€” ë°ì´í„°ë© (ë¶„ì„ Top20 + íŠ¸ë Œë“œ) & ì›ë³¸ ì„ë² ë“œ
# =========================
DATALAB_CATS = [
    'íŒ¨ì…˜ì˜ë¥˜','íŒ¨ì…˜ì¡í™”','í™”ì¥í’ˆ/ë¯¸ìš©','ë””ì§€í„¸/ê°€ì „','ê°€êµ¬/ì¸í…Œë¦¬ì–´',
    'ì¶œì‚°/ìœ¡ì•„','ì‹í’ˆ','ìŠ¤í¬ì¸ /ë ˆì €','ìƒí™œ/ê±´ê°•','ì—¬ê°€/ìƒí™œí¸ì˜','ë©´ì„¸ì ','ë„ì„œ'
]
CID_MAP = {
    'íŒ¨ì…˜ì˜ë¥˜':'50000000','íŒ¨ì…˜ì¡í™”':'50000001','í™”ì¥í’ˆ/ë¯¸ìš©':'50000002','ë””ì§€í„¸/ê°€ì „':'50000003',
    'ê°€êµ¬/ì¸í…Œë¦¬ì–´':'50000004','ì¶œì‚°/ìœ¡ì•„':'50000005','ì‹í’ˆ':'50000006','ìŠ¤í¬ì¸ /ë ˆì €':'50000007',
    'ìƒí™œ/ê±´ê°•':'50000008','ì—¬ê°€/ìƒí™œí¸ì˜':'50000009','ë©´ì„¸ì ':'50000010','ë„ì„œ':'50005542',
}

def _naver_cookie() -> str:
    try:
        v = st.secrets.get('NAVER_COOKIE', '')
    except Exception:
        v = ''
    if v: return v.strip()
    env = os.getenv('NAVER_COOKIE', '').strip()
    if env: return env
    return st.session_state.get('__NAVER_COOKIE', '').strip()

def _hdr(cookie: str, cid: str, time_unit: str='week', device: str='all', as_json: bool=True) -> dict:
    h = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124 Safari/537.36",
        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
        "Origin": "https://datalab.naver.com",
        "Referer": f"https://datalab.naver.com/shoppingInsight/sCategory.naver?cid={cid}&timeUnit={time_unit}&device={device}",
        "Cookie": cookie.strip(),
    }
    if as_json:
        h["Accept"] = "application/json, text/plain, */*"
        h["Content-Type"] = "application/x-www-form-urlencoded; charset=UTF-8"
        h["X-Requested-With"] = "XMLHttpRequest"
    else:
        h["Accept"] = "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
    return h

def _to_float(v) -> float:
    if v is None: return 0.0
    if isinstance(v, (int,float)): return float(v)
    s = str(v).replace(',', '')
    m = re.search(r'-?\d+(?:\.\d+)?', s)
    return float(m.group(0)) if m else 0.0

def _normalize_top20(obj: Any) -> List[dict]:
    rows: List[dict] = []
    if isinstance(obj, dict) and isinstance(obj.get("ranks"), list):
        for i, d in enumerate(obj["ranks"], 1):
            kw = (d.get("keyword") or d.get("relKeyword") or "").strip()
            sc = None
            for k in ("ratio","ratioValue","value","score","count","ratioIndex"):
                if k in d: sc = _to_float(d.get(k)); break
            if kw: rows.append({"rank": i, "keyword": kw, "score": 0.0 if sc is None else sc})

    def consider(d: dict):
        kw = (d.get('keyword') or d.get('relKeyword') or d.get('name') or d.get('key') or '').strip()
        sc = None
        for k in ('ratio','ratioValue','ratioIndex','value','score','count'):
            if k in d: sc = _to_float(d.get(k)); break
        if kw: rows.append({'keyword': kw, 'score': 0.0 if sc is None else sc})

    def walk(o):
        if isinstance(o, dict):
            if "ranks" in o and isinstance(o["ranks"], list):
                for i, d in enumerate(o["ranks"], 1):
                    kw = (d.get("keyword") or d.get("relKeyword") or "").strip()
                    sc = None
                    for k in ("ratio","ratioValue","value","score","count","ratioIndex"):
                        if k in d: sc = _to_float(d.get(k)); break
                    if kw: rows.append({"rank": i, "keyword": kw, "score": 0.0 if sc is None else sc})
            for v in o.values():
                if isinstance(v, (dict, list)): walk(v)
            consider(o)
        elif isinstance(o, list):
            for v in o: walk(v)
    walk(obj)

    best = {}
    for r in rows:
        k = r["keyword"]; s = float(r.get("score", 0) or 0)
        if k and (k not in best or s > best[k]["score"]): best[k] = {"keyword": k, "score": s}
    out = list(best.values()); out.sort(key=lambda x: x.get("score", 0), reverse=True); out = out[:20]
    for i, r in enumerate(out, 1): r["rank"] = i
    return out

def _extract_top20_from_text(txt: str) -> List[dict]:
    # 1) {"message":null, "ranks":[...]}
    for m in re.finditer(r'\{"message"\s*:\s*null.*?\}', txt, re.S):
        try:
            data = json.loads(m.group(0))
            rows = _normalize_top20(data)
            if rows: return rows
        except Exception: pass
    # 2) "ranks":[...]
    m = re.search(r'"ranks"\s*:\s*(\[[^\]]+\])', txt, re.S)
    if m:
        try:
            arr = json.loads(m.group(1))
            return _normalize_top20({"ranks": arr})
        except Exception: pass
    # 3) keyword/ratio ê¸ê¸°
    pats = [
        r'"keyword"\s*:\s*"([^"]+)"[^}]*?(?:ratio|ratioValue|value|score)"\s*:\s*"?(?P<num>[-\d.,]+%?)"?',
        r'"relKeyword"\s*:\s*"([^"]+)"[^}]*?(?:ratio|ratioValue|value|score)"\s*:\s*"?(?P<num>[-\d.,]+%?)"?',
    ]
    kv = defaultdict(float)
    for p in pats:
        for kw, sc in re.findall(p, txt):
            kw = kw.strip(); val = _to_float(sc)
            if kw and val > kv[kw]: kv[kw] = val
    rows = [{"keyword": k, "score": v} for k, v in kv.items()]
    rows.sort(key=lambda x: x["score"], reverse=True); rows = rows[:20]
    for i, r in enumerate(rows, 1): r["rank"] = i
    return rows

@st.cache_data(show_spinner=False, ttl=600)
def _fetch_top20(cookie: str, cid: str, start: str, end: str) -> dict:
    if not requests: return {"ok": False, "reason": "requests ë¯¸ì„¤ì¹˜"}
    tried, last_json, last_reason = [], None, ""
    base_kw = "https://datalab.naver.com/shoppingInsight/getCategoryKeywordRank.naver"

    for method in ("POST","GET"):
        for time_unit in ("week","date"):
            for device in ("all","pc","mo"):
                for age_key in ("age","ages"):
                    tried.append(f"{method}:{time_unit}/{device}/{age_key}")
                    payload = {"cid": str(cid).strip(),"timeUnit": time_unit,"startDate": start,"endDate": end,"device": device,"gender": "all"}
                    payload[age_key] = "all"
                    try:
                        if method=="POST":
                            r = requests.post(base_kw, headers=_hdr(cookie, cid, time_unit, device, as_json=True),
                                              data=payload, timeout=12, allow_redirects=False)
                        else:
                            r = requests.get(base_kw, headers=_hdr(cookie, cid, time_unit, device, as_json=True),
                                             params=payload, timeout=12, allow_redirects=False)
                        ct = (r.headers.get("content-type") or "").lower()
                        if r.status_code in (301,302,303,307,308): return {"ok": False, "reason": "302 ë¦¬ë‹¤ì´ë ‰íŠ¸ â€” ì¿ í‚¤ ë§Œë£Œ/ë¡œê·¸ì¸ í•„ìš”", "tried": tried}
                        if "text/html" in ct: last_reason = "HTML ì‘ë‹µ â€” ì¿ í‚¤/ë¦¬í¼ëŸ¬ ë¶ˆì¼ì¹˜"; continue
                        r.raise_for_status()
                        data = r.json(); last_json = data
                        rows = _normalize_top20(data)
                        if rows: return {"ok": True, "rows": rows}
                        last_reason = "ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨(êµ¬ì¡° ë³€ê²½ ê°€ëŠ¥ì„±)"
                    except Exception as e:
                        last_reason = f"ìš”ì²­ ì‹¤íŒ¨: {e}"

    base_cat = "https://datalab.naver.com/shoppingInsight/getCategory.naver"
    for time_unit in ("week","date"):
        for device in ("all","pc","mo"):
            for age_key in ("age","ages"):
                tried.append(f"GET:getCategory/{time_unit}/{device}/{age_key}")
                params = {"cid": str(cid).strip(),"timeUnit": time_unit,"startDate": start,"endDate": end,"device": device,"gender": "all"}
                params[age_key] = "all"
                try:
                    r = requests.get(base_cat, headers=_hdr(cookie, cid, time_unit, device, as_json=True),
                                     params=params, timeout=12, allow_redirects=False)
                    if r.status_code in (301,302,303,307,308): return {"ok": False, "reason": "302 ë¦¬ë‹¤ì´ë ‰íŠ¸ â€” ì¿ í‚¤ ë§Œë£Œ/ë¡œê·¸ì¸ í•„ìš”", "tried": tried}
                    ct = (r.headers.get("content-type") or "").lower()
                    if "application/json" in ct:
                        data = r.json(); last_json = data
                        rows = _normalize_top20(data)
                        if rows: return {"ok": True, "rows": rows}
                        rows = _extract_top20_from_text(r.text or "")
                        if rows: return {"ok": True, "rows": rows}
                    else:
                        rows = _extract_top20_from_text(r.text or "")
                        if rows: return {"ok": True, "rows": rows}
                    last_reason = "getCategory ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨"
                except Exception as e:
                    last_reason = f"getCategory ì‹¤íŒ¨: {e}"

    try:
        page_url = ("https://datalab.naver.com/shoppingInsight/sCategory.naver"
                    f"?cid={cid}&timeUnit=week&startDate={start}&endDate={end}&device=all&gender=all&ages=all")
        r = requests.get(page_url, headers=_hdr(cookie, cid, as_json=False),
                         timeout=12, allow_redirects=False)
        if r.status_code in (301,302,303,307,308): return {"ok": False, "reason": "302 ë¦¬ë‹¤ì´ë ‰íŠ¸ â€” ì¿ í‚¤ ë§Œë£Œ/ë¡œê·¸ì¸ í•„ìš”", "tried": tried}
        html = r.text or ""; rows = _extract_top20_from_text(html)
        if rows: return {"ok": True, "rows": rows, "fallback": "html"}
        sample = ""
        try:
            if last_json is not None: sample = json.dumps(last_json, ensure_ascii=False)[:800]
        except Exception: pass
        return {"ok": False, "reason": last_reason or "ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨", "tried": tried, "sample": sample}
    except Exception as e:
        sample = ""
        try:
            if last_json is not None: sample = json.dumps(last_json, ensure_ascii=False)[:800]
        except Exception: pass
        return {"ok": False, "reason": f"HTML í´ë°± ì‹¤íŒ¨: {e}", "tried": tried, "sample": sample}

@st.cache_data(show_spinner=False, ttl=600)
def _fetch_trend(cookie: str, keywords: List[str], start: str, end: str) -> pd.DataFrame:
    if not (requests and keywords): return pd.DataFrame()
    url = "https://datalab.naver.com/shoppingInsight/getKeywordTrends.naver"
    headers = _hdr(cookie, cid='50000000', as_json=True)
    payload = {
        "timeUnit": "week","startDate": start,"endDate": end,
        "keyword": json.dumps([{"name": k.strip(), "param": [k.strip()]} for k in keywords], ensure_ascii=False),
        "device": "all","gender": "all","ages": "all",
    }
    try:
        r = requests.post(url, headers=headers, data=payload, timeout=12, allow_redirects=False)
        ct = (r.headers.get("content-type") or "").lower()
        if r.status_code in (301,302,303,307,308) or "text/html" in ct: return pd.DataFrame()
        r.raise_for_status(); data = r.json()
    except Exception: return pd.DataFrame()

    series: Dict[str, list] = {}
    def walk(o):
        if isinstance(o, dict):
            title = o.get("title") or o.get("name")
            data_list = o.get("data")
            if title and isinstance(data_list, list):
                for i, p in enumerate(data_list):
                    period = p.get("period") or p.get("date") or f"P{i}"
                    ratio  = p.get("ratio")  or p.get("value") or 0
                    series.setdefault("period", []).append(period)
                    series.setdefault(title, []).append(ratio)
            for v in o.values():
                if isinstance(v, (dict, list)): walk(v)
        elif isinstance(o, list):
            for v in o: walk(v)
    walk(data)
    if not series: return pd.DataFrame()
    df = pd.DataFrame(series)
    if "period" in df.columns: df = df.set_index("period")
    return df

def render_datalab_block():
    st.markdown("## ë°ì´í„°ë© (ë¶„ì„)")
    cookie = _naver_cookie()
    if not cookie:
        with st.expander("NAVER_COOKIE ì…ë ¥(ìµœì´ˆ 1íšŒ)", expanded=True):
            c = st.text_input("ì¿ í‚¤ ì „ì²´ ë¬¸ìì—´", type="password",
                              help="datalab.naver.com ë¡œê·¸ì¸ ìƒíƒœì—ì„œ NID_* í¬í•¨ ì „ì²´ ì¿ í‚¤ ë³µì‚¬/ë¶™ì—¬ë„£ê¸°")
            if c:
                st.session_state["__NAVER_COOKIE"] = c.strip()
                cookie = c.strip()
                st.success("ì„¸ì…˜ ì €ì¥ ì™„ë£Œ")

    c1, c2 = st.columns([1.1, 1.4])
    with c1:
        cat = st.selectbox("ì¹´í…Œê³ ë¦¬", DATALAB_CATS, key="dl_cat_simple")
        cid = CID_MAP.get(cat, "50000000")
        today = date.today()
        start = st.date_input("ì‹œì‘ì¼", value=today - timedelta(days=30), key="dl_start_simple")
        end   = st.date_input("ì¢…ë£Œì¼", value=today, key="dl_end_simple")
        btn = st.button("Top20 ë¶ˆëŸ¬ì˜¤ê¸°", key="dl_go_simple", use_container_width=True)

        top_df = pd.DataFrame()
        if btn:
            if not cookie:
                st.error("NAVER_COOKIEê°€ í•„ìš”í•©ë‹ˆë‹¤. ìœ„ì—ì„œ í•œ ë²ˆë§Œ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            else:
                res = _fetch_top20(cookie, cid, str(start), str(end))
                if not res.get("ok"):
                    st.error(f"ì¡°íšŒ ì‹¤íŒ¨: {res.get('reason')}")
                    if res.get("tried"): st.caption("ì‹œë„: " + ", ".join(res["tried"]))
                    if res.get("sample"): st.caption("ì‘ë‹µ ìƒ˜í”Œ:"); st.code(res["sample"])
                else:
                    top_df = pd.DataFrame(res["rows"], columns=["rank","keyword","score"])
                    st.dataframe(top_df, hide_index=True, use_container_width=True, height=420)

        st.session_state.setdefault("_top_keywords", [])
        if not top_df.empty: st.session_state["_top_keywords"] = top_df["keyword"].tolist()

    with c2:
        st.markdown("### ì„ íƒ í‚¤ì›Œë“œ íŠ¸ë Œë“œ")
        kw_source = st.session_state.get("_top_keywords", [])
        if kw_source:
            picks = st.multiselect("í‚¤ì›Œë“œ(ìµœëŒ€ 5ê°œ)", kw_source, default=kw_source[:3],
                                   max_selections=5, key="dl_kw_picks")
            if st.button("íŠ¸ë Œë“œ ë³´ê¸°", key="dl_trend_simple"):
                if not cookie:
                    st.error("NAVER_COOKIEê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                elif not picks:
                    st.warning("í‚¤ì›Œë“œë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
                else:
                    df_line = _fetch_trend(cookie, picks,
                                           str(st.session_state["dl_start_simple"]),
                                           str(st.session_state["dl_end_simple"]))
                    if df_line.empty:
                        x = np.arange(0, 12)
                        base = 50 + 5*np.sin(x/2)
                        df_line = pd.DataFrame({
                            (picks[0] if len(picks)>0 else "kw1"): base,
                            (picks[1] if len(picks)>1 else "kw2"): base-5 + 3*np.cos(x/3),
                            (picks[2] if len(picks)>2 else "kw3"): base+3 + 4*np.sin(x/4),
                        }, index=[f"P{i}" for i in range(len(x))])
                        st.info("ì‹¤ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ â€” ìƒ˜í”Œ ë¼ì¸ì„ í‘œì‹œí•©ë‹ˆë‹¤.")
                    st.line_chart(df_line, height=260, use_container_width=True)
        else:
            st.caption("ì¢Œì¸¡ì—ì„œ Top20ì„ ë¨¼ì € ë¶ˆëŸ¬ì˜¤ë©´ ì—¬ê¸°ì„œ íŠ¸ë Œë“œë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

def render_datalab_embed_block():
    st.markdown("## ë°ì´í„°ë© (ì›ë³¸ ì„ë² ë“œ)")
    _CATS = list(CID_MAP.keys())

    colA, colB, colC = st.columns([1.2, 1, 1])
    with colA:
        cat = st.selectbox("ì¹´í…Œê³ ë¦¬", _CATS, index=3, key="dl_embed_cat")
        cid = CID_MAP.get(cat, "50000003")
    with colB:
        time_unit = st.selectbox("ê¸°ê°„ ë‹¨ìœ„", ["week","month"], index=0, key="dl_embed_timeunit")
    with colC:
        device = st.selectbox("ê¸°ê¸°", ["all","pc","mo"], index=0, key="dl_embed_device")

    proxy = (st.session_state.get("PROXY_URL") or "").strip().rstrip("/")
    if not proxy:
        st.warning("PROXY_URL ì—†ìŒ â€” ì‚¬ì´ë“œë°” í•˜ë‹¨ì— Cloudflare Worker ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        return

    target = f"https://datalab.naver.com/shoppingInsight/sCategory.naver?cid={cid}&timeUnit={time_unit}&device={device}&gender=all&ages=all"
    embed_url = f"{proxy}/?url={quote(target, safe=':/?&=%')}"
    st.components.v1.iframe(embed_url, height=980, scrolling=True)
    st.caption("í”„ë¡ì‹œê°€ ì¿ í‚¤/í—¤ë”ë¥¼ ì„œë²„ ì¸¡ì—ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì•±ì—ëŠ” ì¿ í‚¤ ì €ì¥ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤.")


# =========================
# Part 4 â€” 11ë²ˆê°€(ëª¨ë°”ì¼) ì„ë² ë“œ
# =========================
def render_11st_block():
    st.markdown("## 11ë²ˆê°€ (ëª¨ë°”ì¼)")
    url_default = "https://m.11st.co.kr/page/main/home"
    url = st.text_input("ëª¨ë°”ì¼ URL", url_default, key="t11_url")
    proxy = (st.session_state.get("PROXY_URL") or "").strip().rstrip("/")
    if not proxy:
        st.info("PROXY_URL ë¯¸ì„¤ì •: ì§ì ‘ iFrameì€ ì°¨ë‹¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        try:
            st.components.v1.iframe(url, height=560, scrolling=True)
        except Exception as e:
            toast_err(f"11ë²ˆê°€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    embed = f"{proxy}/?url={quote(url, safe=':/?&=%')}"
    try:
        st.components.v1.iframe(embed, height=800, scrolling=True)
    except Exception as e:
        toast_err(f"í”„ë¡ì‹œ ì„ë² ë“œ ì‹¤íŒ¨: {e}")


# =========================
# Part 5 â€” AI í‚¤ì›Œë“œ ë ˆì´ë” (Rakuten)
# =========================
def _rakuten_app_id() -> str:
    app_id = ""
    try:
        app_id = st.secrets.get("rakuten", {}).get("APP_ID", "")
    except Exception:
        app_id = ""
    if not app_id:
        app_id = os.getenv("RAKUTEN_APP_ID", "")
    if not app_id:
        app_id = st.session_state.get("__RAKUTEN_APP_ID", "")
    return app_id.strip()

def render_rakuten_block():
    st.markdown("## AI í‚¤ì›Œë“œ ë ˆì´ë” (Rakuten)")
    colA, colB, colC = st.columns([1,1,1])
    with colA:
        scope = st.radio("ë²”ìœ„", ["êµ­ë‚´","ê¸€ë¡œë²Œ"], horizontal=True, key="rk_scope")
    with colB:
        cat = st.selectbox("ë¼ì¿ í… ì¹´í…Œê³ ë¦¬", ["ì „ì²´","ë·°í‹°/ì½”ìŠ¤ë©”í‹±","ì˜ë¥˜/íŒ¨ì…˜","ê°€ì „/ë””ì§€í„¸","ê°€êµ¬/ì¸í…Œë¦¬ì–´","ì‹í’ˆ","ìƒí™œ/ê±´ê°•","ìŠ¤í¬ì¸ /ë ˆì €","ë¬¸êµ¬/ì·¨ë¯¸"], key="rk_cat")
    with colC:
        genreid = st.text_input("GenreID", "100283", key="rk_genre")

    st.markdown("""<style>.rk table { font-size: 0.92rem !important; }</style>""", unsafe_allow_html=True)

    app_id = _rakuten_app_id()
    rows = []
    if not app_id:
        with st.expander("Rakuten APP_ID ì„¤ì •", expanded=True):
            tmp = st.text_input("APP_ID", type="password", help="ë¼ì¿ í… ê°œë°œì ì½˜ì†”ì˜ Application ID")
            if tmp:
                st.session_state["__RAKUTEN_APP_ID"] = tmp.strip()
                st.success("ì„¸ì…˜ ì €ì¥ ì™„ë£Œ â€” ì•„ë˜ ì¡°íšŒ ê°€ëŠ¥")
    else:
        if not requests:
            st.warning("requests ë¯¸ì„¤ì¹˜")
        else:
            try:
                api = "https://app.rakuten.co.jp/services/api/IchibaItem/Ranking/20170628"
                params = {"applicationId": app_id, "genreId": genreid}
                r = requests.get(api, params=params, timeout=12)
                r.raise_for_status()
                data = r.json()
                items = (data.get("Items") or [])[:20]
                for i, it in enumerate(items, 1):
                    name = it.get("Item", {}).get("itemName", "")
                    rows.append({"rank": i, "keyword": name, "source": "Rakuten"})
            except Exception:
                pass

    if not rows:
        for i in range(1, 21):
            rows.append({"rank": i, "keyword": f"[ìƒ˜í”Œ] í‚¤ì›Œë“œ {i}", "source": "sample"})

    df = pd.DataFrame(rows)
    with st.container():
        st.markdown('<div class="rk">', unsafe_allow_html=True)
        st.dataframe(df, hide_index=True, use_container_width=True, height=420)
        st.markdown('</div>', unsafe_allow_html=True)


# =========================
# Part 6 â€” êµ¬ê¸€ ë²ˆì—­ (í…ìŠ¤íŠ¸ ì…ë ¥/ì¶œë ¥ + í•œêµ­ì–´ í™•ì¸ìš©)
# =========================
def translate_text(src:str, tgt:str, text:str) -> tuple[str,str]:
    if not GoogleTranslator:
        raise ModuleNotFoundError("deep-translator ë¯¸ì„¤ì¹˜")
    src = lang_label_to_code(src); tgt = lang_label_to_code(tgt)
    translator = GoogleTranslator(source=src, target=tgt)
    out = translator.translate(text)
    ko_hint = ""
    if tgt != "ko" and out.strip():
        try:
            ko_hint = GoogleTranslator(source=tgt, target="ko").translate(out)
        except Exception:
            ko_hint = ""
    return out, ko_hint

def render_translator_block():
    st.markdown("## êµ¬ê¸€ ë²ˆì—­ (í…ìŠ¤íŠ¸ ì…ë ¥/ì¶œë ¥ + í•œêµ­ì–´ í™•ì¸ìš©)")
    c1, c2 = st.columns([1,1])
    with c1:
        src = st.selectbox("ì›ë¬¸ ì–¸ì–´", list(LANG_LABELS.values()), index=list(LANG_LABELS.keys()).index("auto"), key="tr_src")
        text_in = st.text_area("ì›ë¬¸ ì…ë ¥", height=150, key="tr_in")
    with c2:
        tgt = st.selectbox("ë²ˆì—­ ì–¸ì–´", list(LANG_LABELS.values()), index=list(LANG_LABELS.keys()).index("en"), key="tr_tgt")
        if st.button("ë²ˆì—­", key="tr_go"):
            try:
                out, ko_hint = translate_text(lang_label_to_code(src), lang_label_to_code(tgt), text_in)
                # ê°™ì€ ì¤„ ì¶œë ¥ (í•œêµ­ì–´ ëŒ€ìƒì´ë©´ ê´„í˜¸ í‘œì‹œ ìƒëµ)
                if ko_hint and lang_label_to_code(tgt) != "ko":
                    st.write(f"ì›ë¬¸ ì…ë ¥: {text_in}")
                    st.write(f"ë²ˆì—­ ê²°ê³¼: {out} ({ko_hint})")
                else:
                    st.write(f"ì›ë¬¸ ì…ë ¥: {text_in}")
                    st.write(f"ë²ˆì—­ ê²°ê³¼: {out}")
                toast_ok("ë²ˆì—­ ì™„ë£Œ")
            except ModuleNotFoundError as e:
                st.warning(f"deep-translator ì„¤ì¹˜ í•„ìš”: {e}")
            except Exception as e:
                st.error(f"ë²ˆì—­ ì‹¤íŒ¨: {e}")


# =========================
# Part 7 â€” ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ & ì…€ëŸ¬ë¼ì´í”„ (ì›ë³¸ ì„ë² ë“œ)
# =========================
def render_itemscout_embed():
    proxy = (st.session_state.get("PROXY_URL") or "").strip().rstrip("/")
    st.markdown("## ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ (ì›ë³¸ ì„ë² ë“œ)")
    if not proxy:
        st.warning("PROXY_URLì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°” í•˜ë‹¨ì— Worker ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        return
    default_url = st.secrets.get("itemscout", {}).get("DEFAULT_URL", "https://app.itemscout.io/market/keyword")
    url = st.text_input("Itemscout URL", default_url, help="ë¡œê·¸ì¸ëœ ìƒíƒœë¡œ ë³´ê³  ì‹¶ì€ ê²½ë¡œë¥¼ ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥")
    st.components.v1.iframe(f"{proxy}/?url={quote(url, safe=':/?&=%')}", height=920, scrolling=True)

def render_sellerlife_embed():
    proxy = (st.session_state.get("PROXY_URL") or "").strip().rstrip("/")
    st.markdown("## ì…€ëŸ¬ë¼ì´í”„ (ì›ë³¸ ì„ë² ë“œ)")
    if not proxy:
        st.warning("PROXY_URLì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°” í•˜ë‹¨ì— Worker ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        return
    default_url = st.secrets.get("sellerlife", {}).get("DEFAULT_URL", "https://sellerlife.co.kr/dashboard")
    url = st.text_input("SellerLife URL", default_url)
    st.components.v1.iframe(f"{proxy}/?url={quote(url, safe=':/?&=%')}", height=920, scrolling=True)


# =========================
# Part 8 â€” ìƒí’ˆëª… ìƒì„±ê¸° (ê·œì¹™ ê¸°ë°˜)
# =========================
import re as _re_titles
from itertools import product as _product, combinations as _combinations

def _dedup_tokens(seq):
    seen=set(); out=[]
    for tok in seq:
        t=tok.strip()
        if not t: continue
        key=t.lower()
        if key in seen: continue
        seen.add(key); out.append(t)
    return out

def _clean_title(s, delimiter):
    s = _re_titles.sub(r'\s+', ' ', s).strip()
    s = _re_titles.sub(rf'\s*{re.escape(delimiter)}\s*', f' {delimiter} ', s)
    s = _re_titles.sub(rf'(?:\s*{re.escape(delimiter)}\s*)+', f' {delimiter} ', s)
    s = _re_titles.sub(r'\s+', ' ', s).strip(' -|/').strip()
    return s

def render_title_gen_block():
    st.markdown("## ìƒí’ˆëª… ìƒì„±ê¸° (ê·œì¹™ ê¸°ë°˜)")
    with st.container():
        c1,c2,c3 = st.columns([1.1,1,1])
        with c1:
            brand = st.text_input("ë¸Œëœë“œ", placeholder="ì˜ˆ: Apple / Dyson / ë¬´ì§€", key="tg_brand")
            base_keywords = st.text_input("ë©”ì¸ í‚¤ì›Œë“œ(ì½¤ë§ˆ)", placeholder="ì˜ˆ: í—¤ì–´ë“œë¼ì´ì–´, ë¬´ì„ ì²­ì†Œê¸°", key="tg_keywords")
        with c2:
            attrs = st.text_area("ì†ì„±/ìˆ˜ì‹ì–´(ì½¤ë§ˆ)", placeholder="ì˜ˆ: 1200W, ê°•í’, ì €ì†ŒìŒ, ì •í’ˆ, ASê°€ëŠ¥, 2025ì‹ í˜•", height=90, key="tg_attrs")
            model = st.text_input("ëª¨ë¸/ì‹œë¦¬ì¦ˆ", placeholder="ì˜ˆ: HD15 / V12", key="tg_model")
        with c3:
            market = st.selectbox("ë§ˆì¼“ í”„ë¦¬ì…‹", ["ììœ (100)","ë„¤ì´ë²„(50)","11ë²ˆê°€(60)","ì¿ íŒ¡(70)","ë¼ì¿ í…(75)"], index=0, key="tg_market")
            delim = st.selectbox("êµ¬ë¶„ì", ["|","-","/","Â·"," "], index=0, key="tg_delim")
            max_len_map={"ììœ (100)":100,"ë„¤ì´ë²„(50)":50,"11ë²ˆê°€(60)":60,"ì¿ íŒ¡(70)":70,"ë¼ì¿ í…(75)":75}
            max_len = st.slider("ìµœëŒ€ ê¸€ììˆ˜", 30, 120, value=max_len_map[market], step=5, key="tg_maxlen")
        st.caption("ê·œì¹™: {ë¸Œëœë“œ} + {ë©”ì¸í‚¤ì›Œë“œ} + {ì†ì„±ì¡°í•©} + {ëª¨ë¸} ìˆœì„œ. ì¤‘ë³µ/ê³µë°± ìë™ ì •ë¦¬.")

        c4,c5 = st.columns([1,1])
        with c4:
            attrs_per_title = st.slider("ì†ì„± ìµœëŒ€ ê°œìˆ˜", 1, 4, 2, key="tg_attrs_per")
            variants = st.slider("ìƒì„± ê°œìˆ˜", 5, 100, 30, step=5, key="tg_variants")
        with c5:
            stopwords = st.text_input("ê¸ˆì¹™ì–´(ì½¤ë§ˆ)", placeholder="ì˜ˆ: ë¬´ë£Œë°°ì†¡, ì‚¬ì€í’ˆ", key="tg_stop")
            template = st.text_input("í…œí”Œë¦¿", value="{brand} {keyword} {attrs} {model}", key="tg_tpl",
                                     help="{brand},{keyword},{attrs},{model} ì‚¬ìš© ê°€ëŠ¥")

        if st.button("ìƒí’ˆëª… ìƒì„±", use_container_width=True, key="tg_go"):
            brand_tok = brand.strip()
            kws = [t.strip() for t in base_keywords.split(",") if t.strip()]
            attr_tokens = [t.strip() for t in attrs.split(",") if t.strip()]
            model_tok = model.strip()
            bans = {t.strip().lower() for t in stopwords.split(",") if t.strip()}

            if not kws:
                st.error("ë©”ì¸ í‚¤ì›Œë“œë¥¼ ìµœì†Œ 1ê°œ ì…ë ¥í•˜ì„¸ìš”.")
                return

            # ì†ì„± ì¡°í•© ë§Œë“¤ê¸°
            attr_tokens = _dedup_tokens(attr_tokens)[:12]
            attr_combos = [[]]
            for r in range(1, attrs_per_title+1):
                attr_combos += list(_combinations(attr_tokens, r))

            # ìƒì„±
            generated = []
            for kw, combo in _product(kws, attr_combos):
                attrs_str = f" {st.session_state.get('tg_delim','|')} ".join(combo).strip()
                ctx = {"brand": brand_tok, "keyword": kw, "attrs": attrs_str, "model": model_tok}
                raw = template.format(**ctx).strip()
                if any(b in raw.lower() for b in bans):
                    continue
                title = _clean_title(raw, st.session_state.get('tg_delim','|'))
                if len(title) <= st.session_state.get("tg_maxlen", 100) and len(title) >= 8:
                    generated.append(title)

            # ì¤‘ë³µ ì œê±°
            uniq=[]; seen=set()
            for t in generated:
                k=t.lower()
                if k in seen: continue
                seen.add(k); uniq.append(t)
            uniq = uniq[:st.session_state.get("tg_variants", 30)]

            if not uniq:
                st.warning("ì¡°ê±´ì— ë§ëŠ” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ìµœëŒ€ ê¸€ììˆ˜ ë˜ëŠ” ì†ì„± ê°œìˆ˜ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”.")
                return

            df = pd.DataFrame({"ìƒí’ˆëª…": uniq})
            st.dataframe(df, use_container_width=True, hide_index=True, height=min(600, 32+24*len(uniq)))
            st.text_area("ê²°ê³¼(ë³µì‚¬ìš©)", "\n".join(uniq), height=180)
            st.download_button("CSV ë‹¤ìš´ë¡œë“œ", df.to_csv(index=False).encode("utf-8-sig"),
                               file_name="titles.csv", mime="text/csv")


# =========================
# Part 9 â€” ë©”ì¸ ì¡°ë¦½ (3Ã—2 ë ˆì´ì•„ì›ƒ)
# =========================
def _safe_call(fn, title:str=None):
    if title: st.markdown(f"## {title}")
    try:
        fn()
    except Exception as e:
        st.error(f"{title or fn.__name__} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")

def main():
    # ì‚¬ì´ë“œë°” + ì „ì—­ CSS
    render_sidebar()
    inject_global_css()

    st.title("ENVY â€” Season 1 (stable)")
    st.caption("ê°€ë¡œ 3ì—´ Ã— 2í–‰ ê·¸ë¦¬ë“œ. í”„ë¡ì‹œ/ì¿ í‚¤ëŠ” ì›Œì»¤Â·ì‹œí¬ë¦¿ìœ¼ë¡œ ê´€ë¦¬.")

    # 1í–‰: ë°ì´í„°ë© | 11ë²ˆê°€ | ìƒí’ˆëª… ìƒì„±ê¸°
    c1, c2, c3 = st.columns([1.15, 1, 1], gap="large")
    with c1:
        st.markdown("### ë°ì´í„°ë©")
        tab1, tab2 = st.tabs(["ì›ë³¸", "ë¶„ì„"])
        with tab1:
            _safe_call(render_datalab_embed_block)
        with tab2:
            _safe_call(render_datalab_block)
    with c2:
        st.markdown("### 11ë²ˆê°€ (ëª¨ë°”ì¼)")
        _safe_call(render_11st_block)
    with c3:
        st.markdown("### ìƒí’ˆëª… ìƒì„±ê¸°")
        _safe_call(render_title_gen_block)

    # 2í–‰: í‚¤ì›Œë“œ ë ˆì´ë” | êµ¬ê¸€ ë²ˆì—­ | ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸/ì…€ëŸ¬ë¼ì´í”„
    d1, d2, d3 = st.columns([1, 1, 1], gap="large")
    with d1:
        st.markdown("### AI í‚¤ì›Œë“œ ë ˆì´ë” (Rakuten)")
        _safe_call(render_rakuten_block)
    with d2:
        st.markdown("### êµ¬ê¸€ ë²ˆì—­")
        _safe_call(render_translator_block)
    with d3:
        st.markdown("### ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ / ì…€ëŸ¬ë¼ì´í”„")
        t_is, t_sl = st.tabs(["ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸", "ì…€ëŸ¬ë¼ì´í”„"])
        with t_is:
            _safe_call(render_itemscout_embed)
        with t_sl:
            _safe_call(render_sellerlife_embed)

if __name__ == "__main__":
    main()
