# === envy_app.py â€” Part 1 ===
import streamlit as st
import pandas as pd
import requests, time as _t, datetime, re
import urllib.parse as _u
from bs4 import BeautifulSoup

# âœ… ì™€ì´ë“œ ë ˆì´ì•„ì›ƒ
st.set_page_config(page_title="ENVY Full", layout="wide")

COMMON_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124 Safari/537.36",
    "Accept-Language": "ko,en;q=0.9",
}

# ë‹¤í¬ëª¨ë“œ í† ê¸€
if "dark_mode" not in st.session_state:
    st.session_state["dark_mode"] = False
st.session_state["dark_mode"] = st.sidebar.toggle("ğŸŒ— ë‹¤í¬ ëª¨ë“œ", value=st.session_state["dark_mode"], key="toggle_dark")

if st.session_state["dark_mode"]:
    st.markdown("""
    <style>
    body, .stApp { background:#0b1220; color:#e5e7eb; }
    .stDataFrame, .stTable { color:#e5e7eb; }
    </style>
    """, unsafe_allow_html=True)

# âœ… CSS (í˜ì´ì§€ ì „ì²´ í­ + ì¹´ë“œ ì™€ì´ë“œí™”)
st.markdown("""
<style>
/* ì „ì²´ ì»¨í…Œì´ë„ˆ í­ í’€ê¸° */
html, body, [data-testid="stAppViewContainer"] > .main {
  max-width: 100vw !important;
  padding-left: 16px !important;
  padding-right: 16px !important;
}
/* ì‚¬ì´ë“œë°” ì—¬ë°± */
section[data-testid="stSidebar"] .block-container { padding:14px 16px !important; }
section[data-testid="stSidebar"] [data-testid="stVerticalBlock"]{ gap:12px !important; }
/* ë³¸ë¬¸ ì»¬ëŸ¼ ê°„ê²© */
[data-testid="stHorizontalBlock"] { gap: 1.25rem !important; }
/* ì¹´ë“œ */
.envy-card {
  border:1px solid #e5e7eb; border-radius:12px; padding:20px;
  width: 100% !important; max-width: none !important;
  box-sizing: border-box;
}
.envy-card h3 { margin-top:0; margin-bottom:12px; }
/* ê²°ê³¼ pill */
.pill {border-radius:10px; padding:10px 12px; font-weight:700; font-size:14px; margin:6px 0 2px 0; border:1px solid;}
.pill.green  { background:#E6F4EA; color:#0F5132; border-color:#BADBCC; }
.pill.blue   { background:#E7F1FE; color:#0B3D91; border-color:#B6D0FF; }
.pill.yellow { background:#FFF4CC; color:#7A5D00; border-color:#FFE08A; }
/* ìŠ¤í˜ì´ì„œ */
.vspace { height:10px; }
</style>
""", unsafe_allow_html=True)

def fmt_money2(x: float) -> str:
    try:
        return f"{x:,.2f} ì›"
    except Exception:
        return "0.00 ì›"

def show_pill(where, label: str, value: str, color: str):
    where.markdown(f'<div class="pill {color}">{label}: {value}</div>', unsafe_allow_html=True)

# ìƒí’ˆëª… ìƒì„±ê¸° ìœ í‹¸
def _sanitize(t: str) -> str:
    return re.sub(r"\s+", " ", (t or "").replace(",", " ")).strip()

def build_titles(brand: str, base_kw: str, rel_candidates: list[dict],
                 ban_set: set[str], max_len: int, k: int = 5) -> list[str]:
    titles = []
    for cand in rel_candidates:
        kw = cand.get("keyword", "")
        if not kw: continue
        title = f"{brand} {base_kw} {kw}"
        if any(b in title.lower() for b in ban_set):
            continue
        title = _sanitize(title)[:max_len]
        if title and title not in titles:
            titles.append(title)
        if len(titles) >= k: break
    while len(titles) < k:
        fallback = _sanitize(f"{brand} {base_kw}")[:max_len]
        if fallback and fallback not in titles:
            titles.append(fallback)
        else:
            titles.append(_sanitize(brand)[:max_len])
        if len(titles) >= k: break
    return titles
# === envy_app.py â€” Part 2 ===

st.sidebar.header("â‘  í™˜ìœ¨ ê³„ì‚°ê¸°")
rate_map = {"USD": 1400.00, "EUR": 1500.00, "JPY": 9.50, "CNY": 190.00}

fx_cur = st.sidebar.selectbox("ê¸°ì¤€ í†µí™”", list(rate_map.keys()), index=0, key="fx_cur")
fx_rate = rate_map.get(fx_cur, 1400.0)
fx_price = st.sidebar.number_input(
    f"íŒë§¤ê¸ˆì•¡ ({fx_cur})", min_value=0.0, max_value=1e12,
    value=1.00, step=0.01, format="%.2f", key="fx_price"
)
fx_amount = fx_price * fx_rate
show_pill(st.sidebar, "í™˜ì‚° ê¸ˆì•¡", fmt_money2(fx_amount), "green")

st.sidebar.header("â‘¡ ë§ˆì§„ ê³„ì‚°ê¸° (v23)")
m_cur = st.sidebar.selectbox("ê¸°ì¤€ í†µí™”(íŒë§¤ê¸ˆì•¡)", list(rate_map.keys()), index=0, key="m_cur")
m_rate = rate_map.get(m_cur, 1400.0)
m_price = st.sidebar.number_input(
    f"íŒë§¤ê¸ˆì•¡ ({m_cur})", min_value=0.0, max_value=1e12,
    value=1.00, step=0.01, format="%.2f", key="m_price"
)
m_fx = m_price * m_rate
show_pill(st.sidebar, "íŒë§¤ê¸ˆì•¡(í™˜ì‚°)", fmt_money2(m_fx), "green")

st.sidebar.markdown('<div class="vspace"></div>', unsafe_allow_html=True)

fee_card   = st.sidebar.number_input("ì¹´ë“œìˆ˜ìˆ˜ë£Œ (%)", 0.00, 100.00, 4.00, 0.01, format="%.2f", key="fee_card")
fee_market = st.sidebar.number_input("ë§ˆì¼“ìˆ˜ìˆ˜ë£Œ (%)", 0.00, 100.00, 14.00, 0.01, format="%.2f", key="fee_market")
ship_cost  = st.sidebar.number_input("ë°°ì†¡ë¹„ (â‚©)",     0.00, 1e12,   0.00, 0.01, format="%.2f", key="ship_cost")

m_type = st.sidebar.radio("ë§ˆì§„ ë°©ì‹", ["í¼ì„¼íŠ¸ ë§ˆì§„(%)","ë”í•˜ê¸° ë§ˆì§„(â‚©)"], index=0, key="m_type")
m_val  = st.sidebar.number_input("ë§ˆì§„ìœ¨/ê¸ˆì•¡", 0.00, 1e12, 10.00, 0.01, format="%.2f", key="m_val")

calc_price = m_fx * (1 + fee_card/100 + fee_market/100)
if m_type.startswith("í¼ì„¼íŠ¸"):
    calc_price *= (1 + m_val/100)
else:
    calc_price += m_val
calc_price += ship_cost

profit = calc_price - m_fx
show_pill(st.sidebar, "ì˜ˆìƒ íŒë§¤ê°€", fmt_money2(calc_price), "blue")
show_pill(st.sidebar, "ìˆœì´ìµ(ë§ˆì§„)", fmt_money2(profit), "yellow")
# === envy_app.py â€” Part 3 ===

@st.cache_data(ttl=3600)
def fetch_datalab_top20(cid: str, start_date: str, end_date: str, proxy: str | None = None) -> pd.DataFrame:
    try:
        end = datetime.datetime.strptime(end_date, "%Y-%m-%d").date()
    except:
        end = datetime.date.today()
    yesterday = (end - datetime.timedelta(days=1)).strftime("%Y-%m-%d")

    s = requests.Session()
    entry = "https://datalab.naver.com/shoppingInsight/sCategory.naver"
    try: s.get(entry, headers=COMMON_HEADERS, timeout=10)
    except: pass

    api = "https://datalab.naver.com/shoppingInsight/getCategoryKeywordRank.naver"
    url = f"{proxy}?target=" + _u.quote(api, safe="") if proxy else api
    payload = {"cid": cid,"timeUnit":"date","startDate":start_date,"endDate":yesterday,"device":"pc","gender":"","ages":""}
    headers = {**COMMON_HEADERS,"Content-Type":"application/x-www-form-urlencoded; charset=UTF-8","X-Requested-With":"XMLHttpRequest","Referer":entry}

    last_err=None
    for i in range(3):
        try:
            r=s.post(url,headers=headers,data=payload,timeout=12)
            if r.status_code==200 and r.text.strip():
                js=r.json()
                items=js.get("keywordList",[])
                rows=[{"rank":it.get("rank",idx+1),"keyword":it.get("keyword",""),"search":it.get("ratio",0)} for idx,it in enumerate(items[:20])]
                return pd.DataFrame(rows)
            last_err=f"HTTP {r.status_code}"
        except Exception as e: last_err=str(e)
        _t.sleep(1.25*(i+1))
    stub=pd.DataFrame({"rank":list(range(1,6)),"keyword":["í‚¤ì›Œë“œA","í‚¤ì›Œë“œB","í‚¤ì›Œë“œC","í‚¤ì›Œë“œD","í‚¤ì›Œë“œE"],"search":[100,95,90,85,80]})
    stub.attrs["warning"]=f"DataLab í˜¸ì¶œ ì‹¤íŒ¨: {last_err}"
    return stub

def fetch_amazon_top(region: str = "JP") -> pd.DataFrame:
    base = "https://www.amazon.co.jp" if region.upper()=="JP" else "https://www.amazon.com"
    url = f"{base}/gp/bestsellers"
    try:
        r=requests.get(url,headers=COMMON_HEADERS,timeout=10)
        if r.status_code==200:
            soup=BeautifulSoup(r.text,"html.parser")
            titles=[]
            for sel in [".p13n-sc-truncate","div._cDEzb_p13n-sc-css-line-clamp-3_g3dy1","div._cDEzb_p13n-sc-css-line-clamp-2_EWgCb","span.zg-text-center-align > div > a > div"]:
                for el in soup.select(sel):
                    t=re.sub(r"\s+"," ",el.get_text(strip=True))
                    if t and t not in titles: titles.append(t)
                    if len(titles)>=15: break
                if len(titles)>=15: break
            if titles: return pd.DataFrame({"rank":range(1,len(titles)+1),"keyword":titles,"source":[f"Amazon {region}"]*len(titles)})
    except: pass
    return pd.DataFrame({"rank":range(1,6),"keyword":["ìƒ˜í”ŒA","ìƒ˜í”ŒB","ìƒ˜í”ŒC","ìƒ˜í”ŒD","ìƒ˜í”ŒE"],"source":[f"Amazon {region}"]*5})

from urllib.parse import urlparse,urlunparse
def normalize_11st_mobile(url:str)->str:
    try:
        u=urlparse(url.strip())
        if not u.scheme: u=urlparse("https://"+url.strip())
        host=u.netloc.lower()
        if "11st.co.kr" in host and not host.startswith("m."): host="m.11st.co.kr"
        return urlunparse((u.scheme,host,u.path,u.params,u.query,u.fragment))
    except: return "https://m.11st.co.kr"
# === envy_app.py â€” Part 4 ===
st.title("ğŸš€ ENVY v27.12 Full")

# ìœ—ì¤„ 3ë¶„í• 
top1, top2, top3 = st.columns([1,1,1], gap="large")
with top1:
    st.markdown('<div class="envy-card">', unsafe_allow_html=True)
    st.markdown("### ë°ì´í„°ë©")
    cid_map={"íŒ¨ì…˜ì˜ë¥˜":"50000002","íŒ¨ì…˜ì¡í™”":"50000001","í™”ì¥í’ˆ/ë¯¸ìš©":"50000007","ë””ì§€í„¸/ê°€ì „":"50000003","ê°€êµ¬/ì¸í…Œë¦¬ì–´":"50000004","ìƒí™œ/ê±´ê°•":"50000005","ì‹í’ˆ":"50000006","ì¶œì‚°/ìœ¡ì•„":"50000008","ìŠ¤í¬ì¸ /ë ˆì €":"50000009","ìë™ì°¨ìš©í’ˆ":"50000100"}
    dl_cat=st.selectbox("ì¹´í…Œê³ ë¦¬(10ê°œ)",list(cid_map.keys()),index=5,key="dl_cat_main")
    proxy=st.text_input("í”„ë¡ì‹œ(ì„ íƒ)","","https://envy-proxy.taesig0302.workers.dev",key="dl_proxy_main")
    today=datetime.date.today(); start=(today-datetime.timedelta(days=30)).strftime("%Y-%m-%d"); end=today.strftime("%Y-%m-%d")
    df_dl=fetch_datalab_top20(cid_map[dl_cat],start,end,proxy if proxy else None)
    warn=getattr(df_dl,"attrs",{}).get("warning"); 
    if warn: st.warning(warn)
    st.dataframe(df_dl,use_container_width=True,height=260)
    st.markdown('</div>', unsafe_allow_html=True)
with top2: st.markdown('<div class="envy-card"><h3>ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸</h3><p>ì—°ë™ ëŒ€ê¸°</p></div>', unsafe_allow_html=True)
with top3: st.markdown('<div class="envy-card"><h3>ì…€ëŸ¬ë¼ì´í”„</h3><p>ì—°ë™ ëŒ€ê¸°</p></div>', unsafe_allow_html=True)

# ì•„ë«ì¤„ 3ë¶„í• 
bot1, bot2, bot3 = st.columns([1,1,1], gap="large")
with bot1:
    st.markdown('<div class="envy-card">', unsafe_allow_html=True)
    st.markdown("### AI í‚¤ì›Œë“œ ë ˆì´ë”")
    mode=st.radio("ëª¨ë“œ",["êµ­ë‚´","ê¸€ë¡œë²Œ"],index=0,horizontal=True,key="radar_mode_main")
    if mode=="êµ­ë‚´":
        st.dataframe(df_dl,use_container_width=True,height=300)
    else:
        region=st.selectbox("Amazon ì§€ì—­",["JP","US"],index=0,key="amz_region_main")
        st.dataframe(fetch_amazon_top(region),use_container_width=True,height=300)
    st.markdown('</div>', unsafe_allow_html=True)
with bot2:
    st.markdown('<div class="envy-card">', unsafe_allow_html=True)
    st.markdown("### 11ë²ˆê°€")
    url_11=st.text_input("11ë²ˆê°€ URL","https://www.11st.co.kr/",key="url_11_main")
    mobile_11=normalize_11st_mobile(url_11)
    st.components.v1.html(f"<iframe src='{mobile_11}' width='100%' height='520' style='border:1px solid #e5e7eb;border-radius:10px;' sandbox='allow-scripts allow-forms allow-same-origin allow-popups'></iframe>",height=540)
    st.markdown('</div>', unsafe_allow_html=True)
with bot3:
    st.markdown('<div class="envy-card">', unsafe_allow_html=True)
    st.markdown("### ìƒí’ˆëª… ìƒì„±ê¸°")
    brand=st.text_input("ë¸Œëœë“œ","envy",key="nm_brand_main")
    base_kw=st.text_input("ë² ì´ìŠ¤ í‚¤ì›Œë“œ","K-coffee mix",key="nm_base_main")
    rel_kw=st.text_input("ì—°ê´€í‚¤ì›Œë“œ","Maxim, Kanu, Korea",key="nm_rel_main")
    ban_kw=st.text_input("ê¸ˆì¹™ì–´","copy, fake, replica",key="nm_ban_main")
    limit=st.slider("ê¸€ììˆ˜ ì œí•œ",10,100,80,key="nm_limit_main")
    if st.button("ì œëª© ìƒì„±",key="nm_gen_main"):
        tokens=[t.strip() for t in rel_kw.split(",") if t.strip()]
        rel_candidates=[{"keyword":t,"search":None} for t in tokens]
        ban_set={b.strip().lower() for b in ban_kw.split(",") if b.strip()}
        titles=build_titles(brand,base_kw,rel_candidates,ban_set,limit,k=5)
        st.markdown("#### ì¶”ì²œ ì œëª© 5ê°€ì§€")
        for i,t in enumerate(titles,1):
            st.code(f"{i}. {t}")
        st.markdown("#### ì¶”ì²œìš© ì—°ê´€í‚¤ì›Œë“œ")
        st.dataframe(pd.DataFrame(rel_candidates),use_container_width=True,height=200)
    st.markdown('</div>', unsafe_allow_html=True)
