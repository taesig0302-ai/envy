# -*- coding: utf-8 -*-
# ENVY â€” Season 1 (Dual Proxy Edition, Radar tabs=êµ­ë‚´/í•´ì™¸, Rakuten scope radio removed, row1 ratio 8:5:3)
# ì´ë²ˆ ë²„ì „:
# - ìƒí’ˆëª… ìƒì„±ê¸° ì¹´ë“œ ë‚´ë¶€ íƒ­: [ìƒì„±ê¸° | ê¸ˆì¹™ì–´ ê´€ë¦¬]
# - ì™¸ë¶€ ê¸ˆì¹™ì–´ ì„¹ì…˜ì€ ìœ ì§€(ì„ íƒ). ë™ì¼ ì„¸ì…˜í‚¤ ê³µìœ ë¡œ ë™ê¸°í™”ë¨.
# - ì‚¬ì´ë“œë°”: ë‹¤í¬+ë²ˆì—­ê¸° í† ê¸€ / ë²ˆì—­ê¸° ON: ë²ˆì—­ê¸° í¼ì¹¨Â·ê³„ì‚°ê¸° ì ‘í˜, OFF: ê³„ì‚°ê¸° í¼ì¹¨Â·ë²ˆì—­ê¸° ì ‘í˜

import base64, time, re, math, json, io, datetime as dt
from pathlib import Path
from urllib.parse import quote

import pandas as pd
import streamlit as st

# -------- Optional imports --------
try:
    import requests
except Exception:
    requests = None

try:
    from deep_translator import GoogleTranslator
except Exception:
    GoogleTranslator = None

st.set_page_config(page_title="ENVY â€” Season 1 (Dual Proxy Edition)", layout="wide")

# =========================
# 0) GLOBALS & DEFAULT KEYS
# =========================
SHOW_ADMIN_BOX = False

# Proxies (Cloudflare Worker)
NAVER_PROXY      = "https://envy-proxy.taesig0302.workers.dev"
ELEVENST_PROXY   = "https://worker-11stjs.taesig0302.workers.dev"
ITEMSCOUT_PROXY  = "https://worker-itemscoutjs.taesig0302.workers.dev"
SELLERLIFE_PROXY = "https://worker-sellerlifejs.taesig0302.workers.dev"

# ---- Default credentials (secrets ê°€ ìˆìœ¼ë©´ secrets ìš°ì„ ) ----
DEFAULT_KEYS = {
    # Rakuten
    "RAKUTEN_APP_ID":       "1043271015809337425",
    "RAKUTEN_AFFILIATE_ID": "4c723498.cbfeca46.4c723499.1deb6f77",
    # NAVER Searchad(ê²€ìƒ‰ê´‘ê³  API / í‚¤ì›Œë“œë„êµ¬)
    "NAVER_API_KEY":        "0100000000785cf1d8f039b13a5d3c3d1262b84e9ad4a046637e8887bbd003051b0d2a5cdf",
    "NAVER_SECRET_KEY":     "AQAAAAB4XPHY8DmxOl08PRJiuE6ao1LN3lh0kF9rOJ4m5b8O5g==",
    "NAVER_CUSTOMER_ID":    "2274338",
    # NAVER Developers (DataLab Open API)
    "NAVER_CLIENT_ID":      "nBay2VW6uz7E4bZnZ2y9",
    "NAVER_CLIENT_SECRET":  "LNuLh1E3e1",
}
def _get_key(name: str) -> str:
    return (st.secrets.get(name, "") or DEFAULT_KEYS.get(name, "")).strip()

# Simple FX
CURRENCIES = {
    "USD":{"kr":"ë¯¸êµ­ ë‹¬ëŸ¬","symbol":"$","unit":"USD"},
    "EUR":{"kr":"ìœ ë¡œ","symbol":"â‚¬","unit":"EUR"},
    "JPY":{"kr":"ì¼ë³¸ ì—”","symbol":"Â¥","unit":"JPY"},
    "CNY":{"kr":"ì¤‘êµ­ ìœ„ì•ˆ","symbol":"å…ƒ","unit":"CNY"},
}
FX_DEFAULT = {"USD":1400.0,"EUR":1500.0,"JPY":10.0,"CNY":200.0}

# =========================
# Stopwords â€” ì „ì—­/ì¹´í…Œê³ ë¦¬ + í”„ë¦¬ì…‹
# =========================
STOPWORDS_GLOBAL = [
    # ê´‘ê³ /í–‰ì‚¬/ê°€ê²© ê³¼ì¥
    "ë¬´ë£Œë°°ì†¡","ë¬´ë°°","ì´ˆíŠ¹ê°€","íŠ¹ê°€","í•«ë”œ","ìµœì €ê°€","ì„¸ì¼","sale","ì´ë²¤íŠ¸","ì‚¬ì€í’ˆ","ì¦ì •",
    "ì¿ í°","ì—­ëŒ€ê¸‰","ì—­ëŒ€ê°€","í­íƒ„ì„¸ì¼","ì›ê°€","ì •ê°€","íŒŒê²©","ì´ˆëŒ€ë°•","í• ì¸í­","í˜œíƒê°€",
    # ìš´ì˜/AS ë¦¬ìŠ¤í¬
    "íŒŒì†","í™˜ë¶ˆ","êµí™˜","ì¬ê³ ","í’ˆì ˆ","í•œì •ìˆ˜ëŸ‰","ê¸´ê¸‰","ê¸‰ì²˜","íŠ¹íŒ",
    # ê³¼ë„í•œ ë§ˆì¼€íŒ… í‘œí˜„/ì´ëª¨ì§€
    "mustbuy","ê°•ì¶”","ì¶”ì²œ","ì¶”ì²œí…œ","ğŸ”¥","ğŸ’¥","â­","best","ë² ìŠ¤íŠ¸"
]
STOPWORDS_BY_CAT = {
    "íŒ¨ì…˜ì˜ë¥˜":   ["ë£¨ì¦ˆí•","ë¹…ì‚¬ì´ì¦ˆ","ì´ˆìŠ¬ë¦¼","ê·¹ì„¸ì‚¬","ì´ˆê²½ëŸ‰","ì™•ì˜¤ë²„","ëª¸ë§¤ë³´ì •"],
    "íŒ¨ì…˜ì¡í™”":   ["ë¬´ë£Œê°ì¸","ì‚¬ì€í’ˆì§€ê¸‰","ì„¸íŠ¸ì¦ì •"],
    "ë·°í‹°/ë¯¸ìš©":  ["ì •í’ˆë³´ì¥","ë³‘í–‰ìˆ˜ì…","ë²Œí¬","ë¦¬í•„ë§Œ","ìƒ˜í”Œ","í…ŒìŠ¤í„°"],
    "ìƒí™œ/ê±´ê°•":  ["ê³µìš©","ë¹„ë§¤í’ˆ","ë¦¬í¼","ë¦¬í¼ë¹„ì‹œ"],
    "ë””ì§€í„¸/ê°€ì „": ["ê´€ë¶€ê°€ì„¸","ë¶€ê°€ì„¸","í•´ì™¸ì§êµ¬","ë¦¬í¼","ë¦¬í¼ë¹„ì‹œ","ë²Œí¬"],
    "ìŠ¤í¬ì¸ /ë ˆì €": ["ë¬´ë£Œì¡°ë¦½","ê°€ì„±ë¹„ê°‘"],
}
STOP_PRESETS = {
    "ë„¤ì´ë²„_ì•ˆì „ê¸°ë³¸": {
        "global": STOPWORDS_GLOBAL, "by_cat": STOPWORDS_BY_CAT, "whitelist": [],
        "replace": ["ë¬´ë°°=> ", "ë¬´ë£Œë°°ì†¡=> ", "ì •í’ˆ=> "], "aggressive": False
    },
    "ê´‘ê³ í‘œí˜„_ê°•ë ¥ì°¨ë‹¨": {
        "global": STOPWORDS_GLOBAL + ["ì´ˆê°•ë ¥","ì´ˆì €ê°€","ê·¹ê°•","í˜œì","ëŒ€ë€","í’ˆì ˆì„ë°•","ì™„íŒì„ë°•","ë§ˆê°ì„ë°•"],
        "by_cat": STOPWORDS_BY_CAT, "whitelist": [],
        "replace": ["ë¬´ë°°=> ", "ë¬´ë£Œë°°ì†¡=> ", "ì •í’ˆ=> ", "í• ì¸=> "], "aggressive": True
    }
}

# =========================
# 1) UI defaults & CSS
# =========================
def _ensure_session_defaults():
    ss = st.session_state
    ss.setdefault("theme","light")
    ss.setdefault("fx_base","USD")
    ss.setdefault("sale_foreign",1.00)
    ss.setdefault("m_base","USD")
    ss.setdefault("purchase_foreign",0.00)
    ss.setdefault("card_fee_pct",4.00)
    ss.setdefault("market_fee_pct",14.00)
    ss.setdefault("shipping_won",0.0)
    ss.setdefault("margin_mode","í¼ì„¼íŠ¸")
    ss.setdefault("margin_pct",10.00)
    ss.setdefault("margin_won",10000.0)
    # Stopwords manager ìƒíƒœ
    ss.setdefault("STOP_GLOBAL", list(STOPWORDS_GLOBAL))
    ss.setdefault("STOP_BY_CAT", dict(STOPWORDS_BY_CAT))
    ss.setdefault("STOP_WHITELIST", [])
    ss.setdefault("STOP_REPLACE", ["ë¬´ë°°=> ", "ë¬´ë£Œë°°ì†¡=> ", "ì •í’ˆ=> "])
    ss.setdefault("STOP_AGGR", False)
    # Rakuten genre map
    ss.setdefault("rk_genre_map", {
        "ì „ì²´(ìƒ˜í”Œ)": "100283","ë·°í‹°/ì½”ìŠ¤ë©”í‹±": "100283","ì˜ë¥˜/íŒ¨ì…˜": "100283","ê°€ì „/ë””ì§€í„¸": "100283",
        "ê°€êµ¬/ì¸í…Œë¦¬ì–´": "100283","ì‹í’ˆ": "100283","ìƒí™œ/ê±´ê°•": "100283","ìŠ¤í¬ì¸ /ë ˆì €": "100283","ë¬¸êµ¬/ì·¨ë¯¸": "100283",
    })

def _toggle_theme():
    st.session_state["theme"]="dark" if st.session_state.get("theme","light")=="light" else "light"

def _inject_css():
    theme = st.session_state.get("theme","light")
    bg, fg = ("#0e1117","#e6edf3") if theme=="dark" else ("#ffffff","#111111")
    st.markdown(f"""
    <style>
      .block-container{{max-width:3800px!important;padding-top:.55rem!important;padding-bottom:1rem!important}}
      html,body,[data-testid="stAppViewContainer"]{{background:{bg}!important;color:{fg}!important}}
      h2,h3{{margin-top:.3rem!important}}
      [data-testid="stSidebar"],[data-testid="stSidebar"]>div:first-child,[data-testid="stSidebar"] section{{height:100vh!important;overflow:hidden!important;padding:.15rem .25rem!important}}
      [data-testid="stSidebar"] section{{overflow-y:auto!important}}
      [data-testid="stSidebar"] ::-webkit-scrollbar{{display:none!important}}
      [data-testid="stSidebar"] .stSelectbox,.stNumberInput,.stRadio,.stMarkdown,.stTextInput,.stButton{{margin:.06rem 0!important}}
      [data-baseweb="input"] input,.stNumberInput input,[data-baseweb="select"] div[role="combobox"]{{height:1.55rem!important;padding:.12rem .6rem!important;font-size:.96rem!important;border-radius:12px!important}}
      .pill{{border-radius:9999px;padding:.40rem .9rem;font-weight:800;display:inline-block;margin:.10rem 0!important}}
      .pill-green{{background:#b8f06c;border:1px solid #76c02a;color:#083500}}
      .pill-blue{{background:#dbe6ff;border:1px solid #88a8ff;color:#09245e}}
      .pill-yellow{{background:#ffe29b;border:1px solid #d2a12c;color:#3e2a00}}
      .card{{border:1px solid rgba(0,0,0,.06);border-radius:14px;padding:.85rem;background:#fff;box-shadow:0 1px 6px rgba(0,0,0,.05)}}
      .card-title{{font-size:1.18rem;font-weight:900;margin:.1rem 0 .55rem 0}}
      .card iframe{{border:0;width:100%;border-radius:10px}}
      .row-gap{{height:16px}}
      .logo-circle{{width:72px;height:72px;border-radius:50%;overflow:hidden;margin:.2rem auto .4rem auto;box-shadow:0 2px 8px rgba(0,0,0,.12);border:1px solid rgba(0,0,0,.06)}}
      .logo-circle img{{width:100%;height:100%;object-fit:cover}}
      #rk-card [data-testid="stDataFrame"] * {{ font-size: 0.92rem !important; }}
      #rk-card [data-testid="stDataFrame"] div[role='grid']{{ overflow-x: hidden !important; }}
      #rk-card [data-testid="stDataFrame"] div[role='gridcell']{{ white-space: normal !important; word-break: break-word !important; overflow-wrap: anywhere !important; }}
    </style>
    """, unsafe_allow_html=True)

def _inject_alert_center():
    st.markdown("""
    <div id="envy-alert-root" style="position:fixed;top:16px;right:16px;z-index:999999;pointer-events:none;"></div>
    <style>
      .envy-toast{min-width:220px;max-width:420px;margin:8px 0;padding:.7rem 1rem;border-radius:12px;color:#fff;font-weight:700;box-shadow:0 8px 24px rgba(0,0,0,.25);opacity:0;transform:translateY(-6px);transition:opacity .2s ease, transform .2s ease;}
      .envy-toast.show{opacity:1;transform:translateY(0)}
      .envy-info{background:#2563eb}.envy-warn{background:#d97706}.envy-error{background:#dc2626}
    </style>
    <script>
      (function(){
        const root = document.getElementById('envy-alert-root');
        function toast(level, text){
          const el = document.createElement('div');
          el.className='envy-toast envy-'+(level||'info'); el.textContent=text||'ì•Œë¦¼';
          el.style.pointerEvents='auto'; root.appendChild(el);
          requestAnimationFrame(()=>el.classList.add('show'));
          setTimeout(()=>{el.classList.remove('show'); setTimeout(()=>el.remove(), 300);}, 5000);
        }
        window.addEventListener('message',(e)=>{ const d=e.data||{}; if(d.__envy && d.kind==='alert'){toast(d.level,d.msg);} },false);
        let heard=false; window.addEventListener('message',(e)=>{ const d=e.data||{}; if(d.__envy && d.kind==='title'){heard=true;}},false);
        setTimeout(()=>{ if(!heard){ toast('warn','ë°ì´í„°ë© ì—°ê²°ì´ ì§€ì—°ë˜ê³  ìˆì–´ìš”.'); } },8000);
      })();
    </script>
    """, unsafe_allow_html=True)

# =========================
# 2) Responsive
# =========================
def _responsive_probe():
    html = """
    <script>
    (function(){
      const bps=[900,1280,1600];
      const w=Math.max(document.documentElement.clientWidth||0, window.innerWidth||0);
      let bin=0; for(let i=0;i<bps.length;i++) if(w>=bps[i]) bin=i+1;
      const url=new URL(window.location); const curr=url.searchParams.get('vwbin');
      if(curr!==String(bin)){ url.searchParams.set('vwbin', String(bin)); window.location.replace(url.toString()); }
    })();
    </script>
    """
    st.components.v1.html(html, height=0, scrolling=False)

def _get_view_bin():
    try:
        raw = st.query_params.get("vwbin", "3")
    except Exception:
        raw = (st.experimental_get_query_params().get("vwbin", ["3"])[0])
    try:
        return max(0, min(3, int(raw)))
    except:
        return 3

# =========================
# 3) Generic proxy iframe
# =========================
def _proxy_iframe(proxy_base: str, target_url: str, height: int = 860, scroll=True, key=None):
    proxy = (proxy_base or "").strip().rstrip("/")
    url   = f"{proxy}/?url={quote(target_url, safe=':/?&=%')}"
    h     = int(height)
    try:
        st.iframe(url, height=h); return
    except Exception:
        pass
    try:
        st.components.v1.iframe(url, height=h, scrolling=bool(scroll)); return
    except Exception:
        pass
    st.markdown(f'<iframe src="{url}" style="width:100%;height:{h}px;border:0;border-radius:10px;"></iframe>',
                unsafe_allow_html=True)

def _proxy_iframe_with_title(proxy_base: str, target_url: str, height: int = 860, key: str = "naver_home"):
    proxy = (proxy_base or "").strip().rstrip("/")
    url   = f"{proxy}/?url={quote(target_url, safe=':/?&=%')}"
    h     = int(height)
    html  = f'''
<div id="{key}-wrap" style="width:100%;overflow:hidden;">
  <div id="{key}-title"
       style="display:inline-block;border-radius:9999px;padding:.40rem .9rem;
              font-weight:800;background:#dbe6ff;border:1px solid #88a8ff;color:#09245e;margin:0 0 .5rem 0;">
    DataLab
  </div>
  <iframe src="{url}" style="width:100%;height:{h}px;border:0;border-radius:10px;"></iframe>
</div>
<script>
(function(){{
  var titleEl=document.getElementById("{key}-title");
  window.addEventListener("message",function(e){{
    try{{var d=e.data||{{}}; if(d.__envy && d.kind==="title" && d.title) titleEl.textContent=d.title;}}catch(_){{
    }}
  }},false);
}})();
</script>
'''
    st.components.v1.html(html, height=h+56, scrolling=False)

# =========================
# 4) Sidebar (theme + translator toggle + calculators)
# =========================
def _sidebar():
    _ensure_session_defaults(); _inject_css(); _inject_alert_center()
    with st.sidebar:
        lp = Path(__file__).parent / "logo.png"
        if lp.exists():
            b64 = base64.b64encode(lp.read_bytes()).decode("ascii")
            st.markdown(f'<div class="logo-circle"><img src="data:image/png;base64,{b64}"></div>', unsafe_allow_html=True)

        c1, c2 = st.columns(2)
        with c1:
            st.toggle("ğŸŒ“ ë‹¤í¬", value=(st.session_state.get("theme","light")=="dark"),
                      on_change=_toggle_theme, key="__theme_toggle")
        with c2:
            st.toggle("ğŸŒ ë²ˆì—­ê¸°", value=False, key="__show_translator")
        show_tr = st.session_state.get("__show_translator", False)

        def translator_block(expanded=True):
            with st.expander("ğŸŒ êµ¬ê¸€ ë²ˆì—­ê¸°", expanded=expanded):
                LANG_LABELS_SB = {
                    "auto":"ìë™ ê°ì§€","ko":"í•œêµ­ì–´","en":"ì˜ì–´","ja":"ì¼ë³¸ì–´","zh-CN":"ì¤‘êµ­ì–´(ê°„ì²´)",
                    "zh-TW":"ì¤‘êµ­ì–´(ë²ˆì²´)","vi":"ë² íŠ¸ë‚¨ì–´","th":"íƒœêµ­ì–´","id":"ì¸ë„ë„¤ì‹œì•„ì–´",
                    "de":"ë…ì¼ì–´","fr":"í”„ë‘ìŠ¤ì–´","es":"ìŠ¤í˜ì¸ì–´","it":"ì´íƒˆë¦¬ì•„ì–´","pt":"í¬ë¥´íˆ¬ê°ˆì–´"
                }
                def _code_sb(x): return {v:k for k,v in LANG_LABELS_SB.items()}.get(x, x)
                src_label = st.selectbox("ì›ë¬¸ ì–¸ì–´", list(LANG_LABELS_SB.values()),
                                         index=list(LANG_LABELS_SB.keys()).index("auto"), key="sb_tr_src")
                tgt_label = st.selectbox("ë²ˆì—­ ì–¸ì–´", list(LANG_LABELS_SB.values()),
                                         index=list(LANG_LABELS_SB.keys()).index("ko"), key="sb_tr_tgt")
                text_in = st.text_area("í…ìŠ¤íŠ¸", height=120, key="sb_tr_in")
                if st.button("ë²ˆì—­ ì‹¤í–‰", key="sb_tr_btn"):
                    try:
                        from deep_translator import GoogleTranslator as _GT
                    except Exception:
                        _GT = None
                    if not _GT:
                        st.error("deep-translator ì„¤ì¹˜ í•„ìš” ë˜ëŠ” ëŸ°íƒ€ì„ ë¬¸ì œ")
                    else:
                        try:
                            src_code = _code_sb(src_label); tgt_code = _code_sb(tgt_label)
                            out_main = _GT(source=src_code, target=tgt_code).translate(text_in or "")
                            st.text_area(f"ê²°ê³¼ ({tgt_label})", value=out_main, height=120, key="sb_tr_out_main")
                            if tgt_code != "ko":
                                out_ko = _GT(source=tgt_code, target="ko").translate(out_main or "")
                                st.text_area("ê²°ê³¼ (í•œêµ­ì–´)", value=out_ko, height=120, key="sb_tr_out_ko")
                        except Exception as e:
                            st.error(f"ë²ˆì—­ ì¤‘ ì˜¤ë¥˜: {e}")

        def fx_block(expanded=True):
            with st.expander("ğŸ’± í™˜ìœ¨ ê³„ì‚°ê¸°", expanded=expanded):
                fx_base = st.selectbox("ê¸°ì¤€ í†µí™”", list(CURRENCIES.keys()),
                                       index=list(CURRENCIES.keys()).index(st.session_state.get("fx_base","USD")),
                                       key="fx_base")
                sale_foreign = st.number_input("íŒë§¤ê¸ˆì•¡ (ì™¸í™”)", value=float(st.session_state.get("sale_foreign",1.0)),
                                               step=0.01, format="%.2f", key="sale_foreign")
                won = FX_DEFAULT[fx_base]*sale_foreign
                st.markdown(
                    f'<div class="pill pill-green">í™˜ì‚° ê¸ˆì•¡: <b>{won:,.2f} ì›</b>'
                    f'<span style="opacity:.75;font-weight:700"> ({CURRENCIES[fx_base]["symbol"]})</span></div>',
                    unsafe_allow_html=True
                )
                st.caption(f"í™˜ìœ¨ ê¸°ì¤€: {FX_DEFAULT[fx_base]:,.2f} â‚©/{CURRENCIES[fx_base]['unit']}")

        def margin_block(expanded=True):
            with st.expander("ğŸ“ˆ ë§ˆì§„ ê³„ì‚°ê¸°", expanded=expanded):
                m_base = st.selectbox("ë§¤ì… í†µí™”", list(CURRENCIES.keys()),
                                      index=list(CURRENCIES.keys()).index(st.session_state.get("m_base","USD")),
                                      key="m_base")
                purchase_foreign = st.number_input("ë§¤ì…ê¸ˆì•¡ (ì™¸í™”)",
                                                   value=float(st.session_state.get("purchase_foreign",0.0)),
                                                   step=0.01, format="%.2f", key="purchase_foreign")
                base_cost_won = FX_DEFAULT[m_base]*purchase_foreign if purchase_foreign>0 \
                                else FX_DEFAULT[st.session_state.get("fx_base","USD")]*st.session_state.get("sale_foreign",1.0)
                st.markdown(f'<div class="pill pill-green">ì›ê°€(â‚©): <b>{base_cost_won:,.2f} ì›</b></div>', unsafe_allow_html=True)
                c1, c2 = st.columns(2)
                with c1:
                    card_fee = st.number_input("ì¹´ë“œìˆ˜ìˆ˜ë£Œ(%)", value=float(st.session_state.get("card_fee_pct",4.0)),
                                               step=0.01, format="%.2f", key="card_fee_pct")
                with c2:
                    market_fee = st.number_input("ë§ˆì¼“ìˆ˜ìˆ˜ë£Œ(%)", value=float(st.session_state.get("market_fee_pct",14.0)),
                                                 step=0.01, format="%.2f", key="market_fee_pct")
                shipping_won = st.number_input("ë°°ì†¡ë¹„(â‚©)", value=float(st.session_state.get("shipping_won",0.0)),
                                               step=100.0, format="%.0f", key="shipping_won")
                mode = st.radio("ë§ˆì§„ ë°©ì‹", ["í¼ì„¼íŠ¸","í”ŒëŸ¬ìŠ¤"], horizontal=True, key="margin_mode")
                if mode=="í¼ì„¼íŠ¸":
                    margin_pct = st.number_input("ë§ˆì§„ìœ¨ (%)", value=float(st.session_state.get("margin_pct",10.0)),
                                                 step=0.01, format="%.2f", key="margin_pct")
                    target_price = base_cost_won*(1+card_fee/100)*(1+market_fee/100)*(1+margin_pct/100)+shipping_won
                    margin_value = target_price - base_cost_won; desc=f"{margin_pct:.2f}%"
                else:
                    margin_won = st.number_input("ë§ˆì§„ì•¡ (â‚©)", value=float(st.session_state.get("margin_won",10000.0)),
                                                 step=100.0, format="%.0f", key="margin_won")
                    target_price = base_cost_won*(1+card_fee/100)*(1+market_fee/100)+margin_won+shipping_won
                    margin_value = margin_won; desc=f"+{margin_won:,.0f}"
                st.markdown(f'<div class="pill pill-blue">íŒë§¤ê°€: <b>{target_price:,.2f} ì›</b></div>', unsafe_allow_html=True)
                st.markdown(f'<div class="pill pill-yellow">ìˆœì´ìµ(ë§ˆì§„): <b>{margin_value:,.2f} ì›</b> â€” {desc}</div>', unsafe_allow_html=True)

        if show_tr:
            translator_block(expanded=True); fx_block(expanded=False); margin_block(expanded=False)
        else:
            fx_block(expanded=True); margin_block(expanded=True); translator_block(expanded=False)

        if SHOW_ADMIN_BOX:
            st.divider()
            st.text_input("PROXY_URL(ë””ë²„ê·¸)", key="PROXY_URL", help="Cloudflare Worker ì£¼ì†Œ (ì˜µì…˜)")

# =========================
# 5) Rakuten Ranking
# =========================
def _rakuten_keys():
    app_id = _get_key("RAKUTEN_APP_ID")
    affiliate = _get_key("RAKUTEN_AFFILIATE_ID")
    return app_id, affiliate

@st.cache_data(ttl=900, show_spinner=False)
def _rk_fetch_rank_cached(genre_id: str, topn: int = 20, strip_emoji: bool=True) -> pd.DataFrame:
    app_id, affiliate = _rakuten_keys()
    def _clean(s: str) -> str:
        if not strip_emoji: return s
        return re.sub(r"[\U00010000-\U0010ffff]", "", s or "")
    if not (requests and app_id):
        rows=[{"rank":i+1,"keyword":_clean(f"[ìƒ˜í”Œ] í‚¤ì›Œë“œ {i+1} ãƒãƒ­ã‚¦ã‚£ãƒ³ ç§‹ ğŸ‚"),
               "shop":"ìƒ˜í”Œ","url":"https://example.com"} for i in range(topn)]
        return pd.DataFrame(rows)
    def _do():
        api = "https://app.rakuten.co.jp/services/api/IchibaItem/Ranking/20170628"
        params = {"applicationId": app_id, "genreId": str(genre_id).strip(), "hits": topn}
        if affiliate: params["affiliateId"] = affiliate
        r = requests.get(api, params=params, timeout=12)
        r.raise_for_status()
        items = r.json().get("Items", [])[:topn]
        rows=[]
        for it in items:
            node = it.get("Item", {})
            rows.append({
                "rank": node.get("rank"),
                "keyword": _clean(node.get("itemName","")),
                "shop": node.get("shopName",""),
                "url": node.get("itemUrl",""),
            })
        return pd.DataFrame(rows)
    try:
        return _do()
    except Exception:
        rows=[{"rank":i+1,"keyword":_clean(f"[ìƒ˜í”Œ] í‚¤ì›Œë“œ {i+1} ãƒãƒ­ã‚¦ã‚£ãƒ³ ç§‹ ğŸ‚"),
               "shop":"ìƒ˜í”Œ","url":"https://example.com"} for i in range(topn)]
        return pd.DataFrame(rows)

def section_rakuten_ui():
    st.markdown('<div id="rk-card">', unsafe_allow_html=True)
    colB, colC = st.columns([2,1])
    with colB:
        cat = st.selectbox("ë¼ì¿ í… ì¹´í…Œê³ ë¦¬",
                           ["ì „ì²´(ìƒ˜í”Œ)","ë·°í‹°/ì½”ìŠ¤ë©”í‹±","ì˜ë¥˜/íŒ¨ì…˜","ê°€ì „/ë””ì§€í„¸","ê°€êµ¬/ì¸í…Œë¦¬ì–´","ì‹í’ˆ","ìƒí™œ/ê±´ê°•","ìŠ¤í¬ì¸ /ë ˆì €","ë¬¸êµ¬/ì·¨ë¯¸"], key="rk_cat")
    with colC:
        sample_only = st.checkbox("ìƒ˜í”Œ ë³´ê¸°", value=False, key="rk_sample")
    strip_emoji = st.toggle("ì´ëª¨ì§€ ì œê±°", value=True, key="rk_strip_emoji")
    genre_map = st.session_state.get("rk_genre_map", {})
    genre_id = (genre_map.get(cat) or "").strip() or "100283"
    with st.spinner("ë¼ì¿ í… ë­í‚¹ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
        df = (pd.DataFrame([{"rank":i+1,"keyword":f"[ìƒ˜í”Œ] í‚¤ì›Œë“œ {i+1}","shop":"ìƒ˜í”Œ","url":"https://example.com"} for i in range(20)])
              if sample_only else _rk_fetch_rank_cached(genre_id, topn=20, strip_emoji=strip_emoji))
    colcfg = {
        "rank": st.column_config.NumberColumn("rank", width="small"),
        "keyword": st.column_config.TextColumn("keyword", width="medium"),
        "shop": st.column_config.TextColumn("shop", width="small"),
        "url": st.column_config.LinkColumn("url", display_text="ì—´ê¸°", width="small"),
    }
    st.dataframe(df[["rank","keyword","shop","url"]], hide_index=True, use_container_width=True, height=430, column_config=colcfg)
    st.download_button("í‘œ CSV ë‹¤ìš´ë¡œë“œ", data=df.to_csv(index=False).encode("utf-8-sig"),
                       file_name="rakuten_ranking.csv", mime="text/csv")
    with st.expander("ğŸ”§ ì¥ë¥´ ë§¤í•‘ í¸ì§‘ (í™”ë©´ì—ëŠ” ìˆ¨ê¹€)", expanded=False):
        st.caption("ì¹´í…Œê³ ë¦¬ â†’ genreId ë§¤í•‘ì…ë‹ˆë‹¤. ì˜¬ë°”ë¥¸ genreIdë¡œ ë°”ê¾¸ê³  ì €ì¥í•˜ì„¸ìš”.")
        g1, g2 = st.columns(2)
        with g1:
            for k in ["ë·°í‹°/ì½”ìŠ¤ë©”í‹±","ì˜ë¥˜/íŒ¨ì…˜","ê°€êµ¬/ì¸í…Œë¦¬ì–´","ìŠ¤í¬ì¸ /ë ˆì €","ë¬¸êµ¬/ì·¨ë¯¸"]:
                st.session_state["rk_genre_map"][k] = st.text_input(k, st.session_state["rk_genre_map"].get(k,"100283"), key=f"rk_{k}")
        with g2:
            for k in ["ê°€ì „/ë””ì§€í„¸","ì‹í’ˆ","ìƒí™œ/ê±´ê°•","ì „ì²´(ìƒ˜í”Œ)"]:
                st.session_state["rk_genre_map"][k] = st.text_input(k, st.session_state["rk_genre_map"].get(k,"100283"), key=f"rk_{k}")
        st.info("ì„¸ì…˜ì— ì €ì¥ë©ë‹ˆë‹¤. ì•± ì¬ì‹¤í–‰ ì‹œ ì´ˆê¸°ê°’ìœ¼ë¡œ ëŒì•„ì˜¬ ìˆ˜ ìˆì–´ìš”.")
    st.markdown('</div>', unsafe_allow_html=True)

# =========================
# 6) Korea Radar (Naver Searchad API)
# =========================
import hashlib, hmac, base64 as b64
def _naver_signature(timestamp: str, method: str, uri: str, secret: str) -> str:
    msg = f"{timestamp}.{method}.{uri}"
    digest = hmac.new(bytes(secret, "utf-8"), bytes(msg, "utf-8"), hashlib.sha256).digest()
    return b64.b64encode(digest).decode("utf-8")
def _naver_keys_from_secrets():
    ak = _get_key("NAVER_API_KEY"); sk = _get_key("NAVER_SECRET_KEY"); cid= _get_key("NAVER_CUSTOMER_ID")
    return ak.strip(), sk.strip(), str(cid).strip()
def _naver_keywordstool(hint_keywords: list[str]) -> pd.DataFrame:
    api_key, sec_key, customer_id = _naver_keys_from_secrets()
    if not (requests and api_key and sec_key and customer_id and hint_keywords):
        return pd.DataFrame()
    base_url="https://api.naver.com"; uri="/keywordstool"; ts = str(round(time.time()*1000))
    headers = {"X-API-KEY": api_key, "X-Signature": _naver_signature(ts, "GET", uri, sec_key),
               "X-Timestamp": ts, "X-Customer": customer_id}
    params={ "hintKeywords": ",".join(hint_keywords), "includeHintKeywords": "0", "showDetail": "1" }
    r = requests.get(base_url+uri, headers=headers, params=params, timeout=12)
    try:
        r.raise_for_status()
        data = r.json().get("keywordList", [])[:200]
        if not data: return pd.DataFrame()
        df = pd.DataFrame(data).rename(columns={
            "relKeyword":"í‚¤ì›Œë“œ","monthlyPcQcCnt":"PCì›”ê°„ê²€ìƒ‰ìˆ˜","monthlyMobileQcCnt":"Mobileì›”ê°„ê²€ìƒ‰ìˆ˜",
            "monthlyAvePcClkCnt":"PCì›”í‰ê· í´ë¦­ìˆ˜","monthlyAveMobileClkCnt":"Mobileì›”í‰ê· í´ë¦­ìˆ˜",
            "monthlyAvePcCtr":"PCì›”í‰ê· í´ë¦­ë¥ ","monthlyAveMobileCtr":"Mobileì›”í‰ê· í´ë¦­ë¥ ",
            "plAvgDepth":"ì›”í‰ê· ë…¸ì¶œê´‘ê³ ìˆ˜","compIdx":"ê´‘ê³ ê²½ìŸì •ë„",
        }).drop_duplicates(["í‚¤ì›Œë“œ"]).set_index("í‚¤ì›Œë“œ").reset_index()
        num_cols=["PCì›”ê°„ê²€ìƒ‰ìˆ˜","Mobileì›”ê°„ê²€ìƒ‰ìˆ˜","PCì›”í‰ê· í´ë¦­ìˆ˜","Mobileì›”í‰ê· í´ë¦­ìˆ˜","PCì›”í‰ê· í´ë¦­ë¥ ","Mobileì›”í‰ê· í´ë¦­ë¥ ","ì›”í‰ê· ë…¸ì¶œê´‘ê³ ìˆ˜"]
        for c in num_cols: df[c]=pd.to_numeric(df[c], errors="coerce")
        return df
    except Exception:
        return pd.DataFrame()

def _count_product_from_shopping(keyword: str) -> int|None:
    if not requests: return None
    try:
        url=f"https://search.shopping.naver.com/search/all?where=all&frm=NVSCTAB&query={quote(keyword)}"
        r=requests.get(url, timeout=10); r.raise_for_status()
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(r.text, "html.parser")
        a_tags = soup.select("a.subFilter_filter__3Y-uy")
        for a in a_tags:
            if "ì „ì²´" in a.text:
                span = a.find("span")
                if span:
                    txt = span.get_text().replace(",","").strip()
                    return int(re.sub(r"[^0-9]", "", txt) or "0")
        return None
    except Exception:
        return None

def section_korea_ui():
    st.caption("â€» ê²€ìƒ‰ì§€í‘œëŠ” ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API(í‚¤ì›Œë“œë„êµ¬) ê¸°ì¤€, ìƒí’ˆìˆ˜ëŠ” ë„¤ì´ë²„ì‡¼í•‘ â€˜ì „ì²´â€™ íƒ­ í¬ë¡¤ë§ ê¸°ì¤€ì…ë‹ˆë‹¤.")
    c1, c2, c3 = st.columns([1,1,1])
    with c1:
        months = st.slider("ë¶„ì„ê¸°ê°„(ê°œì›”, í‘œì‹œìš©)", 1, 6, 3)
    with c2:
        device = st.selectbox("ë””ë°”ì´ìŠ¤", ["all","pc","mo"], index=0)
    with c3:
        src = st.selectbox("í‚¤ì›Œë“œ ì†ŒìŠ¤", ["ì§ì ‘ ì…ë ¥"], index=0)
    keywords_txt = st.text_area("í‚¤ì›Œë“œ(ì½¤ë§ˆë¡œ êµ¬ë¶„)", "í•¸ë“œë©”ì´ë“œì½”íŠ¸, ë‚¨ìì½”íŠ¸, ì—¬ìì½”íŠ¸", height=96)
    kw_list = [k.strip() for k in (keywords_txt or "").split(",") if k.strip()]
    opt1, opt2 = st.columns([1,1])
    with opt1:
        add_product = st.toggle("ë„¤ì´ë²„ì‡¼í•‘ â€˜ì „ì²´â€™ ìƒí’ˆìˆ˜ ìˆ˜ì§‘(ëŠë¦¼)", value=False)
    with opt2:
        table_mode = st.radio("í‘œ ëª¨ë“œ", ["A(ê²€ìƒ‰ì§€í‘œ)","B(ê²€ìƒ‰+ìˆœìœ„)","C(ê²€ìƒ‰+ìƒí’ˆìˆ˜+ìŠ¤ì½”ì–´)"], horizontal=True, index=2)
    if st.button("ë ˆì´ë” ì—…ë°ì´íŠ¸", use_container_width=False):
        with st.spinner("ë„¤ì´ë²„ í‚¤ì›Œë“œë„êµ¬ ì¡°íšŒ ì¤‘â€¦"):
            df = _naver_keywordstool(kw_list)
        if df.empty:
            st.error("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (API/ê¶Œí•œ/ì¿¼í„° ë˜ëŠ” í‚¤ì›Œë“œ í™•ì¸)")
            return
        if table_mode.startswith("A"):
            st.dataframe(df, use_container_width=True, height=430)
            st.download_button("CSV ë‹¤ìš´ë¡œë“œ", df.to_csv(index=False).encode("utf-8-sig"),
                               file_name="korea_keyword_A.csv", mime="text/csv"); return
        df2 = df.copy()
        df2["ê²€ìƒ‰í•©ê³„"] = (pd.to_numeric(df2["PCì›”ê°„ê²€ìƒ‰ìˆ˜"], errors="coerce").fillna(0) +
                           pd.to_numeric(df2["Mobileì›”ê°„ê²€ìƒ‰ìˆ˜"], errors="coerce").fillna(0))
        df2["ê²€ìƒ‰ìˆœìœ„"] = df2["ê²€ìƒ‰í•©ê³„"].rank(ascending=False, method="min")
        if table_mode.startswith("B"):
            out = df2.sort_values("ê²€ìƒ‰ìˆœìœ„")
            st.dataframe(out, use_container_width=True, height=430)
            st.download_button("CSV ë‹¤ìš´ë¡œë“œ", out.to_csv(index=False).encode("utf-8-sig"),
                               file_name="korea_keyword_B.csv", mime="text/csv"); return
        product_counts = []
        if add_product:
            with st.spinner("ë„¤ì´ë²„ì‡¼í•‘ ìƒí’ˆìˆ˜ ìˆ˜ì§‘ ì¤‘â€¦(í‚¤ì›Œë“œ ìˆ˜ì— ë”°ë¼ ìˆ˜ ë¶„ ì†Œìš”)"):
                for k in df2["í‚¤ì›Œë“œ"]:
                    cnt = _count_product_from_shopping(k)
                    product_counts.append(cnt if cnt is not None else math.nan)
        else:
            product_counts = [math.nan]*len(df2)
        df2["íŒë§¤ìƒí’ˆìˆ˜"] = product_counts
        df2["ìƒí’ˆìˆ˜ìˆœìœ„"] = df2["íŒë§¤ìƒí’ˆìˆ˜"].rank(na_option="bottom", method="min")
        df2["ìƒí’ˆë°œêµ´ëŒ€ìƒ"] = (df2["ê²€ìƒ‰ìˆœìœ„"] + df2["ìƒí’ˆìˆ˜ìˆœìœ„"]).rank(na_option="bottom", method="min")
        cols = ["í‚¤ì›Œë“œ","PCì›”ê°„ê²€ìƒ‰ìˆ˜","Mobileì›”ê°„ê²€ìƒ‰ìˆ˜","íŒë§¤ìƒí’ˆìˆ˜",
                "PCì›”í‰ê· í´ë¦­ìˆ˜","Mobileì›”í‰ê· í´ë¦­ìˆ˜","PCì›”í‰ê· í´ë¦­ë¥ ","Mobileì›”í‰ê· í´ë¦­ë¥ ",
                "ì›”í‰ê· ë…¸ì¶œê´‘ê³ ìˆ˜","ê´‘ê³ ê²½ìŸì •ë„","ê²€ìƒ‰ìˆœìœ„","ìƒí’ˆìˆ˜ìˆœìœ„","ìƒí’ˆë°œêµ´ëŒ€ìƒ"]
        out = df2[cols].sort_values("ìƒí’ˆë°œêµ´ëŒ€ìƒ")
        st.dataframe(out, use_container_width=True, height=430)
        st.download_button("CSV ë‹¤ìš´ë¡œë“œ", out.to_csv(index=False).encode("utf-8-sig"),
                           file_name="korea_keyword_C.csv", mime="text/csv")

# =========================
# 7) DataLab Trend (Open API) + Category â†’ Top20 UI (+ Direct Trend)
# =========================
@st.cache_data(ttl=1800, show_spinner=False)
def _datalab_trend(groups: list, start_date: str, end_date: str,
                   time_unit: str = "week", device: str = "", gender: str = "", ages: list | None = None) -> pd.DataFrame:
    if not requests: return pd.DataFrame()
    cid  = _get_key("NAVER_CLIENT_ID"); csec = _get_key("NAVER_CLIENT_SECRET")
    if not (cid and csec): return pd.DataFrame()
    ref = _get_key("NAVER_WEB_REFERER").strip() or "https://2vrc9owdssnberky8hssf7.streamlit.app"
    groups = (groups or [])[:5]
    url = "https://openapi.naver.com/v1/datalab/search"
    headers = {"X-Naver-Client-Id": cid, "X-Naver-Client-Secret": csec, "Content-Type": "application/json; charset=utf-8", "Referer": ref}
    payload = {"startDate": start_date, "endDate": end_date, "timeUnit": time_unit, "keywordGroups": groups}
    r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=12)
    try:
        r.raise_for_status()
        js = r.json(); out=[]
        for gr in js.get("results", []):
            name = gr.get("title") or (gr.get("keywords") or [""])[0]
            tmp = pd.DataFrame(gr.get("data", []))
            if tmp.empty: continue
            tmp["keyword"] = name; out.append(tmp)
        if not out: return pd.DataFrame()
        big = pd.concat(out, ignore_index=True)
        big.rename(columns={"period": "ë‚ ì§œ", "ratio": "ê²€ìƒ‰ì§€ìˆ˜"}, inplace=True)
        pivot = big.pivot_table(index="ë‚ ì§œ", columns="keyword", values="ê²€ìƒ‰ì§€ìˆ˜", aggfunc="mean")
        pivot = pivot.reset_index().sort_values("ë‚ ì§œ")
        return pivot
    except Exception:
        return pd.DataFrame()

SEED_MAP = {
    "íŒ¨ì…˜ì˜ë¥˜":   ["ì›í”¼ìŠ¤","ì½”íŠ¸","ë‹ˆíŠ¸","ì…”ì¸ ","ë¸”ë¼ìš°ìŠ¤"],
    "íŒ¨ì…˜ì¡í™”":   ["ê°€ë°©","ì§€ê°‘","ëª¨ì","ìŠ¤ì¹´í”„","ë²¨íŠ¸"],
    "ë·°í‹°/ë¯¸ìš©":  ["ì¿ ì…˜","ë¦½ìŠ¤í‹±","ì„ í¬ë¦¼","ë§ˆìŠ¤ì¹´ë¼","í† ë„ˆ"],
    "ìƒí™œ/ê±´ê°•":  ["ì¹«ì†”","ì¹˜ì•½","ìƒ´í‘¸","ì„¸ì œ","ë¬¼í‹°ìŠˆ"],
    "ë””ì§€í„¸/ê°€ì „": ["ë¸”ë£¨íˆ¬ìŠ¤ì´ì–´í°","ìŠ¤í”¼ì»¤","ëª¨ë‹ˆí„°","ë…¸íŠ¸ë¶","ë¡œë´‡ì²­ì†Œê¸°"],
    "ìŠ¤í¬ì¸ /ë ˆì €": ["ëŸ¬ë‹í™”","ìš”ê°€ë³µ","ìº í•‘ì˜ì","í…íŠ¸","ìì „ê±°"],
}

def section_category_keyword_lab():
    st.markdown('<div class="card"><div class="card-title">ì¹´í…Œê³ ë¦¬ â†’ í‚¤ì›Œë“œ Top20 & íŠ¸ë Œë“œ</div>', unsafe_allow_html=True)
    cA, cB, cC = st.columns([1,1,1])
    with cA:
        cat = st.selectbox("ì¹´í…Œê³ ë¦¬", list(SEED_MAP.keys()))
    with cB:
        time_unit = st.selectbox("ë‹¨ìœ„", ["week", "month"], index=0)
    with cC:
        months = st.slider("ì¡°íšŒê¸°ê°„(ê°œì›”)", 1, 12, 3)
    start = (dt.date.today() - dt.timedelta(days=30 * months)).strftime("%Y-%m-%d")
    end   = (dt.date.today() - dt.timedelta(days=1)).strftime("%Y-%m-%d")
    seeds = SEED_MAP.get(cat, [])
    df = _naver_keywordstool(seeds)
    if df.empty:
        st.warning("í‚¤ì›Œë“œë„êµ¬ ì‘ë‹µì´ ë¹„ì—ˆìŠµë‹ˆë‹¤. (API/ê¶Œí•œ/ì¿¼í„° í™•ì¸)")
        st.markdown('</div>', unsafe_allow_html=True); return
    df["ê²€ìƒ‰í•©ê³„"] = pd.to_numeric(df["PCì›”ê°„ê²€ìƒ‰ìˆ˜"], errors="coerce").fillna(0) + pd.to_numeric(df["Mobileì›”ê°„ê²€ìƒ‰ìˆ˜"], errors="coerce").fillna(0)
    top20 = df.sort_values("ê²€ìƒ‰í•©ê³„", ascending=False).head(20).reset_index(drop=True)
    st.dataframe(top20[["í‚¤ì›Œë“œ","ê²€ìƒ‰í•©ê³„","PCì›”ê°„ê²€ìƒ‰ìˆ˜","Mobileì›”ê°„ê²€ìƒ‰ìˆ˜","ì›”í‰ê· ë…¸ì¶œê´‘ê³ ìˆ˜","ê´‘ê³ ê²½ìŸì •ë„"]],
                 use_container_width=True, height=340)
    st.download_button("CSV ë‹¤ìš´ë¡œë“œ", top20.to_csv(index=False).encode("utf-8-sig"),
                       file_name=f"category_{cat}_top20.csv", mime="text/csv")
    topk = st.slider("ë¼ì¸ì°¨íŠ¸ í‚¤ì›Œë“œ ìˆ˜", 3, 10, 5, help="ìƒìœ„ Nê°œ í‚¤ì›Œë“œë§Œ íŠ¸ë Œë“œë¥¼ ê·¸ë¦½ë‹ˆë‹¤.")
    kws = top20["í‚¤ì›Œë“œ"].head(topk).tolist()
    groups = [{"groupName": k, "keywords": [k]} for k in kws]
    ts = _datalab_trend(groups, start, end, time_unit=time_unit)
    if ts.empty:
        st.info("DataLab íŠ¸ë Œë“œ ì‘ë‹µì´ ë¹„ì–´ ìˆì–´ìš”. (Client ID/Secret, Referer/í™˜ê²½, ë‚ ì§œ/ë‹¨ìœ„ í™•ì¸)")
    else:
        try:
            st.line_chart(ts.set_index("ë‚ ì§œ"))
        except Exception:
            st.dataframe(ts, use_container_width=True, height=260)
    st.markdown('</div>', unsafe_allow_html=True)

def section_keyword_trend_widget():
    st.markdown('<div class="card"><div class="card-title">í‚¤ì›Œë“œ íŠ¸ë Œë“œ (ì§ì ‘ ì…ë ¥)</div>', unsafe_allow_html=True)
    kwtxt  = st.text_input("í‚¤ì›Œë“œ(ì½¤ë§ˆ)", "ê°€ë°©, ì›í”¼ìŠ¤", key="kw_txt")
    unit   = st.selectbox("ë‹¨ìœ„", ["week", "month"], index=0, key="kw_unit")
    months = st.slider("ì¡°íšŒê¸°ê°„(ê°œì›”)", 1, 12, 3, key="kw_months")
    if st.button("íŠ¸ë Œë“œ ì¡°íšŒ", key="kw_run"):
        start = (dt.date.today() - dt.timedelta(days=30 * months)).strftime("%Y-%m-%d")
        end   = (dt.date.today() - dt.timedelta(days=1)).strftime("%Y-%m-%d")
        kws = [k.strip() for k in (kwtxt or "").split(",") if k.strip()]
        groups = [{"groupName": k, "keywords": [k]} for k in kws][:5]
        df = _datalab_trend(groups, start, end, time_unit=unit)
        if df.empty:
            st.error("DataLab íŠ¸ë Œë“œ ì‘ë‹µì´ ë¹„ì–´ ìˆì–´ìš”. (Client ID/Secret, Referer/í™˜ê²½, ê¶Œí•œ/ì¿¼í„°/ë‚ ì§œ/ë‹¨ìœ„ í™•ì¸)")
        else:
            st.dataframe(df, use_container_width=True, height=260)
            st.line_chart(df.set_index("ë‚ ì§œ"))
    st.markdown('</div>', unsafe_allow_html=True)

# =========================
# 8) Radar Card (tabs: êµ­ë‚´ -> í•´ì™¸)
# =========================
def section_radar():
    st.markdown('<div class="card"><div class="card-title">AI í‚¤ì›Œë“œ ë ˆì´ë”</div>', unsafe_allow_html=True)
    tab_domestic, tab_overseas = st.tabs(["êµ­ë‚´", "í•´ì™¸"])
    with tab_domestic:
        section_korea_ui()
    with tab_overseas:
        section_rakuten_ui()
    st.markdown('</div>', unsafe_allow_html=True)

# =========================
# Stopwords Manager UI (ê³µìš©) â€” ìƒì„±ê¸° íƒ­/ì™¸ë¶€ ì„¹ì…˜ì—ì„œ ì¬ì‚¬ìš©
# =========================
def _stopwords_manager_ui(compact: bool = False):
    ss = st.session_state
    ss.setdefault("STOP_GLOBAL", list(STOPWORDS_GLOBAL))
    ss.setdefault("STOP_BY_CAT", dict(STOPWORDS_BY_CAT))
    ss.setdefault("STOP_WHITELIST", [])
    ss.setdefault("STOP_REPLACE", ["ë¬´ë°°=> ", "ë¬´ë£Œë°°ì†¡=> ", "ì •í’ˆ=> "])
    ss.setdefault("STOP_AGGR", False)

    # í”„ë¦¬ì…‹(ì»´íŒ©íŠ¸ ëª¨ë“œì—ì„  ìˆ¨ê¹€)
    if not compact:
        with st.expander("ğŸ”§ í”„ë¦¬ì…‹", expanded=False):
            preset = st.selectbox("í”„ë¦¬ì…‹", list(STOP_PRESETS.keys()), key="stop_preset_sel")
            if st.button("í”„ë¦¬ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°", key="stop_preset_load"):
                obj = STOP_PRESETS[preset]
                ss["STOP_GLOBAL"]    = list(obj.get("global", []))
                ss["STOP_BY_CAT"]    = dict(obj.get("by_cat", {}))
                ss["STOP_WHITELIST"] = list(obj.get("whitelist", []))
                ss["STOP_REPLACE"]   = list(obj.get("replace", []))
                ss["STOP_AGGR"]      = bool(obj.get("aggressive", False))
                st.success(f"í”„ë¦¬ì…‹ â€˜{preset}â€™ ì ìš© ì™„ë£Œ")

    tab_global, tab_cat, tab_white, tab_replace, tab_io = st.tabs(
        ["ì „ì—­ ê¸ˆì¹™ì–´", "ì¹´í…Œê³ ë¦¬ ê¸ˆì¹™ì–´", "í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸", "ì¹˜í™˜ ê·œì¹™", "ê°€ì ¸ì˜¤ê¸°/ë‚´ë ¤ë°›ê¸°"]
    )

    with tab_global:
        txt = st.text_area("ì „ì—­ ê¸ˆì¹™ì–´ (ì½¤ë§ˆ)", value=",".join(ss["STOP_GLOBAL"]), height=120, key="stop_glob_txt")
        if st.button("ì €ì¥(ì „ì—­)", key="stop_glob_save"):
            ss["STOP_GLOBAL"] = [t.strip() for t in txt.split(",") if t.strip()]
            st.success("ì „ì—­ ê¸ˆì¹™ì–´ ì €ì¥ ì™„ë£Œ")

    with tab_cat:
        all_cats = sorted(set(list(ss["STOP_BY_CAT"].keys()) + list(STOPWORDS_BY_CAT.keys()))) or \
                   ["íŒ¨ì…˜ì˜ë¥˜","íŒ¨ì…˜ì¡í™”","ë·°í‹°/ë¯¸ìš©","ìƒí™œ/ê±´ê°•","ë””ì§€í„¸/ê°€ì „","ìŠ¤í¬ì¸ /ë ˆì €"]
        cat = st.selectbox("ì¹´í…Œê³ ë¦¬", all_cats, key="stop_cat_sel")
        curr = ",".join(ss["STOP_BY_CAT"].get(cat, []))
        new  = st.text_area("í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ê¸ˆì¹™ì–´ (ì½¤ë§ˆ)", value=curr, height=120, key=f"stop_cat_txt_{cat}")
        c1, c2 = st.columns([1,1])
        with c1:
            if st.button("ì €ì¥(ì¹´í…Œê³ ë¦¬)", key=f"stop_cat_save_{cat}"):
                ss["STOP_BY_CAT"][cat] = [t.strip() for t in new.split(",") if t.strip()]
                st.success(f"{cat} ì €ì¥ ì™„ë£Œ")
        with c2:
            ss["STOP_AGGR"] = st.toggle("ê³µê²©ì  ë¶€ë¶„ì¼ì¹˜ ì œê±°", value=bool(ss["STOP_AGGR"]), key="stop_aggr_ui")

    with tab_white:
        wt = st.text_area("í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸(í—ˆìš©, ì½¤ë§ˆ)", value=",".join(ss["STOP_WHITELIST"]), height=100, key="stop_white_txt")
        if st.button("ì €ì¥(í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸)", key="stop_white_save"):
            ss["STOP_WHITELIST"] = [t.strip() for t in wt.split(",") if t.strip()]
            st.success("í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ")

    with tab_replace:
        rp = st.text_area("ì¹˜í™˜ ê·œì¹™ (í˜•ì‹: src=>dst, ì½¤ë§ˆ)", value=",".join(ss["STOP_REPLACE"]), height=100, key="stop_repl_txt")
        if st.button("ì €ì¥(ì¹˜í™˜)", key="stop_repl_save"):
            ss["STOP_REPLACE"] = [t.strip() for t in rp.split(",") if t.strip()]
            st.success("ì¹˜í™˜ ê·œì¹™ ì €ì¥ ì™„ë£Œ")

    with tab_io:
        payload = {
            "global": ss["STOP_GLOBAL"],
            "by_cat": ss["STOP_BY_CAT"],
            "whitelist": ss["STOP_WHITELIST"],
            "replace": ss["STOP_REPLACE"],
            "aggressive": bool(ss["STOP_AGGR"]),
        }
        st.download_button("ì„¤ì • ë‚´ë ¤ë°›ê¸°(JSON)",
                           data=json.dumps(payload, ensure_ascii=False, indent=2).encode("utf-8"),
                           file_name="stopwords_profile.json", mime="application/json", key="stop_dl")
        up = st.file_uploader("ì„¤ì • ê°€ì ¸ì˜¤ê¸°(JSON)", type=["json"], key="stop_ul")
        if up:
            try:
                obj = json.load(io.TextIOWrapper(up, encoding="utf-8"))
                ss["STOP_GLOBAL"]    = list(obj.get("global", ss["STOP_GLOBAL"]))
                ss["STOP_BY_CAT"]    = dict(obj.get("by_cat", ss["STOP_BY_CAT"]))
                ss["STOP_WHITELIST"] = list(obj.get("whitelist", ss["STOP_WHITELIST"]))
                ss["STOP_REPLACE"]   = list(obj.get("replace", ss["STOP_REPLACE"]))
                ss["STOP_AGGR"]      = bool(obj.get("aggressive", ss["STOP_AGGR"]))
                st.success("ì„¤ì • ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ")
            except Exception as e:
                st.error(f"ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")

# =========================
# 9) ìƒí’ˆëª… ìƒì„±ê¸° (ë„¤ì´ë²„ SEO + ê¸ˆì¹™ì–´ íƒ­ í†µí•©)
# =========================
def section_title_generator():
    import re, math
    st.markdown('<div class="card"><div class="card-title">ìƒí’ˆëª… ìƒì„±ê¸° (ë„¤ì´ë²„ SEO ìë™ í™•ì¥ + ê¸ˆì¹™ì–´)</div>', unsafe_allow_html=True)

    # === íƒ­ êµ¬ì„± ===
    tab_gen, tab_stop = st.tabs(["ìƒì„±ê¸°", "ê¸ˆì¹™ì–´ ê´€ë¦¬"])

    # ---------- ê¸ˆì¹™ì–´ ê´€ë¦¬ì íƒ­ ----------
    with tab_stop:
        _stopwords_manager_ui(compact=True)

    # ---------- ìƒì„±ê¸° íƒ­ ----------
    with tab_gen:
        def _norm(s: str) -> str:
            s = (s or "").strip()
            s = re.sub(r"[ \t\u3000]+", " ", s)
            return re.sub(r"\s{2,}", " ", s)

        def _dedup(tokens):
            seen=set(); out=[]
            for t in tokens:
                t=_norm(t)
                if not t: continue
                key=t.lower()
                if key in seen: continue
                seen.add(key); out.append(t)
            return out

        def _smart_truncate(title: str, max_len: int, must_keep_prefix: str = "") -> str:
            title=_norm(title)
            if len(title)<=max_len: return title
            if must_keep_prefix and title.startswith(must_keep_prefix):
                return title[:max_len-1]+"â€¦"
            cut=title[:max_len+1]
            m=re.search(r"(.{0,"+str(max_len)+r"})(?:[\s\|\Â·\-]|$)", cut)
            if m and m.group(1):
                out=m.group(1).rstrip()
                return out+("â€¦" if len(out)<len(title) else "")
            return title[:max_len-1]+"â€¦"

        def _score_keywords(df: pd.DataFrame) -> pd.DataFrame:
            tmp=df.copy()
            for c in ["PCì›”ê°„ê²€ìƒ‰ìˆ˜","Mobileì›”ê°„ê²€ìƒ‰ìˆ˜","ê´‘ê³ ê²½ìŸì •ë„"]:
                tmp[c]=pd.to_numeric(tmp[c], errors="coerce").fillna(0.0)
            tmp["ê²€ìƒ‰í•©ê³„"]=tmp["PCì›”ê°„ê²€ìƒ‰ìˆ˜"]+tmp["Mobileì›”ê°„ê²€ìƒ‰ìˆ˜"]
            tmp["ê²½ìŸë„"]=tmp["ê´‘ê³ ê²½ìŸì •ë„"].clip(lower=0, upper=1)
            tmp["SEOì ìˆ˜"]=tmp["ê²€ìƒ‰í•©ê³„"].apply(lambda x: math.log1p(x))*(1.0-tmp["ê²½ìŸë„"])
            return tmp.sort_values(["SEOì ìˆ˜","ê²€ìƒ‰í•©ê³„"], ascending=[False,False])

        def _would_overflow(curr: str, piece: str, max_len: int) -> bool:
            sep = "" if not curr else " "
            return len(_norm(curr+sep+piece))>max_len

        def _compile_stopwords(global_list, cate_list, user_str, replace_pairs):
            stop = set()
            for s in global_list + (cate_list or []):
                s=_norm(s)
                if s: stop.add(s.lower())
            user = [_norm(x) for x in (user_str or "").split(",") if _norm(x)]
            for s in user: stop.add(s.lower())
            part = [re.escape(s) for s in stop if len(s)>=2]
            part_re = re.compile("|".join(part), flags=re.IGNORECASE) if part else None
            repl = {}
            for pair in replace_pairs:
                src=_norm(pair.split("=>")[0] if "=>" in pair else pair)
                dst=_norm(pair.split("=>")[1]) if "=>" in pair else ""
                if src: repl[src.lower()] = dst
            return stop, part_re, repl

        def _apply_stopwords(tokens, stop_exact, stop_part_re, repl_map, aggressive=False, whitelist_set=None):
            out=[]; removed=[]
            wl = set(map(str.lower, whitelist_set or []))
            for t in tokens:
                raw=t
                if t and t.lower() in wl:
                    out.append(t); continue
                low=t.lower()
                if low in stop_exact: removed.append(raw); continue
                if low in repl_map:
                    t=repl_map[low]; low=t.lower()
                    if not t: removed.append(raw); continue
                if aggressive and stop_part_re and stop_part_re.search(t):
                    removed.append(raw); continue
                out.append(t)
            return _dedup(out), removed

        # ì…ë ¥
        left, right = st.columns([1,2])
        with left:
            brand = st.text_input("ë¸Œëœë“œ", placeholder="ì˜ˆ: Apple / ìƒ¤ì˜¤ë¯¸ / ë¬´ì§€", key="seo_brand")
            attrs = st.text_input("ì†ì„±(ì½¤ë§ˆ, ì„ íƒ)", placeholder="ì˜ˆ: ê³µì‹, ì •í’ˆ, í•œì •íŒ", key="seo_attrs")
        with right:
            kws_input = st.text_input("í•µì‹¬ í‚¤ì›Œë“œ(ì½¤ë§ˆ)", placeholder="ì˜ˆ: ë…¸íŠ¸ë¶ ìŠ¤íƒ ë“œ, ì ‘ì´ì‹, ì•Œë£¨ë¯¸ëŠ„", key="seo_kws")

        a,b,c = st.columns([1,1,1])
        with a:
            max_len = st.slider("ìµœëŒ€ ê¸€ììˆ˜", 40, 70, 50, 1, key="seo_maxlen")
        with b:
            target_min = st.slider("ëª©í‘œ ìµœì†Œ ê¸€ììˆ˜", 40, 60, 45, 1, key="seo_minlen")
        with c:
            order = st.selectbox("ìˆœì„œ", ["ë¸Œëœë“œ-í‚¤ì›Œë“œ-ì†ì„±","í‚¤ì›Œë“œ-ë¸Œëœë“œ-ì†ì„±","ë¸Œëœë“œ-ì†ì„±-í‚¤ì›Œë“œ"], index=0, key="seo_order")

        row2a, row2b = st.columns([1,1])
        with row2a:
            use_naver   = st.toggle("ë„¤ì´ë²„ SEO ëª¨ë“œ", value=True, key="seo_use_naver")
            auto_expand = st.toggle("ê²€ìƒ‰ëŸ‰ ê¸°ë°˜ ìë™ í™•ì¥", value=True, key="seo_autoexpand")
            topn        = st.slider("ìƒì„± ê°œìˆ˜(ìƒìœ„)", 3, 20, 10, 1, key="seo_topn")
        with row2b:
            cat_for_stop = st.selectbox("ê¸ˆì¹™ì–´ ì¹´í…Œê³ ë¦¬", ["(ì—†ìŒ)"]+list(STOPWORDS_BY_CAT.keys()), index=0, key="stop_cat")
            user_stop    = st.text_input("ì‚¬ìš©ì ê¸ˆì¹™ì–´(ì½¤ë§ˆ)", value="ì •í’ˆ,ë¬´ë£Œë°°ì†¡,ìµœì‹ ,ì¸ê¸°,íŠ¹ê°€", key="seo_stop")
            user_repl    = st.text_input("ì¹˜í™˜ ê·œì¹™(ì½¤ë§ˆ, src=>dst)", value="ë¬´ë°°=> ,ë¬´ë£Œë°°ì†¡=> ,ì •í’ˆ=> ", key="seo_repl")
            saved_aggr   = bool(st.session_state.get("STOP_AGGR", False))
            aggressive   = st.toggle("ê³µê²©ì  ë¶€ë¶„ì¼ì¹˜ ì œê±°", value=saved_aggr, key="stop_aggr")

        # ì‹¤í–‰
        if st.button("ìƒí’ˆëª… ìƒì„± (SEO + ê¸ˆì¹™ì–´)", key="seo_run"):
            kw_list=[_norm(k) for k in (kws_input or "").split(",") if _norm(k)]
            if not kw_list:
                st.warning("í•µì‹¬ í‚¤ì›Œë“œë¥¼ 1ê°œ ì´ìƒ ì…ë ¥í•˜ì„¸ìš”."); return

            saved_global    = st.session_state.get("STOP_GLOBAL", STOPWORDS_GLOBAL)
            saved_by_cat    = st.session_state.get("STOP_BY_CAT", STOPWORDS_BY_CAT)
            saved_whitelist = st.session_state.get("STOP_WHITELIST", [])
            saved_replace   = st.session_state.get("STOP_REPLACE", ["ë¬´ë°°=> ", "ë¬´ë£Œë°°ì†¡=> ", "ì •í’ˆ=> "])

            cate = saved_by_cat.get(cat_for_stop, []) if cat_for_stop and cat_for_stop!="(ì—†ìŒ)" else []
            replace_pairs = [x.strip() for x in (user_repl or "").split(",") if x.strip()] or list(saved_replace)
            stop_exact, stop_part_re, repl_map = _compile_stopwords(saved_global, cate, user_stop, replace_pairs)

            ranked_kws=kw_list; naver_table=None
            if use_naver:
                with st.spinner("ë„¤ì´ë²„ í‚¤ì›Œë“œ ì§€í‘œ ì¡°íšŒ ì¤‘â€¦"):
                    df_raw=_naver_keywordstool(kw_list)
                if not df_raw.empty:
                    naver_table=_score_keywords(df_raw)
                    ranked_kws=naver_table["í‚¤ì›Œë“œ"].tolist()
                else:
                    st.info("ë„¤ì´ë²„ ì§€í‘œë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì…ë ¥ í‚¤ì›Œë“œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

            brand_norm=_norm(brand)
            attrs_norm=_dedup([_norm(a) for a in (attrs or "").split(",") if _norm(a)])
            attrs_norm,_=_apply_stopwords(attrs_norm, stop_exact, stop_part_re, repl_map, aggressive, saved_whitelist)

            def _base_seq(primary_kw: str):
                if order=="ë¸Œëœë“œ-í‚¤ì›Œë“œ-ì†ì„±":
                    seq=[brand_norm, primary_kw]+attrs_norm;  prefix=_norm((brand_norm+" "+primary_kw).strip())
                elif order=="í‚¤ì›Œë“œ-ë¸Œëœë“œ-ì†ì„±":
                    seq=[primary_kw, brand_norm]+attrs_norm;  prefix=_norm((primary_kw+" "+brand_norm).strip())
                else:
                    seq=[brand_norm]+attrs_norm+[primary_kw]; prefix=_norm((brand_norm+" "+primary_kw).strip())
                seq=_dedup([t for t in seq if _norm(t)])
                seq,_=_apply_stopwords(seq, stop_exact, stop_part_re, repl_map, aggressive, saved_whitelist)
                return seq, prefix

            titles=[]; used=set(); joiner=" "
            for primary in ranked_kws:
                primary=_norm(primary)
                if not primary: continue
                pk_list,_=_apply_stopwords([primary], stop_exact, stop_part_re, repl_map, aggressive, saved_whitelist)
                if not pk_list: continue
                primary=pk_list[0]
                seq, prefix = _base_seq(primary)
                title=(joiner.join(seq)).strip()
                expanded=title
                if auto_expand and len(expanded)<target_min:
                    for cand in ranked_kws:
                        cnd=_norm(cand)
                        if not cnd or cnd.lower()==primary.lower(): continue
                        cand_list,_=_apply_stopwords([cnd], stop_exact, stop_part_re, repl_map, aggressive, saved_whitelist)
                        if not cand_list: continue
                        cnd=cand_list[0]
                        if re.search(re.escape(cnd), expanded, flags=re.IGNORECASE): continue
                        if _would_overflow(expanded, cnd, max_len): continue
                        expanded=_norm(expanded+" "+cnd)
                        if len(expanded)>=target_min: break
                final=_smart_truncate(expanded, max_len, must_keep_prefix=prefix)
                key=final.lower()
                if key in used: continue
                used.add(key); titles.append(final)
                if len(titles)>=topn: break

            if naver_table is not None and not naver_table.empty:
                with st.expander("ğŸ“Š ì‚¬ìš©ëœ ë„¤ì´ë²„ ì§€í‘œ(ì •ë ¬ ê·¼ê±°)", expanded=False):
                    cols=["í‚¤ì›Œë“œ","PCì›”ê°„ê²€ìƒ‰ìˆ˜","Mobileì›”ê°„ê²€ìƒ‰ìˆ˜","ê´‘ê³ ê²½ìŸì •ë„","SEOì ìˆ˜"]
                    st.dataframe(naver_table[cols], use_container_width=True, height=260)

            if titles:
                st.success(f"ìƒì„± ì™„ë£Œ Â· {len(titles)}ê±´")
                for i, t in enumerate(titles, 1):
                    st.markdown(f"**{i}.** {t}")
                out_df=pd.DataFrame({"title":titles})
                st.download_button("CSV ë‹¤ìš´ë¡œë“œ", data=out_df.to_csv(index=False).encode("utf-8-sig"),
                                   file_name="titles_seo_stopwords.csv", mime="text/csv")
            else:
                st.warning("ìƒì„±ëœ ìƒí’ˆëª…ì´ ì—†ìŠµë‹ˆë‹¤. (ê¸ˆì¹™ì–´/ì¤‘ë³µ/ê¸¸ì´ ì œí•œ/ì…ë ¥ê°’ í™•ì¸)")

# =========================
# 10) ê¸°íƒ€ ì¹´ë“œ
# =========================
def _11st_abest_url():
    return ("https://m.11st.co.kr/page/main/abest?tabId=ABEST&pageId=AMOBEST&ctgr1No=166160&_ts=%d" % int(time.time()))
def section_11st():
    st.markdown('<div class="card"><div class="card-title">11ë²ˆê°€ (ëª¨ë°”ì¼) â€” ì•„ë§ˆì¡´ ë² ìŠ¤íŠ¸</div>', unsafe_allow_html=True)
    _proxy_iframe(ELEVENST_PROXY, _11st_abest_url(), height=900, scroll=True, key="abest")
    st.markdown('</div>', unsafe_allow_html=True)
def section_itemscout_placeholder():
    st.markdown('<div class="card"><div class="card-title">ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸</div>', unsafe_allow_html=True)
    st.info("ì„ë² ë“œ ë³´ë¥˜ ì¤‘ì…ë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ì›ë³¸ í˜ì´ì§€ë¥¼ ìƒˆ íƒ­ì—ì„œ ì—¬ì„¸ìš”.")
    st.link_button("ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ ì§ì ‘ ì—´ê¸°(ìƒˆ íƒ­)", "https://app.itemscout.io/market/keyword")
    st.markdown('</div>', unsafe_allow_html=True)
def section_sellerlife_placeholder():
    st.markdown('<div class="card"><div class="card-title">ì…€ëŸ¬ë¼ì´í”„</div>', unsafe_allow_html=True)
    st.info("ì„ë² ë“œ ë³´ë¥˜ ì¤‘ì…ë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ì›ë³¸ í˜ì´ì§€ë¥¼ ìƒˆ íƒ­ì—ì„œ ì—¬ì„¸ìš”.")
    st.link_button("ì§ì ‘ ì—´ê¸°(ìƒˆ íƒ­)", "https://sellochomes.co.kr/sellerlife/")
    st.markdown('</div>', unsafe_allow_html=True)

# =========================
# ì™¸ë¶€ Stopwords ì„¹ì…˜(ì„ íƒ) â€” ìœ ì§€í•´ë„ ë˜ê³ , ë ˆì´ì•„ì›ƒì—ì„œ í˜¸ì¶œ ì œê±°í•´ë„ ë¨
# =========================
def section_stopwords_manager():
    st.markdown('<div class="card"><div class="card-title">ê¸ˆì¹™ì–´ ë¦¬ìŠ¤íŠ¸ ê´€ë¦¬ì (í˜„ì—…ìš©)</div>', unsafe_allow_html=True)
    _stopwords_manager_ui(compact=False)

# =========================
# 11) Layout â€” row1: Radar | (ì¹´í…Œê³ ë¦¬ or ì§ì ‘ ì…ë ¥) | ìƒí’ˆëª… ìƒì„±ê¸°
# =========================
_ = _sidebar()
_responsive_probe()
vwbin = _get_view_bin()

st.title("ENVY â€” Season 1 (Dual Proxy Edition)")

# 1í–‰
row1_a, row1_b, row1_c = st.columns([8, 5, 3], gap="medium")
with row1_a:
    section_radar()
with row1_b:
    tab_cat, tab_direct = st.tabs(["ì¹´í…Œê³ ë¦¬", "ì§ì ‘ ì…ë ¥"])
    with tab_cat:
        section_category_keyword_lab()
    with tab_direct:
        section_keyword_trend_widget()
with row1_c:
    section_title_generator()

st.markdown('<div class="row-gap"></div>', unsafe_allow_html=True)

# 2í–‰
c1, c2, c3 = st.columns([3, 3, 3], gap="medium")
with c1:
    section_11st()
with c2:
    section_itemscout_placeholder()
with c3:
    section_sellerlife_placeholder()

st.markdown('<div class="row-gap"></div>', unsafe_allow_html=True)

# ì™¸ë¶€ ê¸ˆì¹™ì–´ ê´€ë¦¬ì(ì„ íƒ)
section_stopwords_manager()
