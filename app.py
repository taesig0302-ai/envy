# ===== Part 1 / 4 : Base, Theme, CSS, Helpers =====
import streamlit as st
import requests
import pandas as pd
import altair as alt
import datetime
import time as _t
import re
from bs4 import BeautifulSoup
import urllib.parse as _u

st.set_page_config(
    page_title="ENVY v27.8 Full (Rakuten API + DataLab)",
    layout="wide",
    initial_sidebar_state="expanded",
)
st.title("ğŸš€ ENVY v27.8 Full (Rakuten API + DataLab)")

# --- Theme toggle ---
if "theme" not in st.session_state:
    st.session_state["theme"] = "light"
theme_is_dark = st.sidebar.toggle(
    "ğŸŒ— ë‹¤í¬ ëª¨ë“œ", value=(st.session_state["theme"] == "dark"), key="__ui_theme_toggle"
)
st.session_state["theme"] = "dark" if theme_is_dark else "light"

PRIMARY = "#2563eb" if st.session_state["theme"] == "light" else "#60a5fa"
BG_PANEL = "#f8fafc" if st.session_state["theme"] == "light" else "#0b1220"
FG_TEXT = "#0f172a" if st.session_state["theme"] == "light" else "#e5e7eb"

# --- Global CSS (sidebar padding & KPI pills) ---
st.markdown(
    f"""
<style>
section[data-testid="stSidebar"] .block-container {{ padding-top: 6px !important; }}

.envy-box {{
  background:{BG_PANEL};
  border:1px solid rgba(100,100,100,0.12);
  border-radius:10px; padding:12px 14px; margin:6px 0;
}}
.envy-title {{ font-weight:700; color:{FG_TEXT}; margin-bottom:4px; }}
.envy-kpi {{ font-size:20px; font-weight:800; color:{PRIMARY}; }}
.envy-kpi-sub {{ font-size:12px; opacity:0.8; }}

/* result pill styles */
.pill {{ border-radius:10px; padding:10px 12px; font-weight:700; font-size:14px;
        margin:6px 0 2px 0; box-shadow:0 1px 0 rgba(0,0,0,0.02) inset; border:1px solid; }}
.pill small{{ font-weight:600; opacity:.9; }}
.pill.green  {{ background:#E6F4EA; color:#0F5132; border-color:#BADBCC; }}   /* ì—°ë‘: í™˜ìœ¨ */
.pill.blue   {{ background:#E7F1FE; color:#0B3D91; border-color:#B6D0FF; }}   /* í•˜ëŠ˜: íŒë§¤ê°€ */
.pill.yellow {{ background:#FFF4CC; color:#7A5D00; border-color:#FFE08A; }}   /* ë…¸ë‘: ë§ˆì§„ */
</style>
""",
    unsafe_allow_html=True,
)

def show_pill(label: str, value: str, tone: str = "green"):
    tone = tone if tone in ("green", "blue", "yellow") else "green"
    st.markdown(
        f"<div class='pill {tone}'>{label}: <small>{value}</small></div>",
        unsafe_allow_html=True,
    )

def fmt_krw(x: float) -> str:
    try:
        return f"â‚©{x:,.0f}"
    except Exception:
        return f"â‚©{x}"
# ===== Part 2 / 4 : Sidebar calculators =====
with st.sidebar:
    st.header("â‘  í™˜ìœ¨ ê³„ì‚°ê¸°")
    fx_ccy = st.selectbox("ê¸°ì¤€ í†µí™”", ["USD", "EUR", "JPY", "CNY"], index=0, key="sb_fx_base")
    # (ì„ì‹œ) ì‹¤ì‹œê°„ APIë¡œ ë°”ê¿€ ìˆ˜ ìˆìŒ
    _fx_map = {"USD": 1400.0, "EUR": 1500.0, "JPY": 9.0, "CNY": 190.0}
    fx_rate = _fx_map.get(fx_ccy, 1400.0)
    st.caption(f"ìë™ í™˜ìœ¨: 1 {fx_ccy} = {fx_rate:,.2f} â‚©")

    fx_price = st.number_input(
        f"íŒë§¤ê¸ˆì•¡ ({fx_ccy})", min_value=0.0, max_value=1e12, value=100.0, step=1.0,
        key="sb_fx_price_foreign",
    )
    fx_krw = fx_price * fx_rate
    show_pill("í™˜ì‚° ê¸ˆì•¡", fmt_krw(fx_krw), "green")  # ì—°ë‘ìƒ‰

    st.markdown("---")
    st.header("â‘¡ ë§ˆì§„ ê³„ì‚°ê¸° (v23)")
    m_ccy = st.selectbox("ê¸°ì¤€ í†µí™”(íŒë§¤ê¸ˆì•¡)", ["USD", "EUR", "JPY", "CNY"], index=0, key="sb_m_base")
    m_rate = _fx_map.get(m_ccy, 1400.0)
    st.caption(f"ìë™ í™˜ìœ¨: 1 {m_ccy} = {m_rate:,.2f} â‚©")

    m_sale_foreign = st.number_input(
        f"íŒë§¤ê¸ˆì•¡ ({m_ccy})", min_value=0.0, max_value=1e12, value=100.0, step=1.0,
        key="sb_m_sale_foreign",
    )
    m_sale_krw = m_sale_foreign * m_rate
    show_pill("íŒë§¤ê¸ˆì•¡(í™˜ì‚°)", fmt_krw(m_sale_krw), "blue")  # í•˜ëŠ˜ìƒ‰

    card = st.number_input("ì¹´ë“œìˆ˜ìˆ˜ë£Œ (%)", 0.0, 100.0, 4.0, 0.1, key="sb_card")
    market = st.number_input("ë§ˆì¼“ìˆ˜ìˆ˜ë£Œ (%)", 0.0, 100.0, 14.0, 0.1, key="sb_market")
    ship = st.number_input("ë°°ì†¡ë¹„ (â‚©)", 0.0, 1e10, 0.0, 100.0, key="sb_ship")
    mode = st.radio("ë§ˆì§„ ë°©ì‹", ["í¼ì„¼íŠ¸ ë§ˆì§„(%)", "ë”í•˜ê¸° ë§ˆì§„(â‚©)"], horizontal=True, key="sb_mode")

    # v23 ê³µì‹
    def _calc_percent(cost_krw, cf, mf, t, ship):
        denom = max(1e-9, 1 - cf - mf)
        target_rev = (cost_krw + ship) * (1 + t)
        P = target_rev / denom
        revenue = P * (1 - cf - mf)
        profit = revenue - (cost_krw + ship)
        return P, profit, (profit / P * 100 if P > 0 else 0.0)

    def _calc_add(cost_krw, cf, mf, add, ship):
        denom = max(1e-9, 1 - cf - mf)
        target_rev = (cost_krw + ship) + add
        P = target_rev / denom
        revenue = P * (1 - cf - mf)
        profit = revenue - (cost_krw + ship)
        return P, profit, (profit / P * 100 if P > 0 else 0.0)

    if mode == "í¼ì„¼íŠ¸ ë§ˆì§„(%)":
        margin_pct = st.number_input("ë§ˆì§„ìœ¨ (%)", 0.0, 500.0, 10.0, 0.1, key="sb_margin_pct")
        P, profit, on_sale = _calc_percent(m_sale_krw, card / 100.0, market / 100.0, margin_pct / 100.0, ship)
    else:
        add_margin = st.number_input("ë”í•˜ê¸° ë§ˆì§„ (â‚©)", 0.0, 1e12, 10000.0, 100.0, key="sb_add_margin")
        P, profit, on_sale = _calc_add(m_sale_krw, card / 100.0, market / 100.0, add_margin, ship)

    show_pill("ì˜ˆìƒ íŒë§¤ê°€", fmt_krw(P), "blue")       # í•˜ëŠ˜ìƒ‰
    show_pill("ìˆœì´ìµ(ë§ˆì§„)", fmt_krw(profit), "yellow")  # ë…¸ë‘
# ===== Part 3 / 4 : Data sources + fetchers =====

COMMON_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124 Safari/537.36",
    "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
}

NAVER_CATEGORIES = {
    "íŒ¨ì…˜ì˜ë¥˜": "50000000", "íŒ¨ì…˜ì¡í™”": "50000001", "í™”ì¥í’ˆ/ë¯¸ìš©": "50000002",
    "ë””ì§€í„¸/ê°€ì „": "50000003", "ê°€êµ¬/ì¸í…Œë¦¬ì–´": "50000004", "ì‹í’ˆ": "50000005",
    "ìƒí™œ/ê±´ê°•": "50000006", "ì¶œì‚°/ìœ¡ì•„": "50000007", "ìŠ¤í¬ì¸ /ë ˆì €": "50000008",
    "ë„ì„œ/ì·¨ë¯¸/ì• ì™„": "50000009",
}

def _retry_post(url, headers=None, data=None, timeout=12, tries=4):
    last = None
    for i in range(tries):
        try:
            r = requests.post(url, headers=headers, data=data, timeout=timeout)
            if r.status_code in (200, 201):
                return r
            if r.status_code in (403, 429):
                _t.sleep(1.2 * (2 ** i))
                continue
            last = r
        except Exception as e:
            last = e
    raise RuntimeError(f"POST ì‹¤íŒ¨: {last}")

def _retry_get(url, headers=None, timeout=12, tries=4):
    last = None
    for i in range(tries):
        try:
            r = requests.get(url, headers=headers, timeout=timeout)
            if r.status_code in (200, 201):
                return r
            if r.status_code in (403, 429):
                _t.sleep(1.2 * (2 ** i))
                continue
            last = r
        except Exception as e:
            last = e
    raise RuntimeError(f"GET ì‹¤íŒ¨: {last}")

def fetch_datalab_top20(cid: str, start_date: str, end_date: str, proxy: str | None = None) -> pd.DataFrame:
    # end_date â†’ ì–´ì œë¡œ ë³´ì •(ê¸ˆì¼ ì§‘ê³„ ë¯¸ì™„ ë°©ì§€)
    try:
        end = datetime.datetime.strptime(end_date, "%Y-%m-%d").date()
    except Exception:
        end = datetime.date.today()
    yesterday = (end - datetime.timedelta(days=1)).strftime("%Y-%m-%d")

    s = requests.Session()
    entry = "https://datalab.naver.com/shoppingInsight/sCategory.naver"
    s.get(entry, headers={**COMMON_HEADERS, "Accept": "text/html,*/*"}, timeout=10)

    api = "https://datalab.naver.com/shoppingInsight/getCategoryKeywordRank.naver"
    if proxy:
        api = f"{proxy}?target=" + _u.quote(api, safe="")

    headers = {
        **COMMON_HEADERS,
        "Accept": "application/json, text/javascript, */*; q=0.01",
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "Origin": "https://datalab.naver.com",
        "Referer": entry,
        "X-Requested-With": "XMLHttpRequest",
        "Sec-Fetch-Site": "same-origin", "Sec-Fetch-Mode": "cors", "Sec-Fetch-Dest": "empty",
    }
    payload = {
        "cid": cid, "timeUnit": "date", "startDate": start_date, "endDate": yesterday,
        "device": "pc", "gender": "", "ages": "",
    }

    r = _retry_post(api, headers=headers, data=payload, timeout=12, tries=4)
    txt = (r.text or "").strip()
    if not txt or not (txt.startswith("{") or txt.startswith("[")):
        raise RuntimeError("DataLab JSON ì•„ë‹˜(ì°¨ë‹¨/êµ¬ì¡°ë³€ê²½ ê°€ëŠ¥ì„±)")

    data = r.json()
    items = data.get("keywordList", [])
    if not isinstance(items, list) or not items:
        raise RuntimeError("DataLab ë°ì´í„° ì—†ìŒ(ê¸°ê°„/ì¹´í…Œê³ ë¦¬/ì°¨ë‹¨ í™•ì¸)")

    rows = []
    for it in items[:20]:
        rows.append({
            "rank": it.get("rank") or len(rows) + 1,
            "keyword": it.get("keyword", ""),
            "search": it.get("ratio") or 0,
        })
    return pd.DataFrame(rows).sort_values("rank").reset_index(drop=True)

def fetch_amazon_bestsellers(limit: int = 15, proxy: str | None = None) -> pd.DataFrame:
    url = "https://www.amazon.com/Best-Sellers/zgbs"
    if proxy:
        url = f"{proxy}?target=" + _u.quote(url, safe="")
    headers = {**COMMON_HEADERS, "Referer": "https://www.amazon.com/"}
    r = _retry_get(url, headers=headers, timeout=12, tries=4)

    soup = BeautifulSoup(r.text, "html.parser")
    titles = []
    selectors = [
        "div.p13n-sc-truncate",
        "div._cDEzb_p13n-sc-css-line-clamp-3_g3dy1",
        "div._cDEzb_p13n-sc-css-line-clamp-2_EWgCb",
        "div.a-section.a-spacing-small > h3, div.a-section.a-spacing-small > a > span",
        "span.zg-text-center-align > div > a > div",
    ]
    for sel in selectors:
        for el in soup.select(sel):
            t = re.sub(r"\s+", " ", el.get_text(strip=True))
            if t and t not in titles:
                titles.append(t)
            if len(titles) >= limit:
                break
        if len(titles) >= limit:
            break
    if not titles:
        raise RuntimeError("Amazon íŒŒì‹± ì‹¤íŒ¨(êµ¬ì¡°ë³€ê²½/ì°¨ë‹¨ ê°€ëŠ¥)")

    df = pd.DataFrame({"rank": range(1, len(titles) + 1), "keyword": titles[:limit]})
    df["score"] = [300 - i for i in range(1, len(df) + 1)]
    df["source"] = "Amazon US"
    return df[["source", "rank", "keyword", "score"]]

# Rakuten AppID (ìƒìš©)
RAKUTEN_APP_ID = "1043271015809337425"

def fetch_rakuten_ranking_api(app_id: str, genre_id: str | None = None,
                              period: str = "day", limit: int = 15) -> pd.DataFrame:
    url = "https://app.rakuten.co.jp/services/api/IchibaItem/Ranking/20170628"
    params = {"applicationId": app_id, "format": "json", "periodType": period}
    if genre_id:
        params["genreId"] = genre_id
    r = requests.get(url, params=params, timeout=12)
    if r.status_code != 200:
        raise RuntimeError(f"Rakuten API ì˜¤ë¥˜: {r.status_code} / {r.text[:120]}")
    js = r.json()
    items = js.get("Items", [])
    rows = []
    for it in items[:limit]:
        I = it.get("Item", {})
        rows.append({
            "rank": I.get("rank"),
            "keyword": I.get("itemName"),
            "score": 220 - (I.get("rank") or len(rows) + 1),
        })
    if not rows:
        raise RuntimeError("Rakuten API ì‘ë‹µì— í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    df = pd.DataFrame(rows)
    df["source"] = "Rakuten JP"
    return df[["source", "rank", "keyword", "score"]]
# ===== Part 4 / 4 : Fixed UI Layout (2 rows Ã— 3 columns) =====

# 1í–‰: ë°ì´í„°ë© / ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ / ì…€ëŸ¬ë¼ì´í”„
c1, c2, c3 = st.columns(3)

with c1:
    st.subheader("ë°ì´í„°ë©")
    sel_cat = st.selectbox("ì¹´í…Œê³ ë¦¬", list(NAVER_CATEGORIES.keys()), index=0, key="dl_cat")
    cid = NAVER_CATEGORIES[sel_cat]
    dl_proxy = st.text_input("í”„ë¡ì‹œ(ì„ íƒ)", "", key="dl_proxy",
                             placeholder="https://your-proxy/app?target=<url>")

    today = datetime.date.today()
    start = (today - datetime.timedelta(days=30)).strftime("%Y-%m-%d")
    end = today.strftime("%Y-%m-%d")  # í•¨ìˆ˜ì—ì„œ ì–´ì œë¡œ ë³´ì •

    try:
        df_dl = fetch_datalab_top20(cid, start, end, proxy=(dl_proxy or None))
        st.dataframe(df_dl, use_container_width=True, height=280)

        chart = alt.Chart(df_dl).mark_line(point=True).encode(
            x=alt.X("rank:Q", title="ë­í¬(1=ìƒìœ„)"),
            y=alt.Y("search:Q", title="ê²€ìƒ‰ëŸ‰(ì§€ìˆ˜)"),
            tooltip=["rank", "keyword", "search"],
        ).properties(height=180)
        st.altair_chart(chart, use_container_width=True)

        st.download_button("Top20 CSV ë‹¤ìš´ë¡œë“œ",
                           df_dl.to_csv(index=False).encode("utf-8-sig"),
                           "datalab_top20.csv", mime="text/csv", key="dl_csv")
        st.session_state["datalab_df"] = df_dl.copy()
    except Exception as e:
        st.error(f"ë°ì´í„°ë© ì˜¤ë¥˜: {e}")
        st.caption("â€¢ í”„ë¡ì‹œë¥¼ ë„£ì–´ ì¬ì‹œë„í•´ë³´ì„¸ìš”. â€¢ ì‚¬ë¬´ì‹¤/í´ë¼ìš°ë“œë§ì€ 403 ì°¨ë‹¨ë  ìˆ˜ ìˆì–´ìš”.")

with c2:
    st.subheader("ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸")
    st.info("ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ ì—°ë™ ëŒ€ê¸°(ë³„ë„ API/í”„ë¡ì‹œ ì—°ê²° ì˜ˆì •)")

with c3:
    st.subheader("ì…€ëŸ¬ë¼ì´í”„")
    st.info("ì…€ëŸ¬ë¼ì´í”„ ì—°ë™ ëŒ€ê¸°(ë³„ë„ API/í”„ë¡ì‹œ ì—°ê²° ì˜ˆì •)")

# 2í–‰: AI ë ˆì´ë” / 11ë²ˆê°€ / ìƒí’ˆëª… ìƒì„±ê¸°
d1, d2, d3 = st.columns(3)

with d1:
    st.subheader("AI í‚¤ì›Œë“œ ë ˆì´ë” (êµ­ë‚´/ê¸€ë¡œë²Œ)")
    mode = st.radio("ëª¨ë“œ", ["êµ­ë‚´", "ê¸€ë¡œë²Œ"], horizontal=True, key="air_mode")
    if mode == "êµ­ë‚´":
        src = st.session_state.get("datalab_df")
        if src is not None and len(src):
            radar = (
                src.assign(source="DataLab", score=lambda x: 1000 - x["rank"] * 10)
                [["source", "keyword", "score", "rank"]]
                .sort_values(["score", "rank"], ascending=[False, True])
            )
            st.dataframe(radar, use_container_width=True, height=420)
            st.download_button("êµ­ë‚´ í‚¤ì›Œë“œ CSV",
                               radar.to_csv(index=False).encode("utf-8-sig"),
                               "radar_domestic.csv", mime="text/csv", key="air_csv_dom")
        else:
            st.info("ë°ì´í„°ë© ê²°ê³¼ê°€ ì—†ì–´ í‘œì‹œí•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        amz_proxy = st.text_input("Amazon í”„ë¡ì‹œ(ì„ íƒ)", "", key="amz_proxy",
                                  placeholder="https://your-proxy/app?target=<url>")
        rak_genre = st.text_input("Rakuten genreId (ì„ íƒ, ë¹„ìš°ë©´ ì¢…í•©)", "", key="rak_genre")

        try:
            df_amz = fetch_amazon_bestsellers(15, proxy=(amz_proxy or None))
        except Exception as e:
            st.error(f"Amazon ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            df_amz = pd.DataFrame(columns=["source", "rank", "keyword", "score"])

        try:
            df_rak = fetch_rakuten_ranking_api(RAKUTEN_APP_ID,
                                               genre_id=(rak_genre or None),
                                               period="day", limit=15)
        except Exception as e:
            st.error(f"Rakuten API ì‹¤íŒ¨: {e}")
            df_rak = pd.DataFrame(columns=["source", "rank", "keyword", "score"])

        df_glb = pd.concat([df_amz, df_rak], ignore_index=True)
        if len(df_glb):
            df_glb = df_glb.sort_values(["score", "rank"], ascending=[False, True])
            st.dataframe(df_glb, use_container_width=True, height=420)
            st.download_button("ê¸€ë¡œë²Œ í‚¤ì›Œë“œ CSV",
                               df_glb.to_csv(index=False).encode("utf-8-sig"),
                               "radar_global.csv", mime="text/csv", key="air_csv_glb")
        else:
            st.info("ê¸€ë¡œë²Œ ì†ŒìŠ¤ ìˆ˜ì§‘ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

with d2:
    st.subheader("11ë²ˆê°€ (ëª¨ë°”ì¼ í”„ë¡ì‹œ + ìš”ì•½í‘œ)")
    url_11 = st.text_input("ëŒ€ìƒ URL", "https://www.11st.co.kr/", key="url_11")
    proxy_11 = st.text_input("í”„ë¡ì‹œ ì—”ë“œí¬ì¸íŠ¸(ì„ íƒ)", "", key="proxy_11")
    html11 = ""
    try:
        if proxy_11:
            tgt = f"{proxy_11}?target=" + _u.quote(url_11, safe="")
            r = requests.get(tgt, headers=COMMON_HEADERS, timeout=10)
        else:
            r = requests.get(url_11, headers=COMMON_HEADERS, timeout=10)
        if r.status_code == 200:
            html11 = r.text
        else:
            st.error(f"11ë²ˆê°€ ì‘ë‹µ ì˜¤ë¥˜: {r.status_code}")
    except Exception as e:
        st.error(f"11ë²ˆê°€ ìš”ì²­ ì‹¤íŒ¨: {e}")

    if html11:
        st.components.v1.html(
            f"<iframe srcdoc='{html11}' width='100%' height='400'></iframe>",
            height=420, scrolling=True
        )

    with st.expander("ì„ë² ë“œ ì‹¤íŒ¨ ëŒ€ë¹„ ìš”ì•½í‘œ ë³´ê¸°"):
        df_11 = pd.DataFrame({
            "title": [f"ìƒí’ˆ{i}" for i in range(1, 6)],
            "price": [i * 1000 for i in range(1, 6)],
            "sales": [i * 7 for i in range(1, 6)],
            "link": [url_11] * 5,
        })
        st.dataframe(df_11, use_container_width=True)
        st.download_button("CSV ë‹¤ìš´ë¡œë“œ",
                           df_11.to_csv(index=False).encode("utf-8-sig"),
                           "11st_list.csv", mime="text/csv", key="m11_csv")

with d3:
    st.subheader("ìƒí’ˆëª… ìƒì„±ê¸° (ê·œì¹™ + HuggingFace KoGPT2)")
    brand = st.text_input("ë¸Œëœë“œ", "envy")
    base_kw = st.text_input("ë² ì´ìŠ¤ í‚¤ì›Œë“œ", "K-coffee mix")
    rel_kw = st.text_input("ì—°ê´€í‚¤ì›Œë“œ", "Maxim, Kanu, Korea")
    ban_kw = st.text_input("ê¸ˆì¹™ì–´", "copy, fake, replica")
    limit_len = st.slider("ê¸€ììˆ˜ ì œí•œ", 10, 120, 80)
    mode_gen = st.radio("ëª¨ë“œ", ["ê·œì¹™ ê¸°ë°˜", "HuggingFace AI"], horizontal=True, key="gen_mode")

    if st.button("ìƒì„±", key="gen_go"):
        if mode_gen == "ê·œì¹™ ê¸°ë°˜":
            out = f\"{brand} {base_kw} {rel_kw}\".replace(",", " ")
            for w in ban_kw.split(","):
                out = out.replace(w.strip(), "")
            st.success(out[:limit_len])
        else:
            # HuggingFace í‚¤ëŠ” st.secrets['HF_API_KEY']ë¡œ ê´€ë¦¬ ê¶Œì¥
            HF_KEY = st.secrets.get("HF_API_KEY", "")
            if not HF_KEY:
                st.error("HuggingFace API Keyê°€ ì—†ìŠµë‹ˆë‹¤. st.secrets['HF_API_KEY']ì— ì„¤ì •í•˜ì„¸ìš”.")
            else:
                headers = {"Authorization": f"Bearer {HF_KEY}", "Content-Type": "application/json"}
                payload = {"inputs": f"{brand} {base_kw} {rel_kw}",
                           "parameters": {"max_new_tokens": 32, "return_full_text": False}}
                try:
                    r = requests.post(
                        "https://api-inference.huggingface.co/models/skt/kogpt2-base-v2",
                        headers=headers, json=payload, timeout=20
                    )
                    if r.status_code == 200:
                        js = r.json()
                        text = js[0].get("generated_text", "") if isinstance(js, list) and js else str(js)
                        for w in ban_kw.split(","):
                            text = text.replace(w.strip(), "")
                        st.success(text[:limit_len])
                    else:
                        st.error(f"HuggingFace API ì˜¤ë¥˜: {r.status_code} {r.text[:160]}")
                except Exception as e:
                    st.error(f"HuggingFace í˜¸ì¶œ ì‹¤íŒ¨: {e}")
