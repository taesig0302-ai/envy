# =========================================================
# ENVY â€” Season 1 (One-Page) Â· app.py  (2025-09-20 merge)
#  - ì‚¬ì´ë“œë°”(ê³ ì •, í™˜ìœ¨/ë§ˆì§„ ê³„ì‚°ê¸° ë³€ê²½ ê¸ˆì§€)
#  - ë°ì´í„°ë©: ì›ë³¸ ì„ë² ë“œ(ê¸°ë³¸) + ë¶„ì„(ë³´ì¡°)
#  - 11ë²ˆê°€/ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸/ì…€ëŸ¬ë¼ì´í”„: í”„ë¡ì‹œ ì„ë² ë“œ (Cloudflare Worker ?url=)
#  - AI í‚¤ì›Œë“œ ë ˆì´ë”(Rakuten): [ì‹¤ë°ì´í„° ìš°ì„  + ìŠ¤í¬ë¡¤/ì—¬ë°±/URL ì¶•ì†Œ] â† ìµœì‹  Part 5 ë°˜ì˜
#  - êµ¬ê¸€ ë²ˆì—­: ê°™ì€ ì¤„ ë°°ì¹˜ + í•œêµ­ì–´ í™•ì¸ ê·œì¹™
#  - ìƒí’ˆëª… ìƒì„±ê¸°(ê·œì¹™ ê¸°ë°˜): ìƒˆ ì„¹ì…˜ ì¶”ê°€
#  - PROXY_URLì€ ì‚¬ì´ë“œë°” í•˜ë‹¨ ì…ë ¥(Cloudflare Worker v2 ?url= ë°©ì‹)
#  - ë¯¼ê°ê°’(ì¿ í‚¤/í‚¤)ì€ .streamlit/secrets.tomlë¡œ ë¶„ë¦¬
#  - ê¸°ë³¸ PROXY_URL ì˜ˆì‹œ: https://envy-proxy.taesig0302.workers.dev/
#  - Naver DataLab ì£¼ìš” ì—”ë“œí¬ì¸íŠ¸:
#       /shoppingInsight/getCategoryKeywordRank.naver
#       /shoppingInsight/getKeywordClickTrend.naver (ë˜ëŠ” getKeywordTrends.naver)
# =========================================================

import os, base64, json, re, time
from pathlib import Path
from datetime import date, timedelta
from typing import List, Dict, Any

import streamlit as st
import pandas as pd
import numpy as np

# requests / deep_translatorëŠ” requirements.txtì— ëª…ì‹œ
try:
    import requests
except Exception:
    requests = None
try:
    from deep_translator import GoogleTranslator
except Exception:
    GoogleTranslator = None

# -----------------------------
# Part 1 â€” ì‚¬ì´ë“œë°” (ìˆ˜ì • ê¸ˆì§€ ì˜ì—­ ìœ ì§€)
# -----------------------------
CURRENCIES = {
    "USD": {"kr": "ë¯¸êµ­ ë‹¬ëŸ¬", "symbol": "$", "unit": "USD"},
    "EUR": {"kr": "ìœ ë¡œ",     "symbol": "â‚¬", "unit": "EUR"},
    "JPY": {"kr": "ì¼ë³¸ ì—”",   "symbol": "Â¥", "unit": "JPY"},
    "CNY": {"kr": "ì¤‘êµ­ ìœ„ì•ˆ", "symbol": "å…ƒ","unit": "CNY"},
}
FX_DEFAULT = {"USD": 1400.0, "EUR": 1500.0, "JPY": 10.0, "CNY": 200.0}

def _ensure_session_defaults():
    ss = st.session_state
    ss.setdefault("theme", "light")
    ss.setdefault("PROXY_URL", "")
    ss.setdefault("fx_base", "USD")
    ss.setdefault("sale_foreign", 1.00)
    ss.setdefault("m_base", "USD")
    ss.setdefault("purchase_foreign", 0.00)
    ss.setdefault("card_fee_pct", 4.00)
    ss.setdefault("market_fee_pct", 14.00)
    ss.setdefault("shipping_won", 0.0)
    ss.setdefault("margin_mode", "í¼ì„¼íŠ¸")
    ss.setdefault("margin_pct", 10.00)
    ss.setdefault("margin_won", 10000.0)

def _toggle_theme():
    st.session_state["theme"] = "dark" if st.session_state.get("theme","light")=="light" else "light"

def _inject_sidebar_css():
    theme = st.session_state.get("theme","light")
    bg, fg = ("#0e1117", "#e6edf3") if theme=="dark" else ("#ffffff","#111111")
    st.markdown(f"""
    <style>
      html, body, [data-testid="stAppViewContainer"] {{
        background-color:{bg} !important; color:{fg} !important;
      }}
      .block-container {{ padding-top:.8rem !important; padding-bottom:.35rem !important; }}

      /* ì‚¬ì´ë“œë°” ê³ ì •(lock) â€” ì›ë³¸ ìœ ì§€í•˜ë˜, ì•„ë˜ Part 7ì—ì„œ ì˜¤ë²„ë¼ì´ë“œë¡œ ë‚´ë¶€ ìŠ¤í¬ë¡¤ í—ˆìš© */
      [data-testid="stSidebar"],
      [data-testid="stSidebar"] > div:first-child,
      [data-testid="stSidebar"] section {{
        height: 100vh !important; overflow: hidden !important;
        padding-top:.25rem !important; padding-bottom:.25rem !important;
      }}
      [data-testid="stSidebar"] ::-webkit-scrollbar {{ display:none !important; }}

      [data-testid="stSidebar"] .stSelectbox,
      [data-testid="stSidebar"] .stNumberInput,
      [data-testid="stSidebar"] .stRadio,
      [data-testid="stSidebar"] .stMarkdown,
      [data-testid="stSidebar"] .stTextInput,
      [data-testid="stSidebar"] .stButton {{ margin:.14rem 0 !important; }}

      [data-baseweb="input"] input,
      .stNumberInput input,
      [data-baseweb="select"] div[role="combobox"] {{
        height:1.55rem !important; padding:.12rem !important; font-size:.92rem !important;
      }}

      .logo-circle {{
        width:95px; height:95px; border-radius:50%; overflow:hidden;
        margin:.15rem auto .35rem auto; box-shadow:0 2px 8px rgba(0,0,0,.12);
        border:1px solid rgba(0,0,0,.06);
      }}
      .logo-circle img {{ width:100%; height:100%; object-fit:cover; }}

      .badge-green  {{ background:#e6ffcc; border:1px solid #b6f3a4; padding:6px 10px; border-radius:6px; color:#0b2e13; font-size:.86rem; }}
      .badge-blue   {{ background:#eef4ff; border:1px solid #bcd0ff; padding:6px 10px; border-radius:6px; color:#0a235a; font-size:.86rem; }}
      .badge-yellow {{ background:#fff7d6; border:1px solid #f1d27a; padding:6px 10px; border-radius:6px; color:#4a3b07; font-size:.86rem; }}
      .muted        {{ opacity:.8; font-size:.8rem; }}
      .info-box {{ background:rgba(0,0,0,.03); border:1px dashed rgba(0,0,0,.08); padding:.6rem; border-radius:.5rem; }}
    </style>
    """, unsafe_allow_html=True)

def render_sidebar() -> dict:
    _ensure_session_defaults()
    _inject_sidebar_css()

    result = {}
    with st.sidebar:
        lp = Path(__file__).parent / "logo.png"
        if lp.exists():
            b64 = base64.b64encode(lp.read_bytes()).decode("ascii")
            st.markdown(f'<div class="logo-circle"><img src="data:image/png;base64,{b64}"></div>', unsafe_allow_html=True)
        else:
            st.caption("logo.png ë¥¼ ì•± íŒŒì¼ê³¼ ê°™ì€ í´ë”ì— ë‘ë©´ ë¡œê³ ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

        st.toggle("ğŸŒ“ ë‹¤í¬ ëª¨ë“œ", value=(st.session_state.get("theme","light")=="dark"), on_change=_toggle_theme, key="__theme_toggle")

        # â‘  í™˜ìœ¨ ê³„ì‚°ê¸°
        st.markdown("### â‘  í™˜ìœ¨ ê³„ì‚°ê¸°")
        base = st.selectbox("ê¸°ì¤€ í†µí™”", list(CURRENCIES.keys()),
                            index=list(CURRENCIES.keys()).index(st.session_state["fx_base"]),
                            key="fx_base")
        sale_foreign = st.number_input("íŒë§¤ê¸ˆì•¡ (ì™¸í™”)", value=float(st.session_state["sale_foreign"]), step=0.01, format="%.2f", key="sale_foreign")
        won = FX_DEFAULT[base] * sale_foreign
        st.markdown(
            f'<div class="badge-green">í™˜ì‚° ê¸ˆì•¡: <b>{won:,.2f} ì›</b> '
            f'<span class="muted">({CURRENCIES[base]["kr"]} â€¢ {CURRENCIES[base]["symbol"]})</span></div>',
            unsafe_allow_html=True
        )
        st.caption(f"í™˜ìœ¨ ê¸°ì¤€: {FX_DEFAULT[base]:,.2f} â‚©/{CURRENCIES[base]['unit']}")

        # â‘¡ ë§ˆì§„ ê³„ì‚°ê¸°
        st.markdown("### â‘¡ ë§ˆì§„ ê³„ì‚°ê¸°")
        m_base = st.selectbox("ë§¤ì… í†µí™”", list(CURRENCIES.keys()),
                              index=list(CURRENCRIES.keys()).index(st.session_state["m_base"]) if 'CURRENCRIES' in globals() else list(CURRENCIES.keys()).index(st.session_state["m_base"]),
                              key="m_base")
        purchase_foreign = st.number_input("ë§¤ì…ê¸ˆì•¡ (ì™¸í™”)", value=float(st.session_state["purchase_foreign"]), step=0.01, format="%.2f", key="purchase_foreign")
        base_cost_won = FX_DEFAULT[m_base] * purchase_foreign if purchase_foreign>0 else won
        st.markdown(f'<div class="badge-green">ì›ê°€(â‚©): <b>{base_cost_won:,.2f} ì›</b></div>', unsafe_allow_html=True)

        colf1, colf2 = st.columns(2)
        with colf1:
            card_fee = st.number_input("ì¹´ë“œìˆ˜ìˆ˜ë£Œ(%)", value=float(st.session_state["card_fee_pct"]), step=0.01, format="%.2f", key="card_fee_pct")
        with colf2:
            market_fee = st.number_input("ë§ˆì¼“ìˆ˜ìˆ˜ë£Œ(%)", value=float(st.session_state["market_fee_pct"]), step=0.01, format="%.2f", key="market_fee_pct")
        shipping_won = st.number_input("ë°°ì†¡ë¹„(â‚©)", value=float(st.session_state["shipping_won"]), step=100.0, format="%.0f", key="shipping_won")

        mode = st.radio("ë§ˆì§„ ë°©ì‹", ["í¼ì„¼íŠ¸","í”ŒëŸ¬ìŠ¤"], horizontal=True, key="margin_mode")
        if mode == "í¼ì„¼íŠ¸":
            margin_pct = st.number_input("ë§ˆì§„ìœ¨ (%)", value=float(st.session_state["margin_pct"]), step=0.01, format="%.2f", key="margin_pct")
            target_price = base_cost_won * (1 + card_fee/100) * (1 + market_fee/100) * (1 + margin_pct/100) + shipping_won
            margin_value = target_price - base_cost_won
            margin_desc = f"{margin_pct:.2f}%"
        else:
            margin_won = st.number_input("ë§ˆì§„ì•¡ (â‚©)", value=float(st.session_state["margin_won"]), step=100.0, format="%.0f", key="margin_won")
            target_price = base_cost_won * (1 + card_fee/100) * (1 + market_fee/100) + margin_won + shipping_won
            margin_value = margin_won
            margin_desc = f"+{margin_won:,.0f}"

        st.markdown(f'<div class="badge-blue">íŒë§¤ê°€: <b>{target_price:,.2f} ì›</b></div>', unsafe_allow_html=True)
        st.markdown(f'<div class="badge-yellow">ìˆœì´ìµ(ë§ˆì§„): <b>{margin_value:,.2f} ì›</b> â€” {margin_desc}</div>', unsafe_allow_html=True)

        st.divider()
        st.markdown("##### í”„ë¡ì‹œ/í™˜ê²½")
        st.text_input("PROXY_URL (Cloudflare Worker ë“±)", value=st.session_state.get("PROXY_URL",""), key="PROXY_URL", help="ì˜ˆ: https://envy-proxy.taesig0302.workers.dev/")
        st.markdown("""
            <div class="info-box">
              <b>ENVY</b> ì‚¬ì´ë“œë°” ì •ë³´ëŠ” ê³ ì •ì…ë‹ˆë‹¤.<br/>
              Â· ë¡œê³ /í™˜ìœ¨/ë§ˆì§„ ê³„ì‚°ê¸°: ë³€ê²½ ê¸ˆì§€<br/>
              Â· PROXY_URL: 11ë²ˆê°€/ë°ì´í„°ë©/ì„ë² ë“œìš©(í•„ìš”ì‹œ)<br/>
              Â· ë‹¤í¬/ë¼ì´íŠ¸ ëª¨ë“œëŠ” ìƒë‹¨ í† ê¸€
            </div>
        """, unsafe_allow_html=True)

    result.update({
        "fx_base": base,
        "sale_foreign": sale_foreign,
        "converted_won": won,
        "purchase_base": m_base,
        "purchase_foreign": purchase_foreign,
        "base_cost_won": base_cost_won,
        "card_fee_pct": card_fee,
        "market_fee_pct": market_fee,
        "shipping_won": shipping_won,
        "margin_mode": mode,
        "target_price": target_price,
        "margin_value": margin_value,
    })
    return result

# -----------------------------
# Part 2 â€” ê³µìš© ìœ í‹¸
# -----------------------------
LANG_LABELS = {
    "auto":"ìë™ ê°ì§€",
    "ko":"í•œêµ­ì–´","en":"ì˜ì–´","ja":"ì¼ë³¸ì–´",
    "zh-CN":"ì¤‘êµ­ì–´(ê°„ì²´)","zh-TW":"ì¤‘êµ­ì–´(ë²ˆì²´)",
    "vi":"ë² íŠ¸ë‚¨ì–´","th":"íƒœêµ­ì–´","id":"ì¸ë„ë„¤ì‹œì•„ì–´",
    "de":"ë…ì¼ì–´","fr":"í”„ë‘ìŠ¤ì–´","es":"ìŠ¤í˜ì¸ì–´","it":"ì´íƒˆë¦¬ì•„ì–´","pt":"í¬ë¥´íˆ¬ê°ˆì–´",
}
def lang_label_to_code(label_or_code:str) -> str:
    rev = {v:k for k,v in LANG_LABELS.items()}
    return rev.get(label_or_code, label_or_code)

def toast_ok(msg:str): st.toast(f"âœ… {msg}")
def toast_warn(msg:str): st.toast(f"âš ï¸ {msg}")
def toast_err(msg:str): st.toast(f"âŒ {msg}")

# -----------------------------
# Part 3 â€” ë°ì´í„°ë©(ë¶„ì„ ë³´ì¡°) v3
# -----------------------------
from collections import defaultdict

DATALAB_CATS = [
    'íŒ¨ì…˜ì˜ë¥˜','íŒ¨ì…˜ì¡í™”','í™”ì¥í’ˆ/ë¯¸ìš©','ë””ì§€í„¸/ê°€ì „','ê°€êµ¬/ì¸í…Œë¦¬ì–´',
    'ì¶œì‚°/ìœ¡ì•„','ì‹í’ˆ','ìŠ¤í¬ì¸ /ë ˆì €','ìƒí™œ/ê±´ê°•','ì—¬ê°€/ìƒí™œí¸ì˜','ë©´ì„¸ì ','ë„ì„œ'
]
CID_MAP = {
    'íŒ¨ì…˜ì˜ë¥˜':'50000000','íŒ¨ì…˜ì¡í™”':'50000001','í™”ì¥í’ˆ/ë¯¸ìš©':'50000002','ë””ì§€í„¸/ê°€ì „':'50000003',
    'ê°€êµ¬/ì¸í…Œë¦¬ì–´':'50000004','ì¶œì‚°/ìœ¡ì•„':'50000005','ì‹í’ˆ':'50000006','ìŠ¤í¬ì¸ /ë ˆì €':'50000007',
    'ìƒí™œ/ê±´ê°•':'50000008','ì—¬ê°€/ìƒí™œí¸ì˜':'50000009','ë©´ì„¸ì ':'50000010','ë„ì„œ':'50005542',
}

def _naver_cookie() -> str:
    # secrets â†’ env â†’ session ìˆœ
    try:
        v = st.secrets.get('NAVER_COOKIE', '')
    except Exception:
        v = ''
    if v: return v.strip()
    env = os.getenv('NAVER_COOKIE', '').strip()
    if env: return env
    return st.session_state.get('__NAVER_COOKIE', '').strip()

def _hdr(cookie: str, cid: str, time_unit: str='week', device: str='all', as_json: bool=True) -> dict:
    h = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124 Safari/537.36",
        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
        "Origin": "https://datalab.naver.com",
        "Referer": f"https://datalab.naver.com/shoppingInsight/sCategory.naver?cid={cid}&timeUnit={time_unit}&device={device}",
        "Cookie": cookie.strip(),
    }
    if as_json:
        h["Accept"] = "application/json, text/plain, */*"
        h["Content-Type"] = "application/x-www-form-urlencoded; charset=UTF-8"
        h["X-Requested-With"] = "XMLHttpRequest"
    else:
        h["Accept"] = "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
    return h

def _to_float(v) -> float:
    if v is None: return 0.0
    if isinstance(v, (int,float)): return float(v)
    s = str(v).replace(',', '')
    m = re.search(r'-?\d+(?:\.\d+)?', s)
    return float(m.group(0)) if m else 0.0

def _normalize_top20(obj: Any) -> List[dict]:
    rows: List[dict] = []
    if isinstance(obj, dict) and isinstance(obj.get("ranks"), list):
        for i, d in enumerate(obj["ranks"], 1):
            kw = (d.get("keyword") or d.get("relKeyword") or "").strip()
            sc = None
            for k in ("ratio","ratioValue","value","score","count","ratioIndex"):
                if k in d:
                    sc = _to_float(d.get(k)); break
            if kw:
                rows.append({"rank": i, "keyword": kw, "score": 0.0 if sc is None else sc})

    def consider(d: dict):
        kw = (d.get('keyword') or d.get('relKeyword') or d.get('name') or d.get('key') or '').strip()
        sc = None
        for k in ('ratio','ratioValue','ratioIndex','value','score','count'):
            if k in d: sc = _to_float(d.get(k)); break
        if kw: rows.append({'keyword': kw, 'score': 0.0 if sc is None else sc})

    def walk(o):
        if isinstance(o, dict):
            if "ranks" in o and isinstance(o["ranks"], list):
                for i, d in enumerate(o["ranks"], 1):
                    kw = (d.get("keyword") or d.get("relKeyword") or "").strip()
                    sc = None
                    for k in ("ratio","ratioValue","value","score","count","ratioIndex"):
                        if k in d: sc = _to_float(d.get(k)); break
                    if kw: rows.append({"rank": i, "keyword": kw, "score": 0.0 if sc is None else sc})
            for v in o.values():
                if isinstance(v, (dict, list)): walk(v)
            consider(o)
        elif isinstance(o, list):
            for v in o: walk(v)
    walk(obj)

    best = {}
    for r in rows:
        k = r["keyword"]; s = float(r.get("score", 0) or 0)
        if k and (k not in best or s > best[k]["score"]): best[k] = {"keyword": k, "score": s}
    out = list(best.values()); out.sort(key=lambda x: x.get("score", 0), reverse=True); out = out[:20]
    for i, r in enumerate(out, 1): r["rank"] = i
    return out

def _extract_top20_from_text(txt: str) -> List[dict]:
    # 1) {"message":null, "ranks":[...]}
    for m in re.finditer(r'\{"message"\s*:\s*null.*?\}', txt, re.S):
        try:
            data = json.loads(m.group(0))
            rows = _normalize_top20(data)
            if rows: return rows
        except Exception: pass
    # 2) "ranks":[...]
    m = re.search(r'"ranks"\s*:\s*(\[[^\]]+\])', txt, re.S)
    if m:
        try:
            arr = json.loads(m.group(1))
            return _normalize_top20({"ranks": arr})
        except Exception: pass
    # 3) keyword/ratio ìŒ ê¸ê¸°
    pats = [
        r'"keyword"\s*:\s*"([^"]+)"[^}]*?(?:ratio|ratioValue|value|score)"\s*:\s*"?(?P<num>[-\d.,]+%?)"?',
        r'"relKeyword"\s*:\s*"([^"]+)"[^}]*?(?:ratio|ratioValue|value|score)"\s*:\s*"?(?P<num>[-\d.,]+%?)"?',
    ]
    kv = defaultdict(float)
    for p in pats:
        for kw, sc in re.findall(p, txt):
            kw = kw.strip(); val = _to_float(sc)
            if kw and val > kv[kw]: kv[kw] = val
    rows = [{"keyword": k, "score": v} for k, v in kv.items()]
    rows.sort(key=lambda x: x["score"], reverse=True); rows = rows[:20]
    for i, r in enumerate(rows, 1): r["rank"] = i
    return rows

@st.cache_data(show_spinner=False, ttl=600)
def _fetch_top20(cookie: str, cid: str, start: str, end: str) -> dict:
    if not requests: return {"ok": False, "reason": "requests ë¯¸ì„¤ì¹˜"}
    tried, last_json, last_reason = [], None, ""
    base_kw = "https://datalab.naver.com/shoppingInsight/getCategoryKeywordRank.naver"

    for method in ("POST","GET"):
        for time_unit in ("week","date"):
            for device in ("all","pc","mo"):
                for age_key in ("age","ages"):
                    tried.append(f"{method}:{time_unit}/{device}/{age_key}")
                    payload = {"cid": str(cid).strip(),"timeUnit": time_unit,"startDate": start,"endDate": end,"device": device,"gender": "all"}
                    payload[age_key] = "all"
                    try:
                        if method=="POST":
                            r = requests.post(base_kw, headers=_hdr(cookie, cid, time_unit, device, as_json=True),
                                              data=payload, timeout=12, allow_redirects=False)
                        else:
                            r = requests.get(base_kw, headers=_hdr(cookie, cid, time_unit, device, as_json=True),
                                             params=payload, timeout=12, allow_redirects=False)
                        ct = (r.headers.get("content-type") or "").lower()
                        if r.status_code in (301,302,303,307,308): return {"ok": False, "reason": "302 ë¦¬ë‹¤ì´ë ‰íŠ¸ â€” ì¿ í‚¤ ë§Œë£Œ/ë¡œê·¸ì¸ í•„ìš”", "tried": tried}
                        if "text/html" in ct: last_reason = "HTML ì‘ë‹µ â€” ì¿ í‚¤/ë¦¬í¼ëŸ¬ ë¶ˆì¼ì¹˜"; continue
                        r.raise_for_status()
                        data = r.json(); last_json = data
                        rows = _normalize_top20(data)
                        if rows: return {"ok": True, "rows": rows}
                        last_reason = "ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨(êµ¬ì¡° ë³€ê²½ ê°€ëŠ¥ì„±)"
                    except Exception as e:
                        last_reason = f"ìš”ì²­ ì‹¤íŒ¨: {e}"

    base_cat = "https://datalab.naver.com/shoppingInsight/getCategory.naver"
    for time_unit in ("week","date"):
        for device in ("all","pc","mo"):
            for age_key in ("age","ages"):
                tried.append(f"GET:getCategory/{time_unit}/{device}/{age_key}")
                params = {"cid": str(cid).strip(),"timeUnit": time_unit,"startDate": start,"endDate": end,"device": device,"gender": "all"}
                params[age_key] = "all"
                try:
                    r = requests.get(base_cat, headers=_hdr(cookie, cid, time_unit, device, as_json=True),
                                     params=params, timeout=12, allow_redirects=False)
                    if r.status_code in (301,302,303,307,308): return {"ok": False, "reason": "302 ë¦¬ë‹¤ì´ë ‰íŠ¸ â€” ì¿ í‚¤ ë§Œë£Œ/ë¡œê·¸ì¸ í•„ìš”", "tried": tried}
                    ct = (r.headers.get("content-type") or "").lower()
                    if "application/json" in ct:
                        data = r.json(); last_json = data
                        rows = _normalize_top20(data)
                        if rows: return {"ok": True, "rows": rows}
                        rows = _extract_top20_from_text(r.text or "")
                        if rows: return {"ok": True, "rows": rows}
                    else:
                        rows = _extract_top20_from_text(r.text or "")
                        if rows: return {"ok": True, "rows": rows}
                    last_reason = "getCategory ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨"
                except Exception as e:
                    last_reason = f"getCategory ì‹¤íŒ¨: {e}"

    try:
        page_url = ("https://datalab.naver.com/shoppingInsight/sCategory.naver"
                    f"?cid={cid}&timeUnit=week&startDate={start}&endDate={end}&device=all&gender=all&ages=all")
        r = requests.get(page_url, headers=_hdr(cookie, cid, as_json=False),
                         timeout=12, allow_redirects=False)
        if r.status_code in (301,302,303,307,308): return {"ok": False, "reason": "302 ë¦¬ë‹¤ì´ë ‰íŠ¸ â€” ì¿ í‚¤ ë§Œë£Œ/ë¡œê·¸ì¸ í•„ìš”", "tried": tried}
        html = r.text or ""; rows = _extract_top20_from_text(html)
        if rows: return {"ok": True, "rows": rows, "fallback": "html"}
        sample = ""
        try:
            if last_json is not None: sample = json.dumps(last_json, ensure_ascii=False)[:800]
        except Exception: pass
        return {"ok": False, "reason": last_reason or "ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨", "tried": tried, "sample": sample}
    except Exception as e:
        sample = ""
        try:
            if last_json is not None: sample = json.dumps(last_json, ensure_ascii=False)[:800]
        except Exception: pass
        return {"ok": False, "reason": f"HTML í´ë°± ì‹¤íŒ¨: {e}", "tried": tried, "sample": sample}

@st.cache_data(show_spinner=False, ttl=600)
def _fetch_trend(cookie: str, keywords: List[str], start: str, end: str) -> pd.DataFrame:
    if not (requests and keywords): return pd.DataFrame()
    url = "https://datalab.naver.com/shoppingInsight/getKeywordTrends.naver"
    headers = _hdr(cookie, cid='50000000', as_json=True)
    payload = {
        "timeUnit": "week","startDate": start,"endDate": end,
        "keyword": json.dumps([{"name": k.strip(), "param": [k.strip()]} for k in keywords], ensure_ascii=False),
        "device": "all","gender": "all","ages": "all",
    }
    try:
        r = requests.post(url, headers=headers, data=payload, timeout=12, allow_redirects=False)
        ct = (r.headers.get("content-type") or "").lower()
        if r.status_code in (301,302,303,307,308) or "text/html" in ct: return pd.DataFrame()
        r.raise_for_status(); data = r.json()
    except Exception: return pd.DataFrame()

    series: Dict[str, list] = {}
    def walk(o):
        if isinstance(o, dict):
            title = o.get("title") or o.get("name")
            data_list = o.get("data")
            if title and isinstance(data_list, list):
                for i, p in enumerate(data_list):
                    period = p.get("period") or p.get("date") or f"P{i}"
                    ratio  = p.get("ratio")  or p.get("value") or 0
                    series.setdefault("period", []).append(period)
                    series.setdefault(title, []).append(ratio)
            for v in o.values():
                if isinstance(v, (dict, list)): walk(v)
        elif isinstance(o, list):
            for v in o: walk(v)
    walk(data)
    if not series: return pd.DataFrame()
    df = pd.DataFrame(series)
    if "period" in df.columns: df = df.set_index("period")
    return df

def render_datalab_block():
    st.markdown("## ë°ì´í„°ë© (ë¶„ì„)")
    cookie = _naver_cookie()
    if not cookie:
        with st.expander("NAVER_COOKIE ì…ë ¥(ìµœì´ˆ 1íšŒ)", expanded=True):
            c = st.text_input("ì¿ í‚¤ ì „ì²´ ë¬¸ìì—´", type="password",
                              help="datalab.naver.com ë¡œê·¸ì¸ ìƒíƒœì—ì„œ NID_* í¬í•¨ ì „ì²´ ì¿ í‚¤ ë³µì‚¬/ë¶™ì—¬ë„£ê¸°")
            if c:
                st.session_state["__NAVER_COOKIE"] = c.strip()
                cookie = c.strip()
                st.success("ì„¸ì…˜ ì €ì¥ ì™„ë£Œ")

    c1, c2 = st.columns([1.1, 1.4])
    with c1:
        cat = st.selectbox("ì¹´í…Œê³ ë¦¬", DATALAB_CATS, key="dl_cat_simple")
        cid = CID_MAP.get(cat, "50000000")
        today = date.today()
        start = st.date_input("ì‹œì‘ì¼", value=today - timedelta(days=30), key="dl_start_simple")
        end   = st.date_input("ì¢…ë£Œì¼", value=today, key="dl_end_simple")
        btn = st.button("Top20 ë¶ˆëŸ¬ì˜¤ê¸°", key="dl_go_simple", use_container_width=True)

        top_df = pd.DataFrame()
        if btn:
            if not cookie:
                st.error("NAVER_COOKIEê°€ í•„ìš”í•©ë‹ˆë‹¤. ìœ„ì—ì„œ í•œ ë²ˆë§Œ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            else:
                res = _fetch_top20(cookie, cid, str(start), str(end))
                if not res.get("ok"):
                    st.error(f"ì¡°íšŒ ì‹¤íŒ¨: {res.get('reason')}")
                    if res.get("tried"): st.caption("ì‹œë„: " + ", ".join(res["tried"]))
                    if res.get("sample"): st.caption("ì‘ë‹µ ìƒ˜í”Œ:"); st.code(res["sample"])
                else:
                    top_df = pd.DataFrame(res["rows"], columns=["rank","keyword","score"])
                    st.dataframe(top_df, hide_index=True, use_container_width=True, height=420)

        st.session_state.setdefault("_top_keywords", [])
        if not top_df.empty: st.session_state["_top_keywords"] = top_df["keyword"].tolist()

    with c2:
        st.markdown("### ì„ íƒ í‚¤ì›Œë“œ íŠ¸ë Œë“œ")
        kw_source = st.session_state.get("_top_keywords", [])
        if kw_source:
            picks = st.multiselect("í‚¤ì›Œë“œ(ìµœëŒ€ 5ê°œ)", kw_source, default=kw_source[:3],
                                   max_selections=5, key="dl_kw_picks")
            if st.button("íŠ¸ë Œë“œ ë³´ê¸°", key="dl_trend_simple"):
                if not cookie:
                    st.error("NAVER_COOKIEê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                elif not picks:
                    st.warning("í‚¤ì›Œë“œë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
                else:
                    df_line = _fetch_trend(cookie, picks,
                                           str(st.session_state["dl_start_simple"]),
                                           str(st.session_state["dl_end_simple"]))
                    if df_line.empty:
                        x = np.arange(0, 12)
                        base = 50 + 5*np.sin(x/2)
                        df_line = pd.DataFrame({
                            (picks[0] if len(picks)>0 else "kw1"): base,
                            (picks[1] if len(picks)>1 else "kw2"): base-5 + 3*np.cos(x/3),
                            (picks[2] if len(picks)>2 else "kw3"): base+3 + 4*np.sin(x/4),
                        }, index=[f"P{i}" for i in range(len(x))])
                        st.info("ì‹¤ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ â€” ìƒ˜í”Œ ë¼ì¸ì„ í‘œì‹œí•©ë‹ˆë‹¤.")
                    st.line_chart(df_line, height=260, use_container_width=True)
        else:
            st.caption("ì¢Œì¸¡ì—ì„œ Top20ì„ ë¨¼ì € ë¶ˆëŸ¬ì˜¤ë©´ ì—¬ê¸°ì„œ íŠ¸ë Œë“œë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# -----------------------------
# Part 3.5 â€” ë°ì´í„°ë©(ì›ë³¸ ì„ë² ë“œ, Worker v2 '?url=')
# -----------------------------
from urllib.parse import quote

def render_datalab_embed_block():
    st.markdown("## ë°ì´í„°ë© (ì›ë³¸ ì„ë² ë“œ)")
    _CID_MAP = CID_MAP
    _CATS = list(_CID_MAP.keys())

    colA, colB, colC = st.columns([1.2, 1, 1])
    with colA:
        cat = st.selectbox("ì¹´í…Œê³ ë¦¬", _CATS, index=3, key="dl_embed_cat")
        cid = _CID_MAP.get(cat, "50000003")
    with colB:
        time_unit = st.selectbox("ê¸°ê°„ ë‹¨ìœ„", ["week","month"], index=0, key="dl_embed_timeunit")
    with colC:
        device = st.selectbox("ê¸°ê¸°", ["all","pc","mo"], index=0, key="dl_embed_device")

    proxy = (st.session_state.get("PROXY_URL") or "").strip().rstrip("/")
    if not proxy:
        st.warning("PROXY_URL ì—†ìŒ â€” ì‚¬ì´ë“œë°” í•˜ë‹¨ì— Cloudflare Worker ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        return

    target = f"https://datalab.naver.com/shoppingInsight/sCategory.naver?cid={cid}&timeUnit={time_unit}&device={device}&gender=all&ages=all"
    embed_url = f"{proxy}/?url={quote(target, safe=':/?&=%')}"
    st.components.v1.iframe(embed_url, height=980, scrolling=True)
    st.caption("í”„ë¡ì‹œê°€ ì¿ í‚¤/í—¤ë”ë¥¼ ì„œë²„ ì¸¡ì—ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì•±ì—ëŠ” ì¿ í‚¤ ì €ì¥ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤.")

# =========================
# Part 4 â€” 11ë²ˆê°€(ëª¨ë°”ì¼) ì„ë² ë“œ (ì•„ë§ˆì¡´ë² ìŠ¤íŠ¸ 'ê³ ì •')
# =========================
import urllib.parse as _url

AMAZON_BEST_URL = "https://m.11st.co.kr/page/main/abest?tabId=ABEST&pageId=AMOBEST&ctgr1No=166160"

def _proxy_wrap(url: str) -> str:
    """PROXY_URLì´ ìˆìœ¼ë©´ ?url= ë˜í•‘, ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜"""
    proxy = st.session_state.get("PROXY_URL", "").strip().rstrip("/")
    if proxy:
        return f"{proxy}/?url={_url.quote(url, safe='')}"
    return url

def render_11st_block():
    st.markdown("## 11ë²ˆê°€ (ëª¨ë°”ì¼) â€” ì•„ë§ˆì¡´ë² ìŠ¤íŠ¸ (ê³ ì •)")

    if not st.session_state.get("PROXY_URL", "").strip():
        st.warning("PROXY_URLì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. 11ë²ˆê°€ëŠ” iFrame ì°¨ë‹¨ì´ ìˆì–´ Cloudflare Worker ê²½ìœ ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
                   "ì‚¬ì´ë“œë°” í•˜ë‹¨ì— Worker ì£¼ì†Œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

    try:
        st.components.v1.iframe(_proxy_wrap(AMAZON_BEST_URL), height=780, scrolling=True)
        st.caption("ëª¨ë°”ì¼ íƒ­: ì•„ë§ˆì¡´ë² ìŠ¤íŠ¸(ê³ ì •)")
    except Exception as e:
        st.error(f"11ë²ˆê°€ ì„ë² ë“œ ì‹¤íŒ¨: {e}")
        st.code(AMAZON_BEST_URL, language="text")

# -----------------------------
# Part 4.5 â€” ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ ì„ë² ë“œ
# -----------------------------
def render_itemscout_embed():
    proxy = (st.session_state.get("PROXY_URL") or "").strip().rstrip("/")
    st.markdown("## ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ (ì›ë³¸ ì„ë² ë“œ)")
    if not proxy:
        st.warning("PROXY_URLì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°” í•˜ë‹¨ì— Worker ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        return
    default_url = st.secrets.get("itemscout", {}).get("DEFAULT_URL", "https://app.itemscout.io/market/keyword")
    url = st.text_input("Itemscout URL", default_url, help="ë¡œê·¸ì¸ëœ ìƒíƒœë¡œ ë³´ê³  ì‹¶ì€ ê²½ë¡œë¥¼ ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥")
    from urllib.parse import quote as _q
    st.components.v1.iframe(f"{proxy}/?url={_q(url, safe=':/?&=%')}", height=920, scrolling=True)

# -----------------------------
# Part 4.6 â€” ì…€ëŸ¬ë¼ì´í”„ ì„ë² ë“œ
# -----------------------------
def render_sellerlife_embed():
    proxy = (st.session_state.get("PROXY_URL") or "").strip().rstrip("/")
    st.markdown("## ì…€ëŸ¬ë¼ì´í”„ (ì›ë³¸ ì„ë² ë“œ)")
    if not proxy:
        st.warning("PROXY_URLì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°” í•˜ë‹¨ì— Worker ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        return
    default_url = st.secrets.get("sellerlife", {}).get("DEFAULT_URL", "https://sellerlife.co.kr/dashboard")
    url = st.text_input("SellerLife URL", default_url)
    from urllib.parse import quote as _q
    st.components.v1.iframe(f"{proxy}/?url={_q(url, safe=':/?&=%')}", height=920, scrolling=True)

# -----------------------------
# Part 5 â€” AI í‚¤ì›Œë“œ ë ˆì´ë” (Rakuten)  [ì‹¤ë°ì´í„° ìš°ì„  + ìŠ¤í¬ë¡¤/ì—¬ë°±/URL ì¶•ì†Œ]
# -----------------------------
# ë„¤ê°€ ì¤€ í‚¤ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ â€œë°•ìŒâ€ (secretsê°€ ìˆìœ¼ë©´ secretsê°€ ìš°ì„ )
RAKUTEN_APP_ID_DEFAULT       = "1043271015809337425"
RAKUTEN_AFFILIATE_ID_DEFAULT = "4c723498.cbfeca46.4c723499.1deb6f77"

RAKUTEN_CATS = [
    "ì „ì²´(ìƒ˜í”Œ)","ë·°í‹°/ì½”ìŠ¤ë©”í‹±","ì˜ë¥˜/íŒ¨ì…˜","ê°€ì „/ë””ì§€í„¸","ê°€êµ¬/ì¸í…Œë¦¬ì–´",
    "ì‹í’ˆ","ìƒí™œ/ê±´ê°•","ìŠ¤í¬ì¸ /ë ˆì €","ë¬¸êµ¬/ì·¨ë¯¸"
]

def _get_rakuten_keys():
    try:
        app_id = (st.secrets.get("rakuten", {}).get("APP_ID") or
                  st.secrets.get("RAKUTEN_APP_ID") or
                  st.secrets.get("RAKUTEN_APPLICATION_ID") or
                  RAKUTEN_APP_ID_DEFAULT)
    except Exception:
        app_id = RAKUTEN_APP_ID_DEFAULT
    try:
        affiliate = (st.secrets.get("rakuten", {}).get("AFFILIATE_ID") or
                     st.secrets.get("RAKUTEN_AFFILIATE_ID") or
                     st.secrets.get("RAKUTEN_AFFILIATE") or
                     RAKUTEN_AFFILIATE_ID_DEFAULT)
    except Exception:
        affiliate = RAKUTEN_AFFILIATE_ID_DEFAULT
    return (app_id or "").strip(), (affiliate or "").strip()

def _fetch_rank(genre_id: str, topn: int = 20) -> pd.DataFrame:
    """Rakuten IchibaItem Ranking API â†’ Top N"""
    if not requests:
        raise RuntimeError("requests ë¯¸ì„¤ì¹˜")
    app_id, affiliate = _get_rakuten_keys()
    url = "https://app.rakuten.co.jp/services/api/IchibaItem/Ranking/20170628"
    params = {"applicationId": app_id, "genreId": str(genre_id).strip(), "carrier": 0}
    if affiliate:
        params["affiliateId"] = affiliate
    r = requests.get(url, params=params, timeout=12)
    r.raise_for_status()
    items = r.json().get("Items", [])
    rows = []
    for it in items[:topn]:
        node = it.get("Item", {})
        rows.append({
            "rank": node.get("rank"),
            "keyword": node.get("itemName") or "",
            "shop": node.get("shopName") or "",
            "url": node.get("itemUrl") or "",
        })
    return pd.DataFrame(rows)

def _mock_rows(n=20) -> pd.DataFrame:
    return pd.DataFrame([{
        "rank": i+1, "keyword": f"[ìƒ˜í”Œ] í‚¤ì›Œë“œ {i+1} ãƒãƒ­ã‚¦ã‚£ãƒ³ ç§‹ ğŸ‚", "shop": "ìƒ˜í”Œìƒµ", "url": "https://example.com"
    } for i in range(n)])

def render_rakuten_block():
    st.markdown("## AI í‚¤ì›Œë“œ ë ˆì´ë” (Rakuten)")
    # ì„¹ì…˜ ì—¬ë°±/í°íŠ¸ ì •ë¦¬ + í‘œ ë‚´ë¶€ ìŠ¤í¬ë¡¤
    st.markdown("""
    <style>
      .rk-wrap [data-testid="stVerticalBlock"] { gap: .4rem !important; }
      .rk-wrap .stMarkdown { margin: .25rem 0 !important; }
      .rk-wrap .stDataFrame { margin-top: .2rem !important; }
      .rk-wrap .stDataFrame [role="grid"] { font-size: 0.90rem !important; }
      .rk-wrap .stDataFrame a { font-size: 0.86rem !important; }
    </style>
    """, unsafe_allow_html=True)

    colA, colB, colC, colD = st.columns([1,1,1,1])
    with colA:
        scope = st.radio("ë²”ìœ„", ["êµ­ë‚´","ê¸€ë¡œë²Œ"], horizontal=True, key="rk_scope")
    with colB:
        cat = st.selectbox("ë¼ì¿ í… ì¹´í…Œê³ ë¦¬", RAKUTEN_CATS, key="rk_cat")
    with colC:
        genreid = st.text_input("GenreID", "100283", key="rk_genre")
    with colD:
        sample_only = st.checkbox("ìƒ˜í”Œ ë³´ê¸°", value=False, help="ì²´í¬ ì‹œ ìƒ˜í”Œ ë°ì´í„°ë¡œ í‘œì‹œ")

    app_id, affiliate = _get_rakuten_keys()
    st.caption(f"APP_ID: {('âœ… ' + app_id) if app_id else 'âŒ ì—†ìŒ'}  |  Affiliate: {('âœ… ' + affiliate) if affiliate else 'â€”'}")

    # â–¶ ì‹¤ë°ì´í„° ê°•ì œ: ìƒ˜í”Œ ì²´í¬ ì•ˆ í–ˆìœ¼ë©´ í•­ìƒ API ë¨¼ì € ì‹œë„
    df = pd.DataFrame()
    err = None
    if not sample_only:
        try:
            df = _fetch_rank(genreid or "100283", topn=20)
        except Exception as e:
            err = str(e)

    if df.empty:
        if err:
            st.warning(f"Rakuten API ì‹¤íŒ¨ â†’ ìƒ˜í”Œë¡œ ëŒ€ì²´: {err[:200]}")
        df = _mock_rows(20)

    # URL â†’ 'ì—´ê¸°' ë§í¬ (í­ ì¶•ì†Œ)
    df = df[["rank","keyword","shop","url"]]
    colcfg = {
        "rank":    st.column_config.NumberColumn("rank", width="small"),
        "keyword": st.column_config.TextColumn("keyword", width="large"),
        "shop":    st.column_config.TextColumn("shop", width="medium"),
        "url":     st.column_config.LinkColumn("url", display_text="ì—´ê¸°", width="small"),
    }

    with st.container():
        st.markdown('<div class="rk-wrap">', unsafe_allow_html=True)
        st.dataframe(df, hide_index=True, use_container_width=True, height=420, column_config=colcfg)
        st.markdown('</div>', unsafe_allow_html=True)

# -----------------------------
# Part 6 â€” êµ¬ê¸€ ë²ˆì—­
# -----------------------------
def translate_text(src:str, tgt:str, text:str) -> tuple[str,str]:
    if not GoogleTranslator:
        raise ModuleNotFoundError("deep-translator ë¯¸ì„¤ì¹˜")
    src = lang_label_to_code(src); tgt = lang_label_to_code(tgt)
    translator = GoogleTranslator(source=src, target=tgt)
    out = translator.translate(text)
    ko_hint = ""
    if tgt != "ko" and out.strip():
        try:
            ko_hint = GoogleTranslator(source=tgt, target="ko").translate(out)
        except Exception:
            ko_hint = ""
    return out, ko_hint

def render_translator_block():
    st.markdown("## êµ¬ê¸€ ë²ˆì—­ (í…ìŠ¤íŠ¸ ì…ë ¥/ì¶œë ¥ + í•œêµ­ì–´ í™•ì¸ìš©)")
    c1, c2 = st.columns([1,1])
    with c1:
        src = st.selectbox("ì›ë¬¸ ì–¸ì–´", list(LANG_LABELS.values()), index=list(LANG_LABELS.keys()).index("auto"), key="tr_src")
        text_in = st.text_area("ì›ë¬¸ ì…ë ¥", height=150, key="tr_in")
    with c2:
        tgt = st.selectbox("ë²ˆì—­ ì–¸ì–´", list(LANG_LABELS.values()), index=list(LANG_LABELS.keys()).index("en"), key="tr_tgt")
        if st.button("ë²ˆì—­", key="tr_go"):
            try:
                out, ko_hint = translate_text(lang_label_to_code(src), lang_label_to_code(tgt), text_in)
                if ko_hint and lang_label_to_code(tgt) != "ko":
                    st.text_area("ë²ˆì—­ ê²°ê³¼", value=f"{out}\n{ko_hint}", height=150)
                else:
                    st.text_area("ë²ˆì—­ ê²°ê³¼", value=out, height=150)
                toast_ok("ë²ˆì—­ ì™„ë£Œ")
            except ModuleNotFoundError as e:
                st.warning(f"deep-translator ì„¤ì¹˜ í•„ìš”: {e}")
            except Exception as e:
                st.error(f"ë²ˆì—­ ì‹¤íŒ¨: {e}")

# -----------------------------
# Part 7 â€” ë©”ì¸ ì¡°ë¦½ (ì›í˜ì´ì§€, ê°€ë¡œ ê·¸ë¦¬ë“œ 4Ã—2)  [êµì²´ìš©]
# -----------------------------
def _inject_global_css():
    # ì‚¬ì´ë“œë°”ëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ(ì¤‘ìš”). ë³¸ë¬¸ ì¹´ë“œ ìŠ¤íƒ€ì¼ë§Œ ì¶”ê°€.
    st.markdown("""
    <style>
      .block-container { max-width: 1500px !important; padding-top:.8rem !important; padding-bottom:1rem !important; }
      html, body { overflow: auto !important; }

      /* ì¹´ë“œ ìŠ¤íƒ€ì¼: í¼ì§í•˜ê³  ëŒ€ë¹„ ë†’ê²Œ */
      .envy-card {
        background: rgba(0,0,0,.02);
        border: 1px solid rgba(0,0,0,.09);
        border-radius: 16px;
        padding: 18px 18px;
        box-shadow: 0 6px 18px rgba(0,0,0,.05);
      }
      .envy-card h3, .envy-card h2 { margin: 0 0 .35rem 0 !important; }
      .envy-sub { font-size:.86rem; opacity:.75; margin-bottom:.35rem; }

      /* ì¹´ë“œ ê°„ ê°„ê²© */
      .envy-gap { margin-top: .6rem; margin-bottom: .6rem; }
    </style>
    """, unsafe_allow_html=True)

def _card(title:str, sub:str=""):
    st.markdown('<div class="envy-card">', unsafe_allow_html=True)
    st.markdown(f'**{title}**' + (f'  \n<span class="envy-sub">{sub}</span>' if sub else ''), unsafe_allow_html=True)

def _close_card():
    st.markdown('</div>', unsafe_allow_html=True)

def _safe_call(fn_name:str, title:str=None, sub:str=""):
    fn = globals().get(fn_name)
    _card(title or fn_name, sub)
    if callable(fn):
        try:
            fn()
        except Exception as e:
            st.error(f"{title or fn_name} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
    else:
        st.info(f"'{fn_name}()' ì´ ì •ì˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    _close_card()

def _spacer(h=10):
    st.markdown(f'<div class="envy-gap" style="height:{h}px;"></div>', unsafe_allow_html=True)

def main():
    # ì‚¬ì´ë“œë°”ëŠ” ì›ë³¸ í•¨ìˆ˜ ê·¸ëŒ€ë¡œ í˜¸ì¶œ (ë¶ˆë³€)
    _ = render_sidebar()
    _inject_global_css()

    st.title("ENVY â€” Season 1 (stable)")
    st.caption("ì„ë² ë“œ ê¸°ë³¸ + ë¶„ì„ ë³´ì¡°. í”„ë¡ì‹œ/ì¿ í‚¤ëŠ” Worker ë¹„ë°€ê°’ìœ¼ë¡œ ê´€ë¦¬.")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Row 1 â€” ê°€ë¡œ 4ì—´: ë°ì´í„°ë©(ì›ë³¸) Â· ë°ì´í„°ë©(ë¶„ì„) Â· 11ë²ˆê°€(ì•„ë§ˆì¡´) Â· ìƒí’ˆëª… ìƒì„±ê¸°
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    r1c1, r1c2, r1c3, r1c4 = st.columns([1,1,1,1], gap="large")
    with r1c1:
        _safe_call("render_datalab_embed_block", "ë°ì´í„°ë© (ì›ë³¸ ì„ë² ë“œ)", "í”„ë¡ì‹œ ê²½ìœ  Â· ì¿ í‚¤ ì•± ë¹„ì €ì¥")
    with r1c2:
        _safe_call("render_datalab_block", "ë°ì´í„°ë© (ë¶„ì„ ë³´ì¡°)", "Top20 + íŠ¸ë Œë“œ")
    with r1c3:
        _safe_call("render_11st_block", "11ë²ˆê°€ (ëª¨ë°”ì¼) â€” ì•„ë§ˆì¡´ë² ìŠ¤íŠ¸", "í”„ë¡ì‹œ ê¶Œì¥")
    with r1c4:
        _safe_call("render_product_name_generator", "ìƒí’ˆëª… ìƒì„±ê¸° (ê·œì¹™ ê¸°ë°˜)", "ë¸Œëœë“œ/ì†ì„±/í‚¤ì›Œë“œ ì¡°í•©")

    _spacer(8)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Row 2 â€” ê°€ë¡œ 4ì—´: AI í‚¤ì›Œë“œ ë ˆì´ë” Â· êµ¬ê¸€ ë²ˆì—­ê¸° Â· ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ Â· ì…€ëŸ¬ë¼ì´í”„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    r2c1, r2c2, r2c3, r2c4 = st.columns([1,1,1,1], gap="large")
    with r2c1:
        _safe_call("render_rakuten_block", "AI í‚¤ì›Œë“œ ë ˆì´ë” (Rakuten)", "ì‹¤ë°ì´í„° ìš°ì„  Â· URL â€˜ì—´ê¸°â€™")
    with r2c2:
        _safe_call("render_translator_block", "êµ¬ê¸€ ë²ˆì—­", "í•œêµ­ì–´ í™•ì¸ ë¼ì¸ í¬í•¨")
    with r2c3:
        _safe_call("render_itemscout_embed", "ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ (ì„ë² ë“œ)", "ë¡œê·¸ì¸ í•„ìš” ì‹œ Worker Secrets")
    with r2c4:
        _safe_call("render_sellerlife_embed", "ì…€ëŸ¬ë¼ì´í”„ (ì„ë² ë“œ)", "ë¡œê·¸ì¸ í•„ìš” ì‹œ Worker Secrets")

# -----------------------------
# Part 8 â€” ê°„ë‹¨ ê·œì¹™ ê¸°ë°˜ ìƒí’ˆëª… ìƒì„±ê¸°(ë³µêµ¬)
# -----------------------------
def render_product_name_generator():
    st.markdown("### ìƒí’ˆëª… ìƒì„±ê¸° (ê·œì¹™ ê¸°ë°˜)")
    with st.container(border=True):
        colA, colB = st.columns([1,2])
        with colA:
            brand = st.text_input("ë¸Œëœë“œ", placeholder="ì˜ˆ: Apple / ìƒ¤ì˜¤ë¯¸ / ë¬´ì§€")
            attrs = st.text_input("ì†ì„±(ì½¤ë§ˆ, ì„ íƒ)", placeholder="ì˜ˆ: ê³µì‹, ì •í’ˆ, í•œì •íŒ")
        with colB:
            kws = st.text_input("í‚¤ì›Œë“œ(ì½¤ë§ˆ)", placeholder="ì˜ˆ: ë…¸íŠ¸ë¶ ìŠ¤íƒ ë“œ, ì ‘ì´ì‹, ì•Œë£¨ë¯¸ëŠ„")
        col1, col2, col3 = st.columns([1,1,1])
        with col1:
            max_len = st.slider("ìµœëŒ€ ê¸€ììˆ˜", 20, 80, 50, 1)
        with col2:
            joiner = st.selectbox("êµ¬ë¶„ì", [" ", " | ", " Â· ", " - "], index=0)
        with col3:
            order = st.selectbox("ìˆœì„œ", ["ë¸Œëœë“œ-í‚¤ì›Œë“œ-ì†ì„±", "í‚¤ì›Œë“œ-ë¸Œëœë“œ-ì†ì„±", "ë¸Œëœë“œ-ì†ì„±-í‚¤ì›Œë“œ"], index=0)

        if st.button("ìƒí’ˆëª… ìƒì„±"):
            kw_list = [k.strip() for k in kws.split(",") if k.strip()]
            at_list = [a.strip() for a in attrs.split(",") if a.strip()]
            if not kw_list:
                st.warning("í‚¤ì›Œë“œê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤.")
                return
            titles = []
            for k in kw_list:
                seq = []
                if order=="ë¸Œëœë“œ-í‚¤ì›Œë“œ-ì†ì„±": seq = [brand, k] + at_list
                elif order=="í‚¤ì›Œë“œ-ë¸Œëœë“œ-ì†ì„±": seq = [k, brand] + at_list
                else: seq = [brand] + at_list + [k]
                title = joiner.join([p for p in seq if p])
                if len(title) > max_len:
                    title = title[:max_len-1] + "â€¦"
                titles.append(title)
            st.success(f"ì´ {len(titles)}ê±´")
            st.write("\n".join(titles))

# -----------------------------
# Main
# -----------------------------
def main():
    sidebar_vals = render_sidebar()
    _inject_global_css()

    st.title("ENVY â€” Season 1 (stable)")
    st.caption("ì„ë² ë“œ ê¸°ë³¸ + ë¶„ì„ ë³´ì¡°. í”„ë¡ì‹œ/ì¿ í‚¤ëŠ” Worker ë¹„ë°€ê°’ìœ¼ë¡œ ê´€ë¦¬. (PROXY_URL ì˜ˆ: https://envy-proxy.taesig0302.workers.dev/)")

    # ë°ì´í„°ë© â€” ì›ë³¸ ì„ë² ë“œ
    _spacer(); st.markdown("### ë°ì´í„°ë© (ì›ë³¸ ì„ë² ë“œ)")
    _safe_call("render_datalab_embed_block")

    # ë°ì´í„°ë© â€” ë¶„ì„ ë³´ì¡°
    _spacer(); st.markdown("### ë°ì´í„°ë© (ë¶„ì„)")
    _safe_call("render_datalab_block")

    # 11ë²ˆê°€ + ë ˆì´ë”
    _spacer()
    colL, colR = st.columns([1,1], gap="large")
    with colL:
        st.markdown("### 11ë²ˆê°€ (ëª¨ë°”ì¼)")
        _safe_call("render_11st_block")
    with colR:
        st.markdown("### AI í‚¤ì›Œë“œ ë ˆì´ë” (Rakuten)")
        _safe_call("render_rakuten_block")

    # ë²ˆì—­
    _spacer(); st.markdown("### êµ¬ê¸€ ë²ˆì—­")
    _safe_call("render_translator_block")

    # ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸ / ì…€ëŸ¬ë¼ì´í”„
    _spacer(); st.markdown("### ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸")
    _safe_call("render_itemscout_embed")
    _spacer(); st.markdown("### ì…€ëŸ¬ë¼ì´í”„")
    _safe_call("render_sellerlife_embed")

    # ìƒí’ˆëª… ìƒì„±ê¸°
    _spacer(); st.markdown("### ìƒí’ˆëª… ìƒì„±ê¸°")
    _safe_call("render_product_name_generator")

if __name__ == "__main__":
    main()
